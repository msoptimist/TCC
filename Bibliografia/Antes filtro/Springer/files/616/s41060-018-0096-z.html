<!DOCTYPE html>
<html class="js" lang="en-gb"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=2.5,user-scalable=yes">
    <meta name="citation_publisher" content="Springer International Publishing">
    <meta name="citation_title" content="Automatic emotion detection in text streams by analyzing Twitter data">
    <meta name="citation_doi" content="10.1007/s41060-018-0096-z">
    <meta name="citation_language" content="en">
    <meta name="citation_abstract_html_url" content="https://link.springer.com/article/10.1007/s41060-018-0096-z">
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s41060-018-0096-z">
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007%2Fs41060-018-0096-z.pdf">
    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s41060-018-0096-z&amp;api_key=">
    <meta name="citation_firstpage" content="1">
    <meta name="citation_lastpage" content="17">
    <meta name="citation_author" content="Maryam Hasan">
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute">
    <meta name="citation_author_email" content="mhasan@wpi.edu">
    <meta name="citation_author" content="Elke Rundensteiner">
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute">
    <meta name="citation_author" content="Emmanuel Agu">
    <meta name="citation_author_institution" content="Worcester Polytechnic Institute">
    <meta name="dc.identifier" content="10.1007/s41060-018-0096-z">
    <meta name="format-detection" content="telephone=no">
    <meta name="description" content="Techniques to detect the emotions expressed in microblogs and social media posts have a wide range of applications including, detecting psychological disorders such as anxiety or depression in...">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Automatic emotion detection in text streams by analyzing Twitter data">
    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/41060/6/2.jpg">
    <meta name="twitter:image:alt" content="Content cover image">
    <meta name="twitter:site" content="SpringerLink">
    <meta name="twitter:description" content="Techniques to detect the emotions expressed in microblogs and social media posts have a wide range of applications including, detecting psychological disorders such as anxiety or depression in...">
    <meta name="citation_journal_title" content="International Journal of Data Science and Analytics">
    <meta name="citation_journal_abbrev" content="Int J Data Sci Anal">
    <meta name="citation_issn" content="2364-415X">
    <meta name="citation_issn" content="2364-4168">
    <meta name="citation_online_date" content="2018/02/09">
    <meta name="citation_article_type" content="Regular Paper">
    <meta property="og:title" content="Automatic emotion detection in text streams by analyzing Twitter data">
    <meta property="og:type" content="Article">
    <meta property="og:url" content="https://link.springer.com/article/10.1007/s41060-018-0096-z">
    <meta property="og:image" content="https://static-content.springer.com/cover/journal/41060/6/2.jpg">
    <meta property="og:site_name" content="SpringerLink">
    <meta property="og:description" content="Techniques to detect the emotions expressed in microblogs and social media posts have a wide range of applications including, detecting psychological disorders such as anxiety or depression in...">

        <title>Automatic emotion detection in text streams by analyzing Twitter data | SpringerLink</title>
        <link rel="canonical" href="https://link.springer.com/article/10.1007/s41060-018-0096-z">
        <link rel="shortcut icon" href="https://link.springer.com/springerlink-static/439917616/images/favicon/favicon.ico">
<link rel="icon" sizes="16x16 32x32 48x48" href="https://link.springer.com/springerlink-static/439917616/images/favicon/favicon.ico">
<link rel="icon" sizes="16x16" type="image/png" href="https://link.springer.com/springerlink-static/439917616/images/favicon/favicon-16x16.png">
<link rel="icon" sizes="32x32" type="image/png" href="https://link.springer.com/springerlink-static/439917616/images/favicon/favicon-32x32.png">
<link rel="icon" sizes="48x48" type="image/png" href="https://link.springer.com/springerlink-static/439917616/images/favicon/favicon-48x48.png">
<link rel="apple-touch-icon" href="https://link.springer.com/springerlink-static/439917616/images/favicon/app-icon-iphone@3x.png">
<link rel="apple-touch-icon" sizes="72x72" href="https://link.springer.com/springerlink-static/439917616/images/favicon/ic_launcher_hdpi.png">
<link rel="apple-touch-icon" sizes="76x76" href="https://link.springer.com/springerlink-static/439917616/images/favicon/app-icon-ipad.png">
<link rel="apple-touch-icon" sizes="114x114" href="https://link.springer.com/springerlink-static/439917616/images/favicon/app-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="https://link.springer.com/springerlink-static/439917616/images/favicon/app-icon-iphone@2x.png">
<link rel="apple-touch-icon" sizes="144x144" href="https://link.springer.com/springerlink-static/439917616/images/favicon/ic_launcher_xxhdpi.png">
<link rel="apple-touch-icon" sizes="152x152" href="https://link.springer.com/springerlink-static/439917616/images/favicon/app-icon-ipad@2x.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://link.springer.com/springerlink-static/439917616/images/favicon/app-icon-iphone@3x.png">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/springerlink-static/439917616/images/favicon/ic_launcher_xxhdpi.png">
        <link rel="dns-prefetch" href="https://fonts.gstatic.com/">
<link rel="dns-prefetch" href="https://fonts.googleapis.com/">
<link rel="dns-prefetch" href="https://google-analytics.com/">
<link rel="dns-prefetch" href="https://www.google-analytics.com/">
<link rel="dns-prefetch" href="https://www.googletagservices.com/">
<link rel="dns-prefetch" href="https://www.googletagmanager.com/">
<link rel="dns-prefetch" href="https://static-content.springer.com/">
        <link rel="stylesheet" href="basic.css" media="screen">
<link rel="stylesheet" href="styles.css" class="js-ctm" media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
<link rel="stylesheet" href="print.css" media="print">


            <script type="text/javascript" async="" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="https://cdn.krxd.net/userdata/get?pub=bd339c69-af54-4a21-b4f1-654bcfcd83ca&amp;kxfp=98ab5e67c4495fafb66af8f59092a4bff97db4dc&amp;kfuid=MJ2f6zZ4&amp;callback=Krux.ns.macmillan.kxjsonp_userdata"></script><script type="text/javascript" src="https://beacon.krxd.net/optout_check?callback=Krux.ns.macmillan.kxjsonp_optOutCheck"></script><script async="" src="/springerlink-static/439917616/js/mathJax.js"></script><script type="text/javascript" src="bd339c69-af54-4a21-b4f1-654bcfcd83ca"></script><script id="nativeads-plugin" type="text/javascript" async="" src="plugin.js"></script><script async="" src="controltag.10b38d7fdd1a9bfe7b2b04b85118d005"></script><script type="text/javascript" async="" src="KDqyaFZ_.js"></script><script type="text/javascript" async="" src="analytics.js"></script><script async="" src="gtm.js"></script><script type="text/javascript">
        window.Krux||((Krux=function(){Krux.q.push(arguments);}).q=[]);
        var dataLayer = [{
                    'GA Key':'UA-26408784-1',
                    'Features':["leaderboardadverts","abtesting"],
                    'Event Category':'Article',
                    'Open Access':'N',
                    'Labs':'Y',
                    'DOI':'10.1007\/s41060-018-0096-z',
                    'VG Wort Identifier':'pw-vgzm.415900-10.1007-s41060-018-0096-z',
                    'HasAccess':'Y',
                    'Full HTML':'Y',
                    'Has Body':'Y',
                    'Static Hash':'439917616',
                    'Has Preview':'N',
                    'user':{'license': {'businessPartnerID': ['3000197460', '3000201946'], 'businessPartnerIDString': '3000197460|3000201946'}},
                    'content':{'type': 'article', 'serial': {'eissn': '2364-4168', 'pissn': '2364-415X'}, 'category': {'pmc': {'primarySubject': 'Computer Science', 'primarySubjectCode': 'I', 'secondarySubjects': {'4': 'Computational Biology\/Bioinformatics', '5': 'Business Information Systems', '1': 'Data Mining and Knowledge Discovery', '2': 'Database Management', '3': 'Artificial Intelligence (incl. Robotics)'}, 'secondarySubjectCodes': {'4': 'I23050', '5': '522030', '1': 'I18030', '2': 'I18024', '3': 'I21017'}}, 'sucode': 'Computer Science'}},
                    'Access Type':'subscription',
                    'Page':'article',
                    'Bpids':'3000197460, 3000201946',
                    'Bpnames':'CAPES MEC, Universidade Tecnologica Federal do Parana',
                    'SubjectCodes':'SCI, SCI18030, SCI18024, SCI21017, SCI23050, SC522030',
                    'session':{'authentication': {'loginStatus': 'N'}, 'attributes': {'edition': 'academic'}},
                    'Keywords':'Supervised emotion learning, Real-time emotion detection, Twitter events analysis, Public emotion sensing, Text stream classification, Soft classification',
                    'Country':'BR',
                    'Journal Id':'41060',
                    'Journal Title':'International Journal of Data Science and Analytics',

                    'doi': "10.1007-s41060-018-0096-z",
                    'kwrd': ["Supervised_emotion_learning","Real-time_emotion_detection","Twitter_events_analysis","Public_emotion_sensing","Text_stream_classification","Soft_classification"],
                    'pmc': ["I","I18030","I18024","I21017","I23050","522030"],
                    'BPID': ["3000197460","3000201946"],
                    'ksg': Krux.segments,
                    'kuid': Krux.uid,

        }];
    </script>

<script type="text/javascript" src="jquery-3.js"></script>

        <script type="text/javascript" src="6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script><link type="text/css" href="optanon.css" rel="stylesheet"><style>#optanon ul#optanon-menu li { background-color: #F7FBFE !important }#optanon ul#optanon-menu li.menu-item-selected { background-color: #FFFFFF !important }#optanon #optanon-popup-wrapper .optanon-white-button-middle { background-color: #3365A4 !important }.optanon-alert-box-wrapper .optanon-alert-box-button-middle { background-color: #3365A4 !important; border-color: #3365A4 !important; }#optanon #optanon-popup-wrapper .optanon-white-button-middle a { color: #ffffff !important }.optanon-alert-box-wrapper .optanon-alert-box-button-middle a { color: #ffffff !important }#optanon #optanon-popup-bottom { background-color: #F7FBFE !important }#optanon.modern #optanon-popup-top, #optanon.modern #optanon-popup-body-left-shading { background-color: #F7FBFE !important }.optanon-alert-box-wrapper { background-color:#F7FBFE !important }.optanon-alert-box-wrapper .optanon-alert-box-bg p { color:#333333 !important }</style>

<script type="text/javascript">
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>

    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WCF9Z9');</script>

    <style>@font-face{font-family:'Source Sans Pro';font-weight:400;src:url(data:application/font-woff;base64,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) format('woff')}@font-face{font-family:'Source Sans Pro';font-weight:600;src:url(data:application/font-woff;base64,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) format('woff')}</style><link rel="preload" href="integrator.js"><script type="text/javascript" src="integrator.js"></script><link rel="preload" href="integrator_002.js"><script type="text/javascript" src="integrator_002.js"></script><script src="pubads_impl_240.js" async=""></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1px; bottom: 2px; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style></head>
    <body data-mediavoice-version="1.99.1"><div id="popup-references" class="u-composite-layer popup-base-theme" style="top:-60px;left:-60px;visibility:hidden;opacity:0;" aria-hidden="true" aria-label="popup"><svg class="popup-arrow" xmlns="http://www.w3.org/2000/svg" width="33.7" height="18.4" viewBox="0 0 33.7 18.4"><path class="fill" fill="#F7FBFE" d="M1.4 18.4h30.9l-15.5-16.9z"></path><path class="stroke" fill="#98BED7" d="M0 18.4h1.4l15.4-16.9 15.5 16.9h1.4l-16.9-18.4z"></path></svg><div class="popup-arrow popup-arrow-shadow icon--popup-arrow-shadow"></div><div class="popup__references"><div tabindex="-1" class="popup-base-theme__inner" data-component="SpringerLink-Popup-inner"></div></div><button tabindex="-1" class="popup-close" data-component="SpringerLink-Popup-close"><img alt="Close" src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2214%22%20height%3D%2214%22%3E%3Cpath%20fill%3D%22%23666%22%20d%3D%22M1.706.292A.996.996%200%200%200%20.294.294a1.002%201.002%200%200%200-.002%201.412L5.527%206.94.292%2012.177a.996.996%200%200%200%20.002%201.412c.39.39%201.026.385%201.412%200L6.94%208.354l5.236%205.235a.998.998%200%200%200%201.414-1.413L8.355%206.94l5.235-5.234a.996.996%200%200%200-.002-1.412%201.002%201.002%200%200%200-1.412-.002L6.94%205.527%201.707.292z%22%2F%3E%3C%2Fsvg%3E"></button></div><div id="popup-article-dates" class="u-composite-layer popup-base-theme" style="top:-60px;left:-60px;visibility:hidden;opacity:0;" aria-hidden="true" aria-label="popup"><svg class="popup-arrow" xmlns="http://www.w3.org/2000/svg" width="33.7" height="18.4" viewBox="0 0 33.7 18.4"><path class="fill" fill="#F7FBFE" d="M1.4 18.4h30.9l-15.5-16.9z"></path><path class="stroke" fill="#98BED7" d="M0 18.4h1.4l15.4-16.9 15.5 16.9h1.4l-16.9-18.4z"></path></svg><div class="popup-arrow popup-arrow-shadow icon--popup-arrow-shadow"></div><div class="popup__article-dates"><div tabindex="-1" class="popup-base-theme__inner" data-component="SpringerLink-Popup-inner"></div></div><button tabindex="-1" class="popup-close" data-component="SpringerLink-Popup-close"><img alt="Close" src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2214%22%20height%3D%2214%22%3E%3Cpath%20fill%3D%22%23666%22%20d%3D%22M1.706.292A.996.996%200%200%200%20.294.294a1.002%201.002%200%200%200-.002%201.412L5.527%206.94.292%2012.177a.996.996%200%200%200%20.002%201.412c.39.39%201.026.385%201.412%200L6.94%208.354l5.236%205.235a.998.998%200%200%200%201.414-1.413L8.355%206.94l5.235-5.234a.996.996%200%200%200-.002-1.412%201.002%201.002%200%200%200-1.412-.002L6.94%205.527%201.707.292z%22%2F%3E%3C%2Fsvg%3E"></button></div><div id="popup-search" class="u-composite-layer popup-search-theme" style="top:-60px;left:-60px;visibility:hidden;opacity:0;" aria-hidden="true" aria-label="popup"><svg class="popup-arrow" xmlns="http://www.w3.org/2000/svg" width="33.7" height="18.4" viewBox="0 0 33.7 18.4"><path class="fill" fill="#F7FBFE" d="M1.4 18.4h30.9l-15.5-16.9z"></path><path class="stroke" fill="#98BED7" d="M0 18.4h1.4l15.4-16.9 15.5 16.9h1.4l-16.9-18.4z"></path></svg><div class="popup-arrow popup-arrow-shadow icon--popup-arrow-shadow"></div><div class="popup__search"><div tabindex="-1" class="popup-base-theme__inner" data-component="SpringerLink-Popup-inner"></div></div><button tabindex="-1" class="popup-close" data-component="SpringerLink-Popup-close"><img alt="Close" src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2214%22%20height%3D%2214%22%3E%3Cpath%20fill%3D%22%23666%22%20d%3D%22M1.706.292A.996.996%200%200%200%20.294.294a1.002%201.002%200%200%200-.002%201.412L5.527%206.94.292%2012.177a.996.996%200%200%200%20.002%201.412c.39.39%201.026.385%201.412%200L6.94%208.354l5.236%205.235a.998.998%200%200%200%201.414-1.413L8.355%206.94l5.235-5.234a.996.996%200%200%200-.002-1.412%201.002%201.002%200%200%200-1.412-.002L6.94%205.527%201.707.292z%22%2F%3E%3C%2Fsvg%3E"></button></div>
        <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                      height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <div class="skip-to">
    <a class="skip-to__link pseudo-focus" href="#main-content">Skip to main content</a>
        <a class="skip-to__link skip-to__link--contents pseudo-focus" href="#article-contents">Skip to sections</a>
</div>
        <div class="page-wrapper">
            <noscript>
    <div class="nojs-banner u-interface">
        <p>This service is more advanced with JavaScript available, learn more at <a
                href="http://activatejavascript.org" target="_blank" rel="noopener">http://activatejavascript.org</a>
        </p>
    </div>
</noscript>
                    <div id="leaderboard" class="leaderboard u-hide" data-component="SpringerLink.GoogleAds" data-namespace="leaderboard">
            <div class="leaderboard__wrapper">
                <p class="leaderboard__label">Advertisement</p>
                <button class="leaderboard__hide" title="Hide this advertisement">Hide</button>
                <div id="doubleclick-leaderboard-ad" class="leaderboard__ad"><div id="google_ads_iframe_270604982/springerlink/41060/article_0__container__" style="border: 0pt none;"><iframe id="google_ads_iframe_270604982/springerlink/41060/article_0" title="3rd party ad content" name="google_ads_iframe_270604982/springerlink/41060/article_0" scrolling="no" marginwidth="0" marginheight="0" style="border: 0px none; vertical-align: bottom;" srcdoc="" width="728" frameborder="0" height="90"></iframe></div></div>
            </div>
        </div>

                <header id="header" class="header u-interface">
        <div class="header__content">
            <div class="header__menu-container">
                    <a id="logo" class="site-logo" href="https://link.springer.com/" title="Go to homepage">
                <div class="u-screenreader-only">SpringerLink</div>
    <svg class="site-logo__springer" width="148" height="30" role="img" focusable="false" aria-hidden="true">
        <image width="148" height="30" alt="" src="/springerlink-static/439917616/images/png/springerlink.png" xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/439917616/images/svg/springerlink.svg"></image>
    </svg>

    </a>


                    <nav id="search-container" class="u-inline-block">
                        <div class="search">
                            <div class="search__content">
                                <form class="u-form-single-input" action="/search" method="get" role="search">
    <label for="search-springerlinks">Search SpringerLink</label>
    <div class="u-relative">
        <input aria-label="Search SpringerLink" name="query" autocomplete="off" type="text">
        <input id="search-springerlink" class="u-hide-text" value="Submit" title="Submit" type="submit">
        <svg class="u-vertical-align-absolute" width="13" height="13" viewBox="222 151 13 13" version="1.1" xmlns="http://www.w3.org/2000/svg" focusable="false" aria-hidden="true" role="presentation">
            <path d="M227 159C228.7 159 230 157.7 230 156 230 154.3 228.7 153 227 153 225.3 153 224 154.3 224 156 224 157.7 225.3 159 227 159L227 159 227 159 227 159ZM230 160.1L231.1 159 233.9 161.7C234.2 162.1 234.2 162.6 233.9 162.9 233.6 163.2 233.1 163.2 232.7 162.9L230 160.1 230 160.1 230 160.1 230 160.1ZM227 161L227 161C224.2 161 222 158.8 222 156 222 153.2 224.2 151 227 151 229.8 151 232 153.2 232 156 232 158.8 229.8 161 227 161L227 161 227 161 227 161 227 161Z" stroke="none" fill-rule="evenodd"></path>
        </svg>
    </div>
</form>
                            </div>
                        </div>
                    </nav>

                    <nav class="nav-container u-interface">
    <div class="global-nav__wrapper">
        <div class="search-button">
            <a class="search-button__label" href="#search-container" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-search">
                <span class="search-button__title">Search</span><svg width="12" height="12" viewBox="222 151 12 12" version="1.1" xmlns="http://www.w3.org/2000/svg" focusable="false" aria-hidden="true" role="presentation">
                    <path d="M227 159C228.7 159 230 157.7 230 156 230 154.3 228.7 153 227 153 225.3 153 224 154.3 224 156 224 157.7 225.3 159 227 159L227 159 227 159 227 159ZM230 160.1L231.1 159 233.9 161.7C234.2 162.1 234.2 162.6 233.9 162.9 233.6 163.2 233.1 163.2 232.7 162.9L230 160.1 230 160.1 230 160.1 230 160.1ZM227 161L227 161C224.2 161 222 158.8 222 156 222 153.2 224.2 151 227 151 229.8 151 232 153.2 232 156 232 158.8 229.8 161 227 161L227 161 227 161 227 161 227 161Z" stroke="none" fill-rule="evenodd"></path>
                </svg>
            </a>
        </div>

        <ul class="global-nav" data-component="SpringerLink.Menu" data-title="Navigation menu" data-text="Menu">
            <li>
                <a href="https://link.springer.com/">
                    <span class="u-overflow-ellipsis">Home</span>
                </a>
            </li>
            <li>
                <a href="https://link.springer.com/contactus">
                    <span class="u-overflow-ellipsis">Contact us</span>
                </a>
            </li>

                <li class="global-nav__logged-out">
                    <a class="test-login-link" href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs41060-018-0096-z">
                        <span class="u-overflow-ellipsis">Log in</span>
                    </a>
                </li>

        </ul><div class="main-menu u-composite-layer c-button-dropdown c-button-dropdown--ghost" data-component="SV.Dropdown" data-namespace="Menu" aria-label="button with dropdown options" style=""><button id="button-Dropdown-Menu-dropdown" type="button" title="Navigation menu" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown-Menu-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">Menu</span><span class="c-button-dropdown__icon"></span></button><div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown-Menu-dropdown"><ul class="main-menu__content" data-role="button-dropdown__content"><li>
                <a href="https://link.springer.com/">
                    <span class="u-overflow-ellipsis">Home</span>
                </a>
            </li><li>
                <a href="https://link.springer.com/contactus">
                    <span class="u-overflow-ellipsis">Contact us</span>
                </a>
            </li><li class="global-nav__logged-out">
                    <a class="test-login-link" href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs41060-018-0096-z">
                        <span class="u-overflow-ellipsis">Log in</span>
                    </a>
                </li></ul></div></div>
    </div> 
</nav> 
            </div>

        </div>
    </header>

            

            <main id="main-content" class="main-wrapper" tabindex="-1">
                <div class="main-container uptodate-recommendations-on">
                    <aside class="main-sidebar-left">
                        <div class="main-sidebar-left__content">
                            <div class="cover-image test-cover" itemscope="">
                                    <a class="test-cover-link" href="https://link.springer.com/journal/41060">
        <span class="u-screenreader-only">International Journal of Data Science and Analytics</span>
        <img class="test-cover-image" src="2.jpg" itemprop="image" alt="">
    </a>


                            </div>
                        </div>
                    </aside>
                    <div class="main-body" data-role="NavigationContainer">
                                <div class="cta-button-container cta-button-container--top cta-button-container--stacked u-mb-16 u-hide-two-col">
                    <div>
            <a href="https://link.springer.com/content/pdf/10.1007%2Fs41060-018-0096-z.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right gtm-pdf-link" title="Download this article in PDF format" rel="noopener">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"></path></g></g></g></svg>
                <span class="hide-text-small">Download</span>
                <span>PDF</span>
            </a>
        </div>

        </div>



                        <article class="main-body__content">
                            <div xmlns="http://www.w3.org/1999/xhtml" class="FulltextWrapper"><div class="ArticleHeader main-context"><div id="enumeration" class="enumeration"><p><a href="https://link.springer.com/journal/41060" title="International Journal of Data Science and Analytics"><span class="JournalTitle">International Journal of Data Science and Analytics</span></a></p><p class="icon--meta-keyline-before"><span class="ArticleCitation_Pages"> pp 1–17</span><span class="u-inline-block u-ml-4"> | <a class="gtm-cite-link" href="#citeas">Cite as</a></span></p></div><div class="MainTitleSection"><h1 class="ArticleTitle" lang="en">Automatic emotion detection in text streams by analyzing Twitter data</h1></div><div class="authors u-clearfix authors--enhanced" data-component="SpringerLink.Authors"><ul class="u-interface u-inline-list authors__title" data-role="AuthorsNavigation"><li><a href="#authors" class="gtm-tab-authors selected">Authors</a></li><li><a href="#authorsandaffiliations" class="gtm-tab-authorsandaffiliations">Authors and affiliations</a></li></ul><span class="marker" style="width: 160px;"></span><div class="authors__list" data-role="AuthorsList" id="authors" tabindex="-1"><ul class="test-contributor-names"><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Maryam&nbsp;Hasan</span><span class="author-information"><span class="authors__contact"><a href="mailto:mhasan@wpi.edu" title="mhasan@wpi.edu" itemprop="email" class="gtm-email-author"><img src="email.svg" alt="Email author" width="24" height="24"></a></span></span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Elke&nbsp;Rundensteiner</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Emmanuel&nbsp;Agu</span></li></ul></div><div class="authors__affiliations" id="authorsandaffiliations" tabindex="-1"><div class="authors-affiliations u-interface"><ul class="test-contributor-names"><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Maryam&nbsp;Hasan</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul><span class="author-information"><span class="author-information__contact u-icon-before icon--email-before"><a href="mailto:mhasan@wpi.edu" title="mhasan@wpi.edu" itemprop="email" class="gtm-email-author" tabindex="-1">Email author</a></span></span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Elke&nbsp;Rundensteiner</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Emmanuel&nbsp;Agu</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li></ul><ol class="test-affiliations"><li class="affiliation" data-test="affiliation-1" data-affiliation-highlight="affiliation-1" itemscope="" itemtype="http://schema.org/Organization"><span class="affiliation__count">1.</span><span class="affiliation__item"><span itemprop="department" class="affiliation__department">Computer Science Department</span><span itemprop="name" class="affiliation__name">Worcester Polytechnic Institute</span><span itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress" class="affiliation__address"><span itemprop="addressRegion" class="affiliation__city">Worcester</span><span itemprop="addressCountry" class="affiliation__country">USA</span></span></span></li></ol></div></div></div><div class="main-context__container" data-component="SpringerLink.ArticleMetrics"><div class="main-context__column"><span><span class="test-render-category">Regular Paper</span></span><div class="article-dates article-dates--enhanced" data-component="SpringerLink.ArticleDates"><div class="article-dates__entry"><span class="article-dates__label">First Online: </span><span class="article-dates__first-online"><a href="#article-dates-history" class="gtm-first-online" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-article-dates">09 February 2018</a></span></div><div class="article-dates__history" id="article-dates-history"><div class="article-dates__entry"><span class="article-dates__label">Received: </span><span><time datetime="2017-03-14">14 March 2017</time></span></div><div class="article-dates__entry"><span class="article-dates__label">Accepted: </span><span><time datetime="2018-01-16">16 January 2018</time></span></div></div></div></div><div class="main-context__column">    <ul id="book-metrics" class="article-metrics u-sansSerif">
            <li class="article-metrics__item">
                     <span class="article-metrics__views">585</span>
                     <span class="article-metrics__label">Downloads</span>
            </li>
    </ul>
</div></div></div><section class="Abstract" id="Abs1" tabindex="-1" lang="en"><h2 class="Heading">Abstract</h2><p id="Par1" class="Para">Techniques
 to detect the emotions expressed in microblogs and social media posts 
have a wide range of applications including, detecting psychological 
disorders such as anxiety or depression in individuals or measuring the 
public mood of a community. A major challenge for automated emotion 
detection is that emotions are subjective concepts with fuzzy boundaries
 and with variations in expression and perception. To address this 
issue, a dimensional model of affect is utilized to define emotion 
classes. Further, a soft classification approach is proposed to measure 
the probability of assigning a message to each emotion class. We develop
 and evaluate a supervised learning system to automatically classify 
emotion in text stream messages. Our approach includes two main tasks: 
an offline training task and an online classification task. The first 
task creates models to classify emotion in text messages. For the second
 task, we develop a two-stage framework called EmotexStream to classify 
live streams of text messages for the real-time emotion tracking. 
Moreover, we propose an online method to measure public emotion and 
detect emotion burst moments in live text streams.</p></section><div class="KeywordGroup" lang="en"><h2 class="Heading">Keywords</h2><span class="Keyword">Supervised emotion learning&nbsp;</span><span class="Keyword">Real-time emotion detection&nbsp;</span><span class="Keyword">Twitter events analysis&nbsp;</span><span class="Keyword">Public emotion sensing&nbsp;</span><span class="Keyword">Text stream classification&nbsp;</span><span class="Keyword">Soft classification&nbsp;</span></div><div class="article-actions--inline" id="article-actions--inline" data-component="article-actions--inline"><div class="citations u-interface c-button-dropdown" data-component="SV.Dropdown" data-namespace="citations--inline" aria-label="button with dropdown options">
        <button id="button-Dropdown-citations--inline-dropdown" type="button" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown-citations--inline-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</span><span class="c-button-dropdown__icon"></span></button>
<div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown-citations--inline-dropdown"><ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" class="gtm-cite-dropdown">How to cite?</a>
    </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=refman&amp;flavour=citation" title="Download this article's citation as a .RIS file" class="gtm-export-citation" data-gtmlabel="RIS">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=endnote&amp;flavour=citation" title="Download this article's citation as a .ENW file" class="gtm-export-citation" data-gtmlabel="ENW">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=bibtex&amp;flavour=citation" title="Download this article's citation as a .BIB file" class="gtm-export-citation" data-gtmlabel="BIB">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul></div>
    </div></div><div id="body"><section id="Sec1" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">1 </span>Introduction<span class="section-icon"></span></h2><div class="content"><p id="Par2" class="Para">Emotion
 plays a critical role in our daily performance affecting many aspects 
of our lives including social interaction, behavior, attitude, and 
decision-making [<span class="CitationRef"><a href="#CR1" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">1</a></span>].
 Understanding human emotion patterns and how the people feel plays an 
essential role in various applications such as public health and safety,
 emergency response, and urban planning.</p><p id="Par3" class="Para">Text
 is a particularly important source of data for detecting emotion 
because the bulk of textual data ranging from microblogs, emails, to SMS
 messages on a smart phone that has become increasingly available. The 
rapid growth of emotion-rich textual data makes a necessity to automate 
identification and analysis of people’s emotion expressed in text [<span class="CitationRef"><a href="#CR1" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">1</a></span>].</p><section id="Sec2" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">1.1 </span>Emotion in social networks</h3><p id="Par4" class="Para">Social
 networks and microblogging tools (e.g., Twitter, Facebook) are 
increasingly used by individuals to share their opinions and feelings in
 the form of short text messages (e.g., texts about normal life and 
opinion on current issues and events) [<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>].
 These messages (commonly known as tweets or microblogs) may also 
contain indicators of emotions of individuals such as happiness, 
anxiety, and depression. In fact, social networks contain a large corpus
 of public real-time data that is rich with emotional content. This 
makes them appropriate data sources for behavioral studies, especially 
for studying emotions of individuals as well as larger populations. 
Therefore, social networks such as Twitter provide valuable information 
to observe crowd emotion and behavior and study a variety of human 
behavior and characteristics [<span class="CitationRef"><a href="#CR3" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">3</a></span>].</p><p id="Par5" class="Para">Increasing evidence suggests that emotion detection and screening built around social media [<span class="CitationRef"><a href="#CR4" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">4</a></span>, <span class="CitationRef"><a href="#CR5" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">5</a></span>, <span class="CitationRef"><a href="#CR6" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">6</a></span>, <span class="CitationRef"><a href="#CR7" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">7</a></span>]
 will be effective in many applications. In particular, Twitter provides
 valuable opportunities to observe public mood and behavior. The 
development of robust textual emotion sensing technologies promises to 
have a substantial impact on public and individual health and urban 
planning. Such emotion mining tools, once available, could potentially 
be employed in a large variety of applications ranging from population 
level studies of emotions, the provision of mental health counseling 
services over social media, and other emotion management applications. 
The census bureau and other polling organizations may be able to use the
 emotion mining technology to estimate the percentage of people in a 
community experiencing certain emotions and correlate this with current 
events and various other aspects of urban living conditions. This type 
of technology can also enhance early outbreak warning for public health 
authorities so that a rapid action can take place [<span class="CitationRef"><a href="#CR8" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">8</a></span>].</p><p id="Par6" class="Para">Moreover,
 the emotion mining tools could also be used by counseling agencies to 
monitor emotional states of individuals or to recognize anxiety or 
systemic stressors of populations [<span class="CitationRef"><a href="#CR9" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">9</a></span>].
 For instance, university counseling centers could be warned early about
 distressed students that may require further personal assessment.</p></section><section id="Sec3" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">1.2 </span>Challenges of detecting emotion in social networks</h3><div id="Par7" class="Para">Our
 goal is to detect emotion in social networks by classifying text 
messages into several classes of emotion. To achieve this goal, the 
major challenges discussed below must be tackled:<div class="UnorderedList"><ul class="UnorderedListMarkDash"><li> <p id="Par8" class="Para"><em class="EmphasisTypeItalic ">Casual style of microblog data</em>
 Text messages are usually written in a casual style. They may contain 
numerous grammatical and spelling errors along with slang words. While 
the use of informal language and short messages has been previously 
studied in the context of sentiment analysis [<span class="CitationRef"><a href="#CR10" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">10</a></span>, <span class="CitationRef"><a href="#CR11" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">11</a></span>, <span class="CitationRef"><a href="#CR12" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">12</a></span>, <span class="CitationRef"><a href="#CR13" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">13</a></span>], the use of such language in the context of emotion mining has been much less studied.</p> </li><li> <p id="Par9" class="Para"><em class="EmphasisTypeItalic ">Semantic ambiguity of text messages </em>
 Human emotions as well as the texts expressing them are ambiguous and 
subjective. This makes it difficult to accurately infer and interpret 
the author’s emotional states.</p> </li><li> <p id="Par10" class="Para"><em class="EmphasisTypeItalic ">Fuzzy boundaries of emotion classes </em>
 Emotions are complex concepts with fuzzy boundaries and with variations
 in expression. Thus, modeling and analyzing the human affective 
behavior is a challenge for automated systems [<span class="CitationRef"><a href="#CR14" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">14</a></span>].</p> </li><li> <p id="Par11" class="Para"><em class="EmphasisTypeItalic ">Difficulty of emotion annotation </em>
 In order to train an automatic classifier, supervised learning methods 
require labeled data. It would be time-consuming, tedious and 
labor-intensive to manually label text messages for the purpose of 
training a classifier for emotion detection.</p> </li><li> <p id="Par12" class="Para"><em class="EmphasisTypeItalic ">Numerous topics and emotional states </em>
 The large breadth of topics discussed on social networks makes it 
challenging to manually create a comprehensive corpus of labeled data 
that covers all possible emotional states.</p> </li><li> <p id="Par13" class="Para"><em class="EmphasisTypeItalic ">Inconsistent annotators </em>
 While crowdsourcing emotion labels have been explored, human annotators
 may not be reliable. A human annotator’s judgement of the emotions in a
 text message is likely to be subjective and inconsistent. Consequently,
 different annotators may classify the same text message into different 
emotion classes, as confirmed by our user study in Sect.&nbsp;<span class="InternalRef"><a href="#Sec24">5</a></span>.</p> </li></ul></div></div></section><section id="Sec4" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">1.3 </span>Proposed approach to detect emotion in text stream messages</h3><p id="Par14" class="Para">To
 detect and analyze the emotion expressed in text messages, we develop a
 supervised machine learning approach to automatically classify the 
messages into their emotional states. Our approach includes two main 
tasks: an offline training task and an online classification task. 
During the first task, we collect a large dataset of emotion-labeled 
messages from Twitter. The messages are preprocessed and used to train 
emotion classification models. The second task utilizes the created 
models to classify live streams of tweets for real-time emotion tracking
 in a geographic location (e.g., a city). For the second task we develop
 a two-stage framework called EmotexStream. A binary classifier is 
created in the first stage to separate tweets with explicit emotion from
 tweets without emotion. The second stage utilizes our emotion 
classification models for a fine-grained (i.e., multi-class) emotion 
classification of tweets with explicit emotion.</p><p id="Par15" class="Para">While
 supervised learning methods achieve high accuracy, they require a large
 corpus of texts labeled with the emotion classes they express [<span class="CitationRef"><a href="#CR15" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">15</a></span>].
 Prior works have mostly utilized manually labeled data. Crowdsourcing 
is a popular approach for labeling data, in which humans manually infer 
and then annotate each message with the emotion it expresses [<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>, <span class="CitationRef"><a href="#CR4" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">4</a></span>, <span class="CitationRef"><a href="#CR5" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">5</a></span>].
 Crowdsourcing tools such as Amazon’s mechanical turk facilitate access 
to manual data labelers. However, manually labeling of Twitter messages 
with the emotions they express faces numerous challenges as previously 
outlined, including the inconsistency of human labelers (See Sect.&nbsp;<span class="InternalRef"><a href="#Sec3">1.2</a></span>).
 Therefore, instead we investigate using hashtags (user-selected 
keywords) in Twitter messages as viable alternative to manual labeling. 
The use of hashtags in tweets is very common. Twitter contains millions 
of different user-defined hashtags. Wang et al. showed that 14.6% of 
tweets in a sample of 0.6 million tweets had at least one hashtag [<span class="CitationRef"><a href="#CR15" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">15</a></span>].
 We make the observation that in many cases the hashtag keywords may 
correspond to the author’s own classification of the main topics of 
their message. A study by Wang et al. showed that emotion hashtags in 
about 93% of their sample tweets are relevant and reflect the writer’s 
emotion [<span class="CitationRef"><a href="#CR1" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">1</a></span>].</p><p id="Par16" class="Para">We
 thus conjecture that emotional hashtags inserted by authors indicate 
the main emotion expressed by their Twitter message. For example, a 
tweet with the hashtag "#depressed" can be interpreted as expressing a 
depressed emotion, while a tweet containing the hashtag "#excited" as 
expressing excitement. By using embedded hashtags to automatically label
 the emotions expressed in text messages, we build a large corpus of 
labeled messages to train classifiers with no manual effort. This 
approach overcomes the need for manual labeling and yields a completely 
automatic scheme for labeling a massive repository of Twitter messages. 
This strategy could equally be applied in other mining applications 
where labeling is required.</p><p id="Par17" class="Para">Another 
challenge for automated emotion detection is that emotions are complex 
concepts with fuzzy boundaries and with individual variations in 
expression and perception. We address this issue using a two-pronged 
approach. First, we define the emotion classes based on the Circumplex 
model of affect [<span class="CitationRef"><a href="#CR16" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">16</a></span>].
 Instead of a small number of discrete categories, this model defines 
the emotion in terms of latent dimensions (e.g., arousal and valence). 
Second, a soft (i.e., fuzzy) classification approach is proposed, which 
classifies each message into multiple emotion classes with different 
probabilities (i.e., weights), instead of forcing each message to be in 
one emotion class only.</p><div id="Par18" class="Para">This paper is an extension of our preliminary results published in [<span class="CitationRef"><a href="#CR9" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">9</a></span>, <span class="CitationRef"><a href="#CR17" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">17</a></span>].
 We first studied supervised learning to classify emotion in texts, and 
the idea of considering Twitter hashtags as automatic emotion labels [<span class="CitationRef"><a href="#CR17" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">17</a></span>].
 We then validated the effectiveness of utilizing our hashtag-based 
labeling concept through two user studies, one with psychology experts 
and the other with the general crowd [<span class="CitationRef"><a href="#CR9" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">9</a></span>].
 In this journal paper, we now extend our previous system and develop a 
two-stage framework, called EmotexStream that performs online emotion 
analysis on live streams of text messages. The first stage of 
EmotexStream separates tweets with explicit emotion from tweets without 
any emotion using a binary classifier. The second stage classifies the 
tweets with explicit emotion into fine-grained emotion classes. 
Furthermore, we deploy EmotexStream to measure public emotion and 
investigate its temporal distribution during major public events in a 
geographic location (e.g., a city). For this, we develop an online 
method to detect emotion bursts in live stream of messages. In 
particular, this paper makes the following major contributions:<div class="UnorderedList"><ul class="UnorderedListMarkDash"><li> <p id="Par19" class="Para">We
 develop the Emotex system to automatically classify emotion expressed 
in text messages. We evaluate the classification accuracy of Emotex by 
comparing it with the accuracy of the lexical approach.</p> </li><li> <p id="Par20" class="Para">We
 utilize a soft (fuzzy) classification approach to measure the 
probability of assigning a message into each emotion class, in addition 
to a typical classification that simply assigns one single emotion class
 to each text message in a deterministic manner.</p> </li><li> <p id="Par21" class="Para">We
 run ample experiments using offline data to train classification models
 and evaluate Emotex system and report its soft and hard classification 
results.</p> </li><li> <p id="Par22" class="Para">We develop a two-stage
 framework called EmotexSream to classify live streams of tweets in the 
wild. The first stage separates tweets with explicit emotion from tweets
 without any emotion using a binary classifier. The second stage deploys
 Emotex to conduct a fine-grained emotion classification on tweets with 
explicit emotion.</p> </li><li> <p id="Par23" class="Para">We evaluate EmotexStream framework by running some experiments using live and unfiltered streams of tweets in the wild.</p> </li><li> <p id="Par24" class="Para">We
 propose an online method to measure public emotion and detect 
emotion-intensive moments, which can be used for real-time emotion 
tracking.</p> </li></ul></div>The rest of the paper is organized as follows. Section&nbsp;<span class="InternalRef"><a href="#Sec5">2</a></span>
 describes different models of emotion. Details of our proposed methods 
to detect and analyze emotion in text streams are illustrated in 
Sect.&nbsp;<span class="InternalRef"><a href="#Sec8">3</a></span>. Section&nbsp;<span class="InternalRef"><a href="#Sec17">4</a></span>
 includes our extensive experimental results about different tasks of 
our approach. Evaluating our labeling method is described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec24">5</a></span>. Section&nbsp;<span class="InternalRef"><a href="#Sec27">6</a></span> includes related work on emotion detection in text. Finally, we conclude our paper in Sect.&nbsp;<span class="InternalRef"><a href="#Sec30">7</a></span>.</div></section></div></section><section id="Sec5" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">2 </span>Models of emotion<span class="section-icon"></span></h2><div class="content"><p id="Par25" class="Para">The emotion models have mainly been studied based on two fundamental approaches: basic emotions model and dimensional model [<span class="CitationRef"><a href="#CR18" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">18</a></span>].</p><section id="Sec6" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">2.1 </span>Basic emotions model</h3><p id="Par26" class="Para">According to the <em class="EmphasisTypeItalic ">basic emotion model</em> humans have a small set of basic emotions, which are discrete and detectable by an individual’s verbal/nonverbal expression [<span class="CitationRef"><a href="#CR19" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">19</a></span>].
 Researchers have attempted to identify a number of basic emotions which
 are universal among all people and differ one from another in important
 ways. A popular example is a cross-cultural study by Ekman et al. [<span class="CitationRef"><a href="#CR19" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">19</a></span>],
 in which they concluded that six basic emotions are anger, disgust, 
fear, happiness, sadness, and surprise. Subsequently, many works in the 
field of emotion detection in texts have been conducted based on this 
basic emotion model [<span class="CitationRef"><a href="#CR20" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">20</a></span>, <span class="CitationRef"><a href="#CR21" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">21</a></span>, <span class="CitationRef"><a href="#CR22" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">22</a></span>, <span class="CitationRef"><a href="#CR23" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">23</a></span>].
 For example, Bollen et al. extracted six dimensions of affect including
 tension, depression, anger, vigor, fatigue, confusion from Twitter to 
model public emotion [<span class="CitationRef"><a href="#CR20" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">20</a></span>].</p><p id="Par27" class="Para">However,
 the main drawback of such basic emotion models is that there is no 
consensus among theorists on which human emotions should be included in 
the basic set of emotions. Moreover, the basic emotions doesn’t cover 
all the variety of emotion expressed by humans in texts. People usually 
express nonbasic, subtle and complex emotions. This problem can’t be 
resolved by using a finer granularity, because the emotions expressed in
 texts are ambiguous and subjective. For instance, “surprise” as a basic
 emotion can indicate negative, neutral or positive valence. Also using a
 finer granularity of emotion makes the distinction of one emotion from 
another an issue in emotion classification. Therefore, a small number of
 discrete emotions may not reflect the complexity of the affective 
states conveyed by humans [<span class="CitationRef"><a href="#CR18" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">18</a></span>].</p></section><section id="Sec7" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">2.2 </span>Dimensional model of emotion</h3><p id="Par28" class="Para">In contrast to the basic emotion model which defines discrete emotions, the <em class="EmphasisTypeItalic ">dimensional model</em>
 defines emotion on a continuous scale. This model characterizes human 
emotions by defining their positions along two or three dimensions. Many
 dimensional models incorporate two fundamental dimensions of emotions 
namely, valence (i.e., pleasure) and arousal (i.e., activation or 
stimulation) [<span class="CitationRef"><a href="#CR18" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">18</a></span>].</p><p id="Par29" class="Para">The most widely used dimensional model is the Circumplex model of affect proposed by Russell [<span class="CitationRef"><a href="#CR16" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">16</a></span>]. As shown in Fig.&nbsp;<span class="InternalRef"><a href="#Fig1">1</a></span>,
 the model suggests that emotions are distributed in a two-dimensional 
circular space, containing valence and arousal dimensions. The 
horizontal axis presents pleasure and measures how positive or negative a
 person feels. The vertical axis presents activation and measures if one
 is likely to take an action.</p><div id="Par30" class="Para">Although 
the Circumplex model is a well-known model and has long been validated 
and studied by emotion and cognition theorists, it has rarely been used 
by computational approaches for automatic emotion analysis in texts [<span class="CitationRef"><a href="#CR24" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">24</a></span>].
 In our emotion classification work, we utilize the Circumplex model by 
considering four major classes of emotion: Happy-Active, Happy-Inactive,
 Unhappy-Active, and Unhappy-Inactive. As shown in Fig.&nbsp;<span class="InternalRef"><a href="#Fig1">1</a></span>,
 the defined four classes of emotion are distinct, yet describe a wide 
range of emotional states as they cover four dimensions of the 
Circumplex model.<figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig1_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig1_HTML.gif" alt="Fig. 1"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1</span> <p class="SimplePara">Circumplex model of affect including 28 affect words by [<span class="CitationRef"><a href="#CR16" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">16</a></span>]</p> </div></figcaption></figure></div></section></div></section><section id="Sec8" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">3 </span>Proposed approach to detect emotion in text stream messages<span class="section-icon"></span></h2><div class="content"><p id="Par31" class="Para">To
 detect and analyze the emotion expressed in text stream messages we 
develop a supervised machine learning approach to automatically classify
 the messages into their emotional states. Our approach includes two 
main tasks: an offline training task and an online classification task. 
The first task develops a system called Emotex to create models for 
classifying emotion. Emotex collects a large dataset of emotion-labeled 
messages from Twitter. The messages are then preprocessed and converted 
into the feature vectors to train emotion classification models. The 
second task utilizes the created models to classify live streams of 
tweets for real-time emotion tracking. For this task, we develop a 
two-stage framework called EmotexStream. EmotexStream creates a binary 
classifier to separate tweets with explicit emotion from tweets without 
emotion. Then it utilizes our emotion classification models for a 
fine-grained emotion classification of tweets with explicit emotion.</p><p id="Par32" class="Para">Furthermore,
 we develop an online method to measure public emotion and detect 
emotion bursts in live streams of tweets posted in a geographic 
location. Details of the proposed tasks and methods are given in the 
following.</p><section id="Sec9" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">3.1 </span>Emotex: a supervised learning model to classify emotion in text messages</h3><div id="Par33" class="Para">We
 develop a supervised learning system called Emotex to classify texts 
into our defined classes of emotion described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec7">2.2</a></span>.
 Emotex is developed as an offline system and includes three parts. The 
first part involves data acquisition and collecting training data. The 
second part is related to feature selection and the third part creates 
the emotion classifiers. Figure&nbsp;<span class="InternalRef"><a href="#Fig2">2</a></span>
 shows the process flow of Emotex. First, we collect Twitter messages 
and annotate them with emotion labels to develop a dataset to train 
classification models. Second, we select certain features and convert 
each tweet in the training set into a feature vector. We then utilize 
the feature vectors annotated with emotion labels to train classifiers. 
The result is a model that can classify unlabeled messages into an 
appropriate emotion class. This section now describes each part of the 
Emotex pipeline.<figure class="Figure" id="Fig2"><div class="MediaObject" id="MO2"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig2_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig2_HTML.gif" alt="Fig. 2"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 2</span> <p class="SimplePara">Model of emotex</p> </div></figcaption></figure></div><section id="Sec10" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading"><span class="HeadingNumber">3.1.1 </span>Collecting labeled data</h4><p id="Par34" class="Para">We
 utilize hashtags to automatically annotate text messages with emotion 
and build a large corpus of emotion-labeled messages. These messages 
then serve as a labeled dataset for training classifiers. Figure&nbsp;<span class="InternalRef"><a href="#Fig3">3</a></span>
 shows the steps of collecting labeled data. We first need to define a 
list of emotion hashtags to collect emotion-labeled messages. For this, 
we exploit the set of 28 affect words from the Circumplex model (as 
shown in Fig.&nbsp;<span class="InternalRef"><a href="#Fig1">1</a></span>) as the initial set of keywords and extend them using WordNet’s synsets [<span class="CitationRef"><a href="#CR25" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">25</a></span>].
 We use the extended set of keywords to detect emotion hashtags. Then, 
we collect tweets which contain one or more hashtags that fall in our 
defined list of emotion hashtags. This way we assure that we have tweets
 labeled with our defined emotion classes described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec7">2.2</a></span>.
 Hashtags that are directly interleaved in the actual tweet text are 
more likely to represent a part of the content of the tweet itself [<span class="CitationRef"><a href="#CR1" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">1</a></span>, <span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>].
 Therefore, we only collect the tweets which contain the emotion 
hashtags at the end. We also don’t collect retweets, which begin with 
the“RT” keyword.</p><div id="Par35" class="Para">Using this approach we 
are able to collect a large number of tweets with various emotion 
hashtags with no manual effort. Another major advantage of this approach
 is that it gives us direct access to the author’s own intended 
emotional state, instead of relying on the possibly inconsistent and 
inaccurate interpretations of third-party annotators about what an 
author of a tweet may have felt. We utilize Twitter’s stream API to 
automatically collect tweets and filter them by emotion hashtags. After 
collecting the same number of tweets for each emotion class, the labeled
 tweets are then preprocessed to mitigate misspellings and casual 
language used in Twitter using the following rules:<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO3"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig3_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig3_HTML.gif" alt="Fig. 3"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 3</span> <p class="SimplePara">Model of labeled data collection</p> </div></figcaption></figure><div class="UnorderedList"><ul class="UnorderedListMarkDash"><li> <p id="Par36" class="Para"><em class="EmphasisTypeItalic ">User IDs and URLs </em>
 In addition to the message body, tweets contain the ID of the user and 
URL links. They are marked separately for later processing.</p> </li><li> <p id="Par37" class="Para"><em class="EmphasisTypeItalic ">Text normalization </em>
 Tweets often contain abbreviations and informal expressions. All 
abbreviations are expanded (e.g., “won’t” to “will not"). Words with 
repeated letters are common. Any letter occurring more than two times 
consecutively is replaced with one occurrence. For instance, the word 
“happyyyy” will be changed into “happy”.</p> </li><li> <p id="Par38" class="Para"><em class="EmphasisTypeItalic ">Conflicting hashtags </em>
 Some tweets may contain hashtags from different emotion classes. For 
example tweet "Got a job interview with At&amp;t...#nervous #happy.”, 
includes the hashtag #nervous from Unhappy-Active class and the tag 
#happy from Happy-Active class. Tweets with conflicting hashtags are 
removed from our labeled data, as they illustrate a mixture of different
 emotions.</p> </li><li> <p id="Par39" class="Para"><em class="EmphasisTypeItalic ">Hashtags at end of tweets </em>
 We consider emotion hashtags at the end of the tweets as emotion 
labels. Therefore, as part of preprocessing, emotion hashtags are 
stripped off from the end of tweets. For instance, the tags 
“#disappointed” and “#sad” are removed from the tweet “No one wants to 
turn up today. #disappointed #sad”. Hashtags that are directly 
interleaved in the actual tweet text represent part of the content of 
the tweet and are not removed.</p> </li></ul></div></div></section><section id="Sec11" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading"><span class="HeadingNumber">3.1.2 </span>Feature selection for capturing emotion</h4><p id="Par40" class="Para">In
 order to train a classifier from labeled data, we represent each tweet 
as a vector of numerical features. Thus, a set of features that 
illustrate the emotion expressed by each tweet is needed. Feature 
selection plays an important role in emotion classification. We 
investigate the effectiveness of different features. We use single 
words, also known as unigrams, as the baseline features for comparison. 
Other features explored include emoticons, punctuations, and negations.</p><section id="Sec12" tabindex="-1" class="Section4 RenderAsSection4"><h5 class="Heading"><span class="HeadingNumber">3.1.2.1 </span>Unigram Features:</h5><p id="Par41" class="Para">Unigrams or single word features have been widely used to capture sentiment or emotion in text [<span class="CitationRef"><a href="#CR10" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">10</a></span>, <span class="CitationRef"><a href="#CR11" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">11</a></span>, <span class="CitationRef"><a href="#CR21" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">21</a></span>]. Let <span class="InlineEquation" id="IEq1">\(\{f_1, f_2,\ldots , f_m\}\)</span> be our predefined set of unigrams that can appear in a tweet. Each feature <span class="InlineEquation" id="IEq2">\(f_{i}\)</span>
 in this vector is a word occurring in the list of tweets in our 
dataset. However, with the large breadth of topics discussed in 
microblogs, the number of words in our input dataset tends to be 
extremely large. Thus, the feature vector of each message would become 
excessively large and sparse (i.e., most features will have a value of 
zero). To overcome the problem of this high-dimensional feature space, 
we select an emotion lexicon as the set of unigram features. As a 
result, our feature space only contains the emotional words from the 
emotion lexicons instead of all the words in our training dataset. This 
method reduces the size of feature space dramatically, with minimal loss
 of informative terms.</p><p id="Par42" class="Para">We use different emotion lexicons in our system, including ANEW lexicon (Affective Norms for English Words) [<span class="CitationRef"><a href="#CR26" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">26</a></span>], LIWC dictionary (Linguistic Inquiry and Word Count) [<span class="CitationRef"><a href="#CR27" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">27</a></span>], and AFINN [<span class="CitationRef"><a href="#CR28" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">28</a></span>].
 LIWC is a dictionary of several thousands words and prefixes, grouped 
into psychological categories. We use emotion-indicative categories 
including positive emotions, negative emotions, anxiety, anger, sadness,
 and negations. ANEW lexicon contains 2477 affect words, each rated for 
its valence and arousal on a 1–9 scale. AFINN was created to include a 
new word list specifically for microblogs.</p><p id="Par43" class="Para"><em class="EmphasisTypeItalic ">Emoticon features</em>&nbsp;Other
 than unigrams, emoticons are also likely to be useful features to 
classify emotion in texts as they are textual portrayals of emotion in 
the form of icons. Emoticons tend to be widely used in sentiment 
analysis. Go et al. and Pak et al. [<span class="CitationRef"><a href="#CR10" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">10</a></span>, <span class="CitationRef"><a href="#CR11" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">11</a></span>]
 used the western-style emoticons to collect labeled data. There are 
many emoticons to express happy, sad, angry or sleepy emotion. The list 
of emoticons that we use can be found in our paper [<span class="CitationRef"><a href="#CR17" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">17</a></span>].</p><p id="Par44" class="Para"><em class="EmphasisTypeItalic ">Punctuation features</em>&nbsp;Other
 features potentially helpful for emotion detection are punctuations 
(i.e., question mark, exclamation mark and combination of them). Users 
often use exclamation marks when they want to express their strong 
feelings. For instance, the tweet “I lost 4lb in 3 days!!” expresses 
strong happiness and the tweet “we’re in december, which means one month
 until EXAMS!!!” represents a high level of stress. The exclamation mark
 is sometimes used in conjunction with the question mark, which in many 
cases appears to convey a sense of astonishment. For example the tweet 
“You don’t even offer high speed, yet you keep overcharging me?!” 
indicates an astonished and annoyed feeling.</p><p id="Par45" class="Para"><em class="EmphasisTypeItalic ">Negation features</em>&nbsp;As
 our last feature, we select negation to address errors caused by tweets
 that contain negated phrases like “not sad” or “not happy”. For example
 the tweet, “I’m not happy about this trade.” should not be classified 
as a happy tweet, even though it has a happy unigram. To tackle this 
problem we define negation as a separate feature. We select the list of 
phrases indicating negation from the LIWC dictionary.</p></section></section><section id="Sec13" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading"><span class="HeadingNumber">3.1.3 </span>Classifier selection for emotion detection </h4><p id="Par46" class="Para">A
 number of classification methods have been applied for text 
categorization, including Bayesian classifiers, decision trees, nearest 
neighbor classifiers, and support vector machines (SVM). To classify 
emotion we explored three different classifiers. We selected Naive Bayes
 as a probabilistic classifier, SVM as a decision boundary classifier, 
and decision tree as a rule based classifier.</p><p id="Par47" class="Para">One
 of the challenges of automated emotion detection is that emotions are 
complex concepts with fuzzy boundaries and with many variations in 
expression. Also, emotion perception is naturally subjective. Thus, it 
is difficult to achieve a consensus to which emotion class each text 
message belongs to. As shown in our user studies described in 
Sect.&nbsp;<span class="InternalRef"><a href="#Sec24">5</a></span>, 
people often have different perceptions about emotion expressed in 
texts. Furthermore, a small number of discrete emotion classes may not 
reflect the complexity of the emotional states conveyed by humans. 
Typical classifiers assume clearly demarcated and nonoverlapping 
classes. They may not assign emotion labels to some messages with high 
confidence and classify them either incorrectly or correctly with low 
confidence. Therefore, simply assigning one single emotion class to each
 text message in a deterministic manner may not perform well in 
practice.</p><p id="Par48" class="Para">To overcome this issue, we use a
 two-pronged approach. First, we define the emotion classes based on a 
dimensional model (See Sect.&nbsp;<span class="InternalRef"><a href="#Sec7">2.2</a></span>).
 Second, a soft (fuzzy) classification approach is proposed to measure 
the strength of each emotion class in association with the message under
 classification. In soft classification, the prediction results become 
less explicit by assigning each message a soft label that indicates how 
likely each emotion would be perceived. More details about hard and soft
 classification of emotion are described bellow.</p><section id="Sec14" tabindex="-1" class="Section4 RenderAsSection4"><h5 class="Heading"><span class="HeadingNumber">3.1.3.1 </span> <strong class="EmphasisTypeBold ">Hard and Soft Classification of Emotion</strong> </h5><div id="Par49" class="Para">For
 classifying emotion, we utilize two types of classification: soft and 
hard classification. In general, a classifier is a function that assigns
 an emotion label <em class="EmphasisTypeItalic ">y</em> to an input feature vector <em class="EmphasisTypeItalic ">x</em>:<div id="Equ1" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} y = f(x), ~~ x \in X, ~~ y \in Y \end{aligned}$$</div> <div class="EquationNumber">(1)</div></div>where <em class="EmphasisTypeItalic ">X</em> is the set of all feature vectors from the tweets in the input dataset, and <em class="EmphasisTypeItalic ">Y</em> is the set of emotion labels.</div><div id="Par50" class="Para">Some
 classifiers such as support vector machines make decision boundaries 
between different classes. Other classifiers are probabilistic 
classifiers meaning that they assign a probability distribution over a 
set of classes to an input <span class="InlineEquation" id="IEq3">\({x \in X}\)</span>.<div id="Equ2" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} P(Y =y \vert x), ~~ x \in X, ~~ y \in Y \end{aligned}$$</div> <div class="EquationNumber">(2)</div></div>In
 hard classification, each message can only belong to one and only one 
class. Soft classifiers measure the degree to which a message belongs to
 each class, rather than dedicating the message to a specific class [<span class="CitationRef"><a href="#CR29" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">29</a></span>].
 In decision boundary classifiers, soft labels can be estimated based on
 decision scores. In probabilistic classifiers, soft labels can refer to
 the class conditional probabilities, and a hard classification label 
can be produced based on the largest estimated probability.<div id="Equ3" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} y = {\max }_{y} \{ {P}(Y=y \vert x), ~~ x \in X, ~~ y \in Y\} \end{aligned}$$</div> <div class="EquationNumber">(3)</div></div>For
 example, the tweet “I can live for months on a good compliment” is 65% 
likely to be happy, 18% likely to be relaxed, 9% likely to be angry, and
 8% likely to be sad. Since the maximum probability of the tweet is 65%,
 it can be assigned to the happy class.</div><div id="Par51" class="Para">Naive
 Bayes and logistic regression are probabilistic classifiers which 
produce a probability distribution over output classes. Other models 
such as support vector machines do not produce probabilities. They 
instead return decision scores which are proportional to the distance 
from the separating hyperplane. They classify input data (here, tweets) 
with certain decision scores, which can be considered as soft labels. 
However, these scores may not correspond with class membership 
probabilities, since the distance from the separating hyperplane is not 
exactly proportional to the chances of class membership [<span class="CitationRef"><a href="#CR30" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">30</a></span>].
 Some methods have been developed to convert the results of these 
classifiers into class membership probabilities. A common method is to 
apply Platt scaling [<span class="CitationRef"><a href="#CR31" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">31</a></span>], which learns the following sigmoid function defined by the parameters <em class="EmphasisTypeItalic ">A</em> and <em class="EmphasisTypeItalic ">B</em> on the decision scores <em class="EmphasisTypeItalic ">s</em>(<em class="EmphasisTypeItalic ">x</em>):<div id="Equ4" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} {P}(Y=y \vert x) = \frac{1}{1+e^ {As(x)+B} } \end{aligned}$$</div> <div class="EquationNumber">(4)</div></div>Zadrozny and Elkan proposed another method by using isotonic regression when sufficient training data are available [<span class="CitationRef"><a href="#CR30" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">30</a></span>].</div></section></section></section><section id="Sec15" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">3.2 </span>EmotexStream: a framework for classifying live streams of text messages</h3><p id="Par52" class="Para">After
 developing Emotex, we now aim to deploy the trained model to analyze 
live streams of tweets. However analyzing text in real time is 
challenging due to the noise and fast-paced nature of tweets in the 
wild. For this, we develop a two-stage approach for classifying live 
streams of tweets.</p><p id="Par53" class="Para">Twitter messages cover a
 wide range of subjects. However, since our focus is on emotion 
detection, we are only interested in processing messages that contain 
emotions. For instance, the tweet "I have a wonderful roommate" conveys a
 happy emotion and is a good input to our system. In contrast, the tweet
 "It’s time for bed" cannot be identified as expressing any type of 
emotion neither happy nor sad. Therefore, we aim to identify such tweets
 without emotion and eliminate them in a fast preclassification step. In
 fact, we decompose the emotion detection task into two subtasks. We 
first detect tweets without any identifiable emotion using a binary 
classifier. Then we conduct a fine-grained emotion classification on 
tweets with explicit emotion.</p><div id="Par54" class="Para">Figure&nbsp;<span class="InternalRef"><a href="#Fig4">4</a></span>
 shows our emotion analysis pipeline in classifying the general stream 
of tweets. As it shows, after cleaning and preprocessing of tweets we 
categorize tweets into two general classes, namely emotion-present and 
emotion-absent tweets. For binary classification of tweets we develop an
 unsupervised method that utilizes emotion lexicons. Our binary 
classifier assumes that tweets with no emotion are the ones without any 
emotional or affective words. Therefore, it classifies tweets containing
 at least one affective or emotional word as emotion-present tweets, and
 classifies tweets without any affective word as emotion-absent tweets. 
As we described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec12">3.1.2</a></span>,
 different emotion lexicons are available, including ANEW lexicon, LIWC 
dictionary, and AFINN. We utilize all the affective words from these 
three lexicons and create a comprehensive affective lexicon for our 
binary classification task. After binary classification, emotion tweets 
will then go through the feature selection and multi-class emotion 
classifier generated by our Emotex technology to classify them based on 
our defined classes of emotion.<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO8"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig4_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig4_HTML.gif" alt="Fig. 4"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 4</span> <p class="SimplePara">EmotexStream: a two-stage approach to classify live streams of tweets</p> </div></figcaption></figure></div></section><section id="Sec16" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">3.3 </span>Proposed approach to detect emotion-intensive moments in live streams of messages</h3><div id="Par55" class="Para">Detecting
 and measuring emotion in social networks such as Twitter enable us to 
observe crowd emotion and behavior. Using EmotexStream, we are able to 
classify live streams of tweets in real-time. We now aim to use our 
EmotexStream system to measure public emotion and detect emotion burst 
moments in live stream of tweets. We are looking for the percentage of 
people in a geographic location experiencing certain emotions during a 
specific time. The goal is to explore temporal distributions of 
aggregate emotion and detect temporal bursts in public emotion from live
 text streams. For this purpose, we first apply our EmotexStream system 
to automatically detect the emotion of people from their messages in 
live stream of tweets. As shown in Fig.&nbsp;<span class="InternalRef"><a href="#Fig5">5</a></span>,
 EmotexStream converts live text streams into streams of emotion 
classes. Then we aggregate the emotion stream of each class into a 
time-based histogram to analyze public emotion trends and discover 
emotion-evolving patterns over time. We propose an online method to 
measure public emotion and detect abrupt changes in emotion as 
emotion-intensive moments in live text streams [<span class="CitationRef"><a href="#CR32" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">32</a></span>].
 Before describing our online method to detect important moments in 
social streams, we define some concepts in the context of tweet streams 
as below:<figure class="Figure" id="Fig5"><div class="MediaObject" id="MO9"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig5_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig5_HTML.gif" alt="Fig. 5"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 5</span> <p class="SimplePara">Converting text streams into emotion streams using EmotexStream</p> </div></figcaption></figure></div><div id="FPar1" class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Definition 1</span></h3><p id="Par56" class="Para">(<em class="EmphasisTypeItalic ">Emotion Stream</em>) An emotion stream <span class="InlineEquation" id="IEq4">\(S_E\)</span> is a continuous sequence of time-ordered messages <span class="InlineEquation" id="IEq5">\(M_1, M_2, \cdots M_r, \cdots \)</span> from a tweet stream, such that each message <span class="InlineEquation" id="IEq6">\(M_i\)</span> belongs to a specific emotion class <span class="InlineEquation" id="IEq7">\(E_{c1} \in E_{\mathrm{Class}}\)</span> (<span class="InlineEquation" id="IEq8">\(E_{\mathrm{Class}}\)</span> is the set of predefined emotion classes defined in Sect.&nbsp;<span class="InternalRef"><a href="#Fig2">2</a></span>).</p></div><div id="Par57" class="Para">In order to estimate the value of a specific emotion class <span class="InlineEquation" id="IEq9">\(E_{c1}\)</span> among the people in a geographic location <em class="EmphasisTypeItalic ">L</em> during a time period <span class="InlineEquation" id="IEq10">\([T_1, T_2]\)</span>, we define a function as below:<div id="Equ5" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned}
 E_{\mathrm{public}}(T_1, T_2, L, E_{c1}) = \sum \limits 
_{T_1&lt;T_i&lt;T_2,~L_i \in L} {F(M_i, E_{c1})} \end{aligned}$$</div> <div class="EquationNumber">(5)</div></div>where <span class="InlineEquation" id="IEq11">\(M_i=&lt;U_i, T_i, L_i, C_i, E_i&gt;\)</span> is a tweet message in the emotion stream from the emotion class <span class="InlineEquation" id="IEq12">\(E_i \in E_{\mathrm{Class}}\)</span>, posted by user <span class="InlineEquation" id="IEq13">\(U_i\)</span> in location <span class="InlineEquation" id="IEq14">\(L_i \in L\)</span>, at the time <span class="InlineEquation" id="IEq15">\(T_1&lt;T_i&lt;T_2\)</span>, and <span class="InlineEquation" id="IEq16">\(F(M_i, E_{c1})\)</span> is an indicator function defined as below:<div id="Equ6" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned}
 F(M_i, E_{c1}) = {\left\{ \begin{array}{ll} 1 &amp;{}\quad \text {if } 
M_i \in E_{c1},\\ 0 &amp;{}\quad \text {Otherwise.} \end{array}\right. }
 \end{aligned}$$</div> <div class="EquationNumber">(6)</div></div>Using Eq.&nbsp;<span class="InternalRef"><a href="#Equ5">5</a></span>
 we can quantify emotion of a population in a geographic location and 
during a time period. We can then analyze such emotion streams to detect
 temporal bursts of crowd emotion. These sudden bursts are characterized
 by a change in the fractional presence of messages in particular 
emotion classes. Formally, we define such abrupt changes as “emotion 
burst”, which can point toward important moments. In order to detect 
emotion bursts, we determine the higher or the lower rate at which 
messages have arrived to an emotion class in the current time window of 
length <em class="EmphasisTypeItalic ">W</em>. Two parameters <span class="InlineEquation" id="IEq17">\(\alpha \)</span> and <span class="InlineEquation" id="IEq18">\(\beta \)</span> are used to measure this evolution rate.</div><div id="FPar2" class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Definition 2</span></h3><p id="Par58" class="Para">(<em class="EmphasisTypeItalic ">Emotion Burst</em>) An emotion burst over a temporal window of length <em class="EmphasisTypeItalic ">W</em> at the current time <span class="InlineEquation" id="IEq19">\(T_c\)</span> is said to have occurred in a geographic region <em class="EmphasisTypeItalic ">L</em>, if the presence of a specific class emotion <span class="InlineEquation" id="IEq20">\(E_{c1}\)</span> during a time period <span class="InlineEquation" id="IEq21">\((T_c - W, T_c)\)</span> is less than the lower threshold <span class="InlineEquation" id="IEq22">\(\alpha \)</span> or greater than the upper threshold <span class="InlineEquation" id="IEq23">\(\beta \)</span>.</p></div><div id="Par59" class="Para">In other words, we should have either<div id="Equ7" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} E_{\mathrm{public}}(T_c-W, T_c, L, E_{c1}) \le \alpha \end{aligned}$$</div> <div class="EquationNumber">(7)</div></div>or<div id="Equ8" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} E_{\mathrm{public}}(T_c-W, T_c, L, E_{c1}) \ge \beta . \end{aligned}$$</div> <div class="EquationNumber">(8)</div></div>Now we need to define the upper bound <span class="InlineEquation" id="IEq24">\(\alpha \)</span> and lower bound <span class="InlineEquation" id="IEq25">\(\beta \)</span>
 of public emotion for each emotion class during a temporal window. If 
our algorithm is applied offline (i.e., all the tweets are available), 
the thresholds can be estimated from the average sum over the whole time
 period. However, in the online approach all the tweets are not 
available. Therefore, in the online approach, we compute the thresholds 
from the tweets in a temporal sliding window, where the size of the 
moving window is a parameter.</div><div id="Par60" class="Para">Figure&nbsp;<span class="InternalRef"><a href="#Fig6">6</a></span>
 presents our system for detecting important moments in live text 
streams. Emotion streams can be created by applying EmotexStream system 
to classify tweets arriving in a stream. Let <span class="InlineEquation" id="IEq26">\(e_1, \ldots e_i, \cdots e_n\)</span> denote the emotion values of class <span class="InlineEquation" id="IEq27">\(E_{c1}\)</span> of the tweets posted within a temporal window of length <em class="EmphasisTypeItalic ">W</em> in an emotion stream (<em class="EmphasisTypeItalic ">n</em> is the number of tweets posted within <em class="EmphasisTypeItalic ">W</em>). Apparently, <span class="InlineEquation" id="IEq28">\(e_1, \ldots e_i, \cdots e_n\)</span> are independent 0–1 random variables (<span class="InlineEquation" id="IEq29">\(e_i=0\)</span> means message <span class="InlineEquation" id="IEq30">\(M_i\)</span> doesn’t belong to the emotion class <span class="InlineEquation" id="IEq31">\(E_{c1}\)</span>, and <span class="InlineEquation" id="IEq32">\(e_i=1\)</span> means message <span class="InlineEquation" id="IEq33">\(M_i\)</span> belongs to the emotion class <span class="InlineEquation" id="IEq34">\(E_{c1}\)</span>). Emotion aggregator uses Eq.&nbsp;<span class="InternalRef"><a href="#Equ5">5</a></span> to measure public emotion over a period of time. Based on Eq.&nbsp;<span class="InternalRef"><a href="#Equ5">5</a></span>, public emotion within the temporal window <em class="EmphasisTypeItalic ">W</em> is defined as below:<figure class="Figure" id="Fig6"><div class="MediaObject" id="MO14"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig6_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig6_HTML.gif" alt="Fig. 6"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 6</span> <p class="SimplePara">Detecting emotion bursts in live text streams</p> </div></figcaption></figure><div id="Equ9" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} E_{\mathrm{public}}(T_c - W, T_c, L, E_{c1}) = \sum \limits _{i=1\ldots n} {F(M_i,E_{c1})} \end{aligned}$$</div> <div class="EquationNumber">(9)</div></div>where <span class="InlineEquation" id="IEq35">\(F(M_i,E_{c1})\)</span> is an indicator function of <span class="InlineEquation" id="IEq36">\(E_{c1}\)</span> and <em class="EmphasisTypeItalic ">n</em> is the number of tweets posted within <em class="EmphasisTypeItalic ">W</em>. As we know Hoeffding’s inequality provides an upper bound on the probability that the sum of random variables deviates <span class="InlineEquation" id="IEq37">\(\lambda &gt;0\)</span> from its expected value as shown by Eq.&nbsp;<span class="InternalRef"><a href="#Equ10">10</a></span>:<div id="Equ10" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} Pr[ |X-\mu | &gt;= \lambda ] &lt;= 2e^ {-2\lambda ^2/n } \end{aligned}$$</div> <div class="EquationNumber">(10)</div></div>where <em class="EmphasisTypeItalic ">X</em> is the sum of independent random variables <span class="InlineEquation" id="IEq38">\(X_1, X_2, \ldots , X_n\)</span>, with <span class="InlineEquation" id="IEq39">\(E[X_i]=p_i\)</span>, and the expected value <span class="InlineEquation" id="IEq40">\(E[X]= \sum \nolimits _{i=1\ldots n} p_i = \mu \)</span>.</div><div id="Par61" class="Para">According to the Central Limit Theorem, if <em class="EmphasisTypeItalic ">n</em> is large then <em class="EmphasisTypeItalic ">X</em>
 approaches a normal distribution. We can use Hoeffding’s inequality to 
define an upper bound on the probability that the public emotion <span class="InlineEquation" id="IEq41">\(E_{c1}\)</span> deviates from its expected value. Using the Hoeffding bound, for any <span class="InlineEquation" id="IEq42">\(\lambda &gt;0\)</span> we have:<div id="Equ11" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned}&amp;Pr[
 |E_{\mathrm{public}}(T_c - W, T_c, L, E_{c1}) -\mu _e| &gt;= \lambda ] 
\nonumber \\&amp;\quad &lt;= 2e^ {-2\lambda ^2/n } \end{aligned}$$</div> <div class="EquationNumber">(11)</div></div>where <span class="InlineEquation" id="IEq43">\(\mu _e\)</span> is the expected number of tweets belong to the emotion class <span class="InlineEquation" id="IEq44">\(E_{c1}\)</span> in window <em class="EmphasisTypeItalic ">W</em> and <em class="EmphasisTypeItalic ">n</em> is the number of tweets posted within <em class="EmphasisTypeItalic ">W</em>. Given that <em class="EmphasisTypeItalic ">n</em> is large in the temporal window <em class="EmphasisTypeItalic ">W</em>, emotion class <span class="InlineEquation" id="IEq45">\(E_{c1}\)</span> can be approximated using a normal distribution.<div id="Equ14" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} \mu _e = n \times P_e \end{aligned}$$</div></div>where <span class="InlineEquation" id="IEq46">\(P_e\)</span> is the expected rate of the emotion class <span class="InlineEquation" id="IEq47">\(E_{c1}\)</span>.</div><p id="Par62" class="Para">We use the historical average rate of each emotion class as expected rate <span class="InlineEquation" id="IEq48">\(P_e\)</span>
 for that emotion class. For example, a weekly window can be used to 
average the rate of each emotion class based on all tweets in general. 
Therefore, other than a sliding detection window over the recent tweets 
posted about a topic, we also utilize a larger reference window to 
summarize the information about the tweets posted in general. In fact, 
our emotion burst detection methodology utilizes two sliding windows. 
One small window that keeps the rate of each emotion class based on the 
most recent tweets posted about a topic. Another large reference window 
that keeps the average rate of each emotion class based on all the past 
tweets posted in general.</p><p id="Par63" class="Para">Now we describe 
our methodology to automatically discover emotion bursts during a 
real-life event. First, we create an emotion stream by applying 
EmotexStream system to classify tweets arriving in a stream based on a 
predefined set of emotion classes. As a second step, our emotion burst 
detection algorithm then aggregates the tweets of each emotion class 
into a time-based histogram, using the function in Eq.&nbsp;<span class="InternalRef"><a href="#Equ5">5</a></span>. This aggregation allows us to count the rate of each emotion class in each time period. We then define a sliding window <span class="InlineEquation" id="IEq49">\(W_{\mathrm{topic}}\)</span>
 (e.g., daily) over the stream of tweets about a topic aggregated in 
temporal bins. We also define a large (e.g., weekly) window <span class="InlineEquation" id="IEq50">\(W_{\mathrm{general}}\)</span>
 over the general stream of tweets to keep track of the average rate of 
each emotion class. In order to perform the burst detection, we 
continuously monitor the rate of public emotion for each emotion class 
within each temporal window <span class="InlineEquation" id="IEq51">\(W_{\mathrm{topic}}\)</span>. Whenever the rate of an emotion class exceeds the upper threshold <span class="InlineEquation" id="IEq52">\(\beta \)</span> or falls beneath the lower limit <span class="InlineEquation" id="IEq53">\(\alpha \)</span>,
 an emotion burst is marked as an important moment by keeping its time 
of occurrence and if it is an up or down case. Then the system signals 
the occurrence of the detected moments.</p></section></div></section><section id="Sec17" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">4 </span>Experimental results on classifying streams of Twitter messages<span class="section-icon"></span></h2><div class="content"><p id="Par64" class="Para">We
 run three separate experiments including, the offline model training, 
the online classification and the emotion burst detection. In the 
offline experiment, we collect enough labeled data to build emotion 
classifiers as described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec9">3.1</a></span>.
 During the online experiment, we apply our emotion classifiers to 
classify the live streams of tweets using EmotexStream system (see 
Sect.&nbsp;<span class="InternalRef"><a href="#Sec15">3.2</a></span>). 
In the last experiment we select a real-life event and detect the 
emotion-intensive moments using our method described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec16">3.3</a></span>.</p><section id="Sec18" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.1 </span>Offline model training: collecting labeled data and building the emotex classifier</h3><div id="Par65" class="Para">To collect emotion-labeled data, we first identify a list of emotion hashtags as explained in Sect.&nbsp;<span class="InternalRef"><a href="#Sec10">3.1.1</a></span>. Using the list of keywords from the Circumplex model (see Fig.&nbsp;<span class="InternalRef"><a href="#Fig1">1</a></span>),
 a set of emotion hashtags for each class was obtained. Then, we 
searched for the tweets containing these emotion hashtags and found more
 emotion hashtags from these tweets, such as the tag ”#ifeelsad”. At the
 end, a set of 20 unique emotion hashtags was collected for each emotion
 class. The objective was to assure that the tags of each class 
constitute emotions which are different compared with the emotions of 
the other classes. Using the identified hashtags, labeled data was 
collected for three weeks between December 26 and January 15. We used 
Twitter Stream API to collect data from online stream of tweets, which 
contains a 1% random sample of all tweets. Figure&nbsp;<span class="InternalRef"><a href="#Fig7">7</a></span>
 presents the distribution of four classes of tweets that we labeled 
using hashtags during and after the new year vacation. It shows that the
 number of happy tweets after vacation is less than the number of happy 
tweets during vacation by about 13%. More interestingly, the number of 
unhappy tweets after vacation is more than twice the number of unhappy 
tweets during vacation. It also shows that the number of active tweets 
during the vacation are higher than the number of active tweets after 
vacation by about 4%.<figure class="Figure" id="Fig7"><div class="MediaObject" id="MO19"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig7_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig7_HTML.gif" alt="Fig. 7"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 7</span> <p class="SimplePara">Distribution of four classes of emotion in collected tweets during and after the new year vacation</p> </div></figcaption></figure><div id="Tab1" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 1</span> <p class="SimplePara">Number of tweets collected as labeled data</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Class</p> </th><th> <p class="SimplePara">Happy-Active</p> </th><th> <p class="SimplePara">Happy-Inactive</p> </th><th> <p class="SimplePara">Unhappy-Active</p> </th><th> <p class="SimplePara">Unhappy-Inactive</p> </th><th> <p class="SimplePara">Total</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">#Tweets before preprocessing</p> </td><td> <p class="SimplePara">40,000</p> </td><td> <p class="SimplePara">41,000</p> </td><td> <p class="SimplePara">44,000</p> </td><td> <p class="SimplePara">41,000</p> </td><td> <p class="SimplePara">166,000</p> </td></tr><tr><td> <p class="SimplePara">#Tweets after preprocessing</p> </td><td> <p class="SimplePara">34,000</p> </td><td> <p class="SimplePara">30,000</p> </td><td> <p class="SimplePara">37,000</p> </td><td> <p class="SimplePara">34,000</p> </td><td> <p class="SimplePara">13,5000</p> </td></tr></tbody></table></div></div><div id="Tab2" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 2</span> <p class="SimplePara">Distribution of features in the collected data</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"><col class="tcol7 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Features</p> </th><th> <p class="SimplePara">Happy icon</p> </th><th> <p class="SimplePara">Sad icon</p> </th><th> <p class="SimplePara">Angry icon</p> </th><th> <p class="SimplePara">Sleepy icon</p> </th><th> <p class="SimplePara">Negation</p> </th><th> <p class="SimplePara">Punctuation</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">#Tweets with&nbsp;a feature</p> </td><td> <p class="SimplePara">5800</p> </td><td> <p class="SimplePara">1320</p> </td><td> <p class="SimplePara">1020</p> </td><td> <p class="SimplePara">270</p> </td><td> <p class="SimplePara">9050</p> </td><td> <p class="SimplePara">19450</p> </td></tr><tr><td> <p class="SimplePara">%Tweets with&nbsp;a feature (%)</p> </td><td> <p class="SimplePara">4.3</p> </td><td> <p class="SimplePara">1</p> </td><td> <p class="SimplePara">0.7</p> </td><td> <p class="SimplePara">0.2</p> </td><td> <p class="SimplePara">6.7</p> </td><td> <p class="SimplePara">14.5</p> </td></tr></tbody></table></div></div><div id="Tab3" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 3</span> <p class="SimplePara">Precision, recall and F-Measure <span class="InlineEquation" id="IEq54">\((\beta =1)\)</span> of SVM, Naive Bayes and decision tree using different features</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"><col class="tcol7 align-left"><col class="tcol8 align-left"><col class="tcol9 align-left"><col class="tcol10 align-left"></colgroup><thead><tr><th rowspan="2"> <p class="SimplePara">Features</p> </th><th colspan="3"> <p class="SimplePara">Naive&nbsp;Bayes</p> </th><th colspan="3"> <p class="SimplePara">SVM</p> </th><th colspan="3"> <p class="SimplePara">Decision tree</p> </th></tr><tr><th> <p class="SimplePara">Prec.</p> </th><th> <p class="SimplePara">Rec.</p> </th><th> <p class="SimplePara">FM</p> </th><th> <p class="SimplePara">Prec.</p> </th><th> <p class="SimplePara">Rec.</p> </th><th> <p class="SimplePara">FM</p> </th><th> <p class="SimplePara">Prec.</p> </th><th> <p class="SimplePara">Rec.</p> </th><th> <p class="SimplePara">FM</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Unigram</p> </td><td> <p class="SimplePara">87.7</p> </td><td> <p class="SimplePara">86.3</p> </td><td> <p class="SimplePara">86.3</p> </td><td> <p class="SimplePara">90.3</p> </td><td> <p class="SimplePara">89.7</p> </td><td> <p class="SimplePara"> <strong class="EmphasisTypeBold ">90</strong> </p> </td><td> <p class="SimplePara">89.6</p> </td><td> <p class="SimplePara">89.5</p> </td><td> <p class="SimplePara">89.5</p> </td></tr><tr><td> <p class="SimplePara">Unigram emoticon</p> </td><td> <p class="SimplePara">87.6</p> </td><td> <p class="SimplePara">86.4</p> </td><td> <p class="SimplePara">86.4</p> </td><td> <p class="SimplePara">89.3</p> </td><td> <p class="SimplePara">88.8</p> </td><td> <p class="SimplePara">89</p> </td><td> <p class="SimplePara">89.7</p> </td><td> <p class="SimplePara">89.6</p> </td><td> <p class="SimplePara"> <strong class="EmphasisTypeBold ">89.6</strong> </p> </td></tr><tr><td> <p class="SimplePara">Unigram punctuation</p> </td><td> <p class="SimplePara">87.1</p> </td><td> <p class="SimplePara">86.6</p> </td><td> <p class="SimplePara">86.6</p> </td><td> <p class="SimplePara">90.4</p> </td><td> <p class="SimplePara">89.3</p> </td><td> <p class="SimplePara"> <strong class="EmphasisTypeBold ">89.9</strong> </p> </td><td> <p class="SimplePara">89.8</p> </td><td> <p class="SimplePara">89.7</p> </td><td> <p class="SimplePara">89.7</p> </td></tr><tr><td> <p class="SimplePara">Unigram negation</p> </td><td> <p class="SimplePara">87.9</p> </td><td> <p class="SimplePara">86.9</p> </td><td> <p class="SimplePara">86.9</p> </td><td> <p class="SimplePara">89.5</p> </td><td> <p class="SimplePara">88.8</p> </td><td> <p class="SimplePara">89.1</p> </td><td> <p class="SimplePara">89.9</p> </td><td> <p class="SimplePara">89.6</p> </td><td> <p class="SimplePara"> <strong class="EmphasisTypeBold ">89.7</strong> </p> </td></tr><tr><td> <p class="SimplePara">All-features</p> </td><td> <p class="SimplePara">87.3</p> </td><td> <p class="SimplePara">87</p> </td><td> <p class="SimplePara">86.9</p> </td><td> <p class="SimplePara">90.2</p> </td><td> <p class="SimplePara">89.5</p> </td><td> <p class="SimplePara">89.9</p> </td><td> <p class="SimplePara">90.1</p> </td><td> <p class="SimplePara">89.9</p> </td><td> <p class="SimplePara"> <strong class="EmphasisTypeBold ">90</strong> </p> </td></tr></tbody></table></div></div></div><p id="Par66" class="Para">To
 train our emotion classifiers we select equal size random samples for 
each emotion class from our collected labeled tweets. In fact, we do 
random under-sampling to create a balanced training dataset with equal 
number of samples in each class [<span class="CitationRef"><a href="#CR33" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">33</a></span>]. The number of samples in each emotion class is large enough to train classifiers. Table&nbsp;<span class="InternalRef"><a href="#Tab1">1</a></span>
 represents the number of labeled tweets selected for each class before 
and after preprocessing. The removal of noisy tweets during 
preprocessing decreased the number of tweets by 19%. We explore the 
usage of different features (see Sect.&nbsp;<span class="InternalRef"><a href="#Sec11">3.1.2</a></span>). Table&nbsp;<span class="InternalRef"><a href="#Tab2">2</a></span> lists the distribution of features in the collected data after preprocessing.</p><p id="Par67" class="Para">As described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec14">3.1.3</a></span>
 we utilize two types of classification including soft and hard 
classification. The emotion classification results using soft and hard 
classification are elaborated below.</p><section id="Sec19" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading"><span class="HeadingNumber">4.1.1 </span>Emotex: hard classification results</h4><p id="Par68" class="Para">We
 used two folds of our labeled data to train classifiers and one fold 
for testing. We used WEKA to train Naive Bayes, and decision tree models
 and we used SVM-light [<span class="CitationRef"><a href="#CR34" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">34</a></span>] with a linear kernel to train the SVM classifier.</p><div id="Par69" class="Para">The classification results are evaluated in terms of F-measure (<span class="InlineEquation" id="IEq55">\(\beta =1\)</span>), defined as:<div id="Equ15" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned}
 2\times \mathrm{precision}\times \mathrm{recall} \mathbin {/} 
(\mathrm{precision}+\mathrm{recall}) \end{aligned}$$</div></div>Table&nbsp;<span class="InternalRef"><a href="#Tab3">3</a></span>
 presents precision, recall and F-measure of Naive Bayes, decision tree,
 and SVM using different features based on 3-fold cross-validation. As 
it shows, decision tree achieved the highest accuracy using all the 
features. SVM achieved the highest accuracy using unigrams only, while 
Naive Bayes achieved the highest accuracy using unigrams and negations. 
Although a decision tree classifier provides high accuracy, it is slow. 
Therefore, it is not practical for big datasets. SVM-light [<span class="CitationRef"><a href="#CR34" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">34</a></span>] runs fast and provides the highest accuracy.</div><div id="Par70" class="Para">The F-measure <span class="InlineEquation" id="IEq56">\((\beta =1)\)</span> values of the SVM model in classifying four emotion classes using different features are presented in Fig.&nbsp;<span class="InternalRef"><a href="#Fig8">8</a></span>.
 Class unhappy-active got the highest F-score. The active classes (i.e.,
 happy-active and unhappy-active) achieved the highest F-score using 
unigrams only. However, for the other classes, the highest F-score is 
achieved using unigrams and punctuations. Across all emotion classes, 
the unigram-trained model gave the highest overall F-score, and among 
other features punctuations performed second best.<figure class="Figure" id="Fig8"><div class="MediaObject" id="MO21"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig8_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig8_HTML.gif" alt="Fig. 8"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 8</span> <p class="SimplePara">The F-measure <span class="InlineEquation" id="IEq57">\((\beta =1)\)</span> of SVM model to classify four emotion classes using different features</p> </div></figcaption></figure></div></section><section id="Sec20" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading"><span class="HeadingNumber">4.1.2 </span>Emotex: soft classification results</h4><p id="Par71" class="Para">We
 utilize a probabilistic classifier to measure the soft label based on 
the probability of assigning a tweet to each emotion class. In this 
experiment, we run Naive Bayes classifier on our training dataset and 
produce the class membership probabilities for each tweet. Then the 
tweets whose maximum probability are higher than a predefined threshold 
are classified to the class with the maximum probability. The 
probability threshold is a tuning parameter of the system.</p><p id="Par72" class="Para">We
 use the test set ROC curve to find a good probability threshold by 
resampling. For instance, the tweet "I can live for months on a good 
compliment." is 65% likely to belong to the happy-active class, 18% 
likely to belong to the happy-inactive class, 9% likely to belong to the
 unhappy-active class, and 8% likely to belong to the unhappy-inactive 
class. Since the maximum probability of this tweet is 65%, it therefore 
can be classified as a happy-active tweet. As another example, the tweet
 “Miss you already!” is 19% likely to belong to the happy-active class, 
24% likely to belong to the happy-inactive class, 25% likely to belong 
to the unhappy-active class, and 32% likely to belong to the 
unhappy-inactive class. The maximum probability of this tweet is 32%, 
which is fairly small. Thus the tweet cannot be classified with a high 
enough certainty to render a hard classification.</p><div id="Par73" class="Para">Figure &nbsp;<span class="InternalRef"><a href="#Fig9">9</a></span> shows the results of running Naive Bayes classifier on our labeled data with the probability threshold of 50% (Table&nbsp;<span class="InternalRef"><a href="#Tab1">1</a></span>
 provides details about our labeled data). As it shows 81% of tweets are
 classified with the maximum probability higher than the threshold of 
50%, where a hard label will be emerged by our system. Only 4% of these 
tweets are classified wrongly. However, 52% of the tweets whose maximum 
probability are lower than the threshold are classified inaccurately. In
 fact, tweets with low confident classification make an error rate of 
52%, thus no hard label will be recommended by the system. The results 
confirm the fact that if tweets are classified with low certainty (i.e.,
 low maximum probability), the classification results have a high error 
rate. This justifies our approach of forcing a hard classification only 
for a certain level of confidence.<figure class="Figure" id="Fig9"><div class="MediaObject" id="MO22"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig9_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig9_HTML.gif" alt="Fig. 9"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 9</span> <p class="SimplePara">Distribution of classified tweets based on maximum probability with threshold <span class="InlineEquation" id="IEq58">\(=\)</span> 50%</p> </div></figcaption></figure></div><div id="Par74" class="Para">Based on our observation shown in Fig.&nbsp;<span class="InternalRef"><a href="#Fig9">9</a></span>
 tweets with low maximum probability have a higher error rates, we thus 
separate them in our analysis. In fact, we only consider tweets that are
 classified with high maximum probability in our analysis. Table&nbsp;<span class="InternalRef"><a href="#Tab4">4</a></span>
 shows the accuracy of classification before and after filtering out the
 tweets with maximum probability lower than the threshold of 50%. As it 
shows the accuracy has increased by 9.8%, after filtering out the tweets
 whose maximum probability scores are lower than the threshold of 50%.<div id="Tab4" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 4</span> <p class="SimplePara">Classification results of Naive Bayes after removing tweets with low maximum probability</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"></colgroup><thead><tr><th>&nbsp;</th><th> <p class="SimplePara">#Tweets</p> </th><th> <p class="SimplePara">Precison (%)</p> </th><th> <p class="SimplePara">Recall (%)</p> </th><th> <p class="SimplePara">F-measure (%)</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">No Filtering</p> </td><td> <p class="SimplePara">134,100</p> </td><td> <p class="SimplePara">88</p> </td><td> <p class="SimplePara">83.7</p> </td><td> <p class="SimplePara">86</p> </td></tr><tr><td> <p class="SimplePara">Removing tweets&nbsp;with&nbsp;low max-probability</p> </td><td> <p class="SimplePara">108,516</p> </td><td> <p class="SimplePara">96</p> </td><td> <p class="SimplePara">94.4</p> </td><td> <p class="SimplePara">95.8</p> </td></tr></tbody></table></div></div></div></section><section id="Sec21" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading"><span class="HeadingNumber">4.1.3 </span>Comparing emotex with the lexical approaches </h4><p id="Par75" class="Para">Existing
 methods for text classification can be categorized into two main 
groups: lexical methods and supervised learning methods [<span class="CitationRef"><a href="#CR23" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">23</a></span>]. To further benchmark the performance of Emotex in classifying emotional messages, we compare it with the lexical approach.</p><p id="Par76" class="Para">The lexical approach has been previously studied in the context of emotion classification [<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>, <span class="CitationRef"><a href="#CR22" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">22</a></span>, <span class="CitationRef"><a href="#CR35" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">35</a></span>, <span class="CitationRef"><a href="#CR36" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">36</a></span>, <span class="CitationRef"><a href="#CR37" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">37</a></span>].
 Lexical methods classify the emotion expressed in texts based on the 
occurrence of certain words. A lexicon of emotion words is created, in 
which each word belongs to an emotion class. Text messages are then 
classified using this emotion lexicon, typically by employing frequency 
counts of terms. The lexical methods may consider only terms of the 
lexicon directly or may associate numerical weights with these terms.</p><p id="Par77" class="Para">Lexical
 methods are based on shallow word-level analysis, and can recognize 
only surface features of the text. They usually ignore semantic features
 (e.g., negation) [<span class="CitationRef"><a href="#CR23" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">23</a></span>].
 Moreover they rely on an emotion lexicon, which is difficult to 
construct a comprehensive set of emotion keywords. The creation of 
emotional lexicon is both time-consuming and labor-intensive, and 
requires expert human annotators.</p><div id="Par78" class="Para">A variety of Emotion lexicons including ANEW lexicon [<span class="CitationRef"><a href="#CR26" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">26</a></span>], WordNet Affect [<span class="CitationRef"><a href="#CR38" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">38</a></span>], and LIWC dictionary [<span class="CitationRef"><a href="#CR27" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">27</a></span>]
 have been developed. To compare the results of Emotex with the lexical 
approach we utilize ANEW lexicon, which contains 2477 affect words that 
are rated for valence and arousal on a 1–9 scale. To classify messages 
using ANEW lexicon, the average valence and arousal of each message is 
estimated using the following formulas:<div id="Equ12" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} \mathrm{Valence}_{\mathrm{tweet}} = \frac{\sum _{i=1}^{n} v_{i}f_{i}}{\sum _{i=1}^{n}f{_{i}}} \end{aligned}$$</div> <div class="EquationNumber">(12)</div></div><div id="Equ13" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} \mathrm{Arousal}_{\mathrm{tweet}} = \frac{\sum _{i=1}^{n} a_{i}f_{i}}{\sum _{i=1}^{n}f{_{i}}} \end{aligned}$$</div> <div class="EquationNumber">(13)</div></div><div id="Tab5" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 5</span> <p class="SimplePara">Comparing the classification results of Emotex with ANEW lexical approach based on precision, recall and F-measure <span class="InlineEquation" id="IEq59">\((\beta =1)\)</span></p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"><col class="tcol7 align-left"></colgroup><thead><tr><th rowspan="2"> <p class="SimplePara">Emotion classes</p> </th><th colspan="3"> <p class="SimplePara">Emotex</p> </th><th colspan="3"> <p class="SimplePara">Lexical method</p> </th></tr><tr><th> <p class="SimplePara">Prec.</p> </th><th> <p class="SimplePara">Rec.</p> </th><th> <p class="SimplePara">FM</p> </th><th> <p class="SimplePara">Prec.</p> </th><th> <p class="SimplePara">Rec.</p> </th><th> <p class="SimplePara">FM</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Happy-Active</p> </td><td> <p class="SimplePara">84.2</p> </td><td> <p class="SimplePara">95.4</p> </td><td> <p class="SimplePara">89.5</p> </td><td> <p class="SimplePara">54.4</p> </td><td> <p class="SimplePara">60.6</p> </td><td> <p class="SimplePara">57.3</p> </td></tr><tr><td> <p class="SimplePara">Happy-Inactive</p> </td><td> <p class="SimplePara">94.3</p> </td><td> <p class="SimplePara">84.4</p> </td><td> <p class="SimplePara">89.1</p> </td><td> <p class="SimplePara">64.2</p> </td><td> <p class="SimplePara">58.5</p> </td><td> <p class="SimplePara">61.2</p> </td></tr><tr><td> <p class="SimplePara">Unhappy-Active</p> </td><td> <p class="SimplePara">91.4</p> </td><td> <p class="SimplePara">90.5</p> </td><td> <p class="SimplePara">91</p> </td><td> <p class="SimplePara">79.4</p> </td><td> <p class="SimplePara">44</p> </td><td> <p class="SimplePara">56.6</p> </td></tr><tr><td> <p class="SimplePara">Unhappy-Inactive</p> </td><td> <p class="SimplePara">91.2</p> </td><td> <p class="SimplePara">88.4</p> </td><td> <p class="SimplePara">89.8</p> </td><td> <p class="SimplePara">91.5</p> </td><td> <p class="SimplePara">52.5</p> </td><td> <p class="SimplePara">66.7</p> </td></tr></tbody></table></div></div><div id="Tab6" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 6</span> <p class="SimplePara">Results of binary classification in live stream of tweets</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"></colgroup><thead><tr><th>&nbsp;</th><th> <p class="SimplePara">Total tweets</p> </th><th> <p class="SimplePara">After preprocessing</p> </th><th> <p class="SimplePara">Emotion tweets</p> </th><th> <p class="SimplePara">No-emotion tweets</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Number</p> </td><td> <p class="SimplePara">105,134</p> </td><td> <p class="SimplePara">104,924</p> </td><td> <p class="SimplePara">56,472</p> </td><td> <p class="SimplePara">48,452</p> </td></tr><tr><td> <p class="SimplePara">Percent</p> </td><td> <p class="SimplePara">100%</p> </td><td> <p class="SimplePara">99.8%</p> </td><td> <p class="SimplePara">53.7%</p> </td><td> <p class="SimplePara">46.1%</p> </td></tr></tbody></table></div></div></div><p id="Par79" class="Para">where n is the number of affect words occurring in the tweet, <span class="InlineEquation" id="IEq60">\(f_i\)</span> is the frequency of the <em class="EmphasisTypeItalic ">i</em>th affect word, and <span class="InlineEquation" id="IEq61">\(v_i \)</span> and <span class="InlineEquation" id="IEq62">\(a_i\)</span> are the valence and arousal of the <em class="EmphasisTypeItalic ">i</em>th affect word, respectively.</p><div id="Par80" class="Para">Then using the following heuristic the message can be easily classified: Less than 5 means low arousal<span class="InlineEquation" id="IEq63">\(\slash \)</span>valence,
 more than 5 means high arousal/valence, and equal to 5 is neutral. For 
example, the tweet “Family and friends made this Christmas great for 
me.” with the affect words family, friends and christmas, the valence 
and arousal values are as following:<div id="Equ16" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned}
 \mathrm{Valence}= &amp; {} (7.74 + 7.65 +7.8 ) \mathbin {/} 3 ~= 7.73\\
 \mathrm{Arousal}= &amp; {} (5.74 + 4.8 + 6.27) \mathbin {/} 3 ~= 5.60 
\end{aligned}$$</div></div>Since both valence and arousal are larger 
than five, the tweet is labeled as happy-active. We compare the 
performance of Emotex with the lexical approach in classifying our 
labeled data shown in Table<span class="InternalRef"><a href="#Tab1">1</a></span>. Table&nbsp;<span class="InternalRef"><a href="#Tab5">5</a></span>
 lists the classification results of Emotex and the lexical approach in 
classifying different emotion classes. As the table shows, the F-score 
of Emotex is about 30% higher than the lexical approach utilizing ANEW 
lexicon.</div></section></section><section id="Sec22" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.2 </span>Online classification: classifying live streams of tweets</h3><p id="Par81" class="Para">After building the Emotex system as described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec18">4.1</a></span>,
 we now deploy it to classify emotion in live streams of tweets. For 
this purpose, we develop EmotexStream framework presented in Sect.&nbsp;<span class="InternalRef"><a href="#Sec15">3.2</a></span>.
 Based on the EmotexStream system, we first detect emotion-present 
tweets and separate them from emotion-absent tweets. Therefore, we 
utilize our binary classifier developed using several emotion lexicons. 
For the binary classification experiment, we collect a large amount of 
general tweets from USA without filtering them by any specific hashtag 
or keyword (see Table&nbsp;<span class="InternalRef"><a href="#Tab6">6</a></span>).
 After cleaning up the noise, we classify them using our binary 
classifier. Emotion-present tweets will then go through the feature 
selection and multi-class emotion classifier generated by our Emotex 
system to classify them based on our defined classes of emotion. 
Table&nbsp;<span class="InternalRef"><a href="#Tab6">6</a></span> shows 
the results of our binary classification experiment. It is interesting 
to observe that in a random sample of tweets the majority does in fact 
contain identifiable emotion.</p><p id="Par82" class="Para">We also 
evaluate the accuracy of our binary classifier through a user study. We 
randomly select a sample set of general tweets including 50 tweets from 
the dataset described in Table&nbsp;<span class="InternalRef"><a href="#Tab6">6</a></span>.
 Then we ask 25 graduate students to manually classify them. They 
classified each tweet into two groups namely, emotion-present tweets 
versus emotion-free tweets (i.e., tweets with explicit emotion versus 
tweets without any emotion). Fleiss-Kappa for the labelers is 0.28 which
 shows a fair agreement. The manual label of each sample tweet is 
selected based on the majority votes of labelers for that tweet. There 
were three tweets which didn’t receive the absolute majority of the 
votes. We didn’t consider them in our evaluation. After creating manual 
labels, we classified the selected sample tweets using our binary 
classifier and compared them with manually classified results. The 
manual labels served as the ground truth labels. We generated our binary
 classifier results using two different lexicons LIWC and ANEW.</p><div id="Par83" class="Para">Table&nbsp;<span class="InternalRef"><a href="#Tab7">7</a></span> shows the precision, recall and F-measure <span class="InlineEquation" id="IEq64">\((\beta =1)\)</span>
 of the binary classifier through comparison with the manual 
classification. As the results show, using a larger lexicon (i.e., LIWC 
and ANEW) increased recall and F-measure, compared with using only one 
lexicon. Therefore, for the binary classification task we use a 
multi-lexicon by combining different lexicons. A larger lexicon 
increases recall, but may decrease precision.<div id="Tab7" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 7</span> <p class="SimplePara">Evaluating binary classification results by comparing them with manually classification results</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Lexicon</p> </th><th> <p class="SimplePara">Precision (%)</p> </th><th> <p class="SimplePara">Recall (%)</p> </th><th> <p class="SimplePara">F-Measure (%)</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">LIWC</p> </td><td> <p class="SimplePara">93</p> </td><td> <p class="SimplePara">77</p> </td><td> <p class="SimplePara">84.3</p> </td></tr><tr><td> <p class="SimplePara">ANEW</p> </td><td> <p class="SimplePara">74</p> </td><td> <p class="SimplePara">82</p> </td><td> <p class="SimplePara">77.8</p> </td></tr><tr><td> <p class="SimplePara">LIWC&amp; ANEW</p> </td><td> <p class="SimplePara">78</p> </td><td> <p class="SimplePara">95</p> </td><td> <p class="SimplePara">85.6</p> </td></tr></tbody></table></div></div></div></section><section id="Sec23" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.3 </span>Detecting emotion bursts in live tweet streams</h3><p id="Par84" class="Para">Using
 EmotexStream, we are able to classify live streams of tweets in 
real-time. We now use this system to measure and analyze public emotion 
in a specific location. The objective of this experiment is to observe 
the temporal distribution of crowd emotion and detect important moments 
during the real-life events. We select the death of Eric Garner in New 
York<sup><a href="#Fn1" id="Fn1_source">1</a></sup> which stirred public
 protests and rallies with charges of police brutality. Eric Garner died
 after a police officer put him in a choke-hold, which caused many 
discussions on social media. On December 3, 2014, a grand jury decided 
not to indict the police officer. We utilize the Twitter search API to 
search for tweets containing a specified set of hashtags. We collected 
4K tweets containing the hashtag “Garner” from November 24, 2015 until 
January 5, 2015 posted in New York. After collecting tweets, we classify
 them using our EmotexStream model (see Sect.&nbsp;<span class="InternalRef"><a href="#Sec15">3.2</a></span>).
 Then, the emotion-classified tweets are aggregated into a daily-based 
histogram. Finally, using the methodology described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec16">3.3</a></span> we measure public emotion and detect emotion-critical moments.</p><div id="Par86" class="Para">Figure&nbsp;<span class="InternalRef"><a href="#Fig10">10</a></span>
 presents the temporal changes of different classes of emotion in New 
York during the selected event. The important moments are also specified
 in this figure. The distribution shows a predominance of sad and angry 
emotions over happy emotion in many days during the event. In order to 
predict the important moments as emotion bursts, we apply a sliding 
window <span class="InlineEquation" id="IEq65">\(W_{\mathrm{event}}\)</span> of length one day over the emotion stream of tweets aggregated in daily bins, as described in Sect.&nbsp;<span class="InternalRef"><a href="#Sec16">3.3</a></span>. Also a reference weekly window <span class="InlineEquation" id="IEq66">\(W_{\mathrm{general}}\)</span>
 is applied over the general stream of tweets to calculate the average 
rate of each emotion class. Then, we continuously monitor the frequency 
rate <span class="InlineEquation" id="IEq67">\(E_{\mathrm{public}}(Tc-W_{\mathrm{event}}, Tc, L, E_{c1})\)</span> over time for each emotion class <span class="InlineEquation" id="IEq68">\(E_{c1}\)</span>. Whenever this rate for an emotion class exceeds the upper threshold of <span class="InlineEquation" id="IEq69">\(\beta \)</span> or falls beneath the lower limit <span class="InlineEquation" id="IEq70">\(\alpha \)</span>, an emotion burst is reported. Table&nbsp;<span class="InternalRef"><a href="#Tab8">8</a></span>
 presents the days of abrupt changes in happiness. The second row shows 
the frequency rate of emotion bursts which are out of range. The last 
row shows the low and high boundaries. Comparing the results of this 
table with the important moments specified in Fig.&nbsp;<span class="InternalRef"><a href="#Fig10">10</a></span> confirms that our method is able to detect emotion-critical moments.<figure class="Figure" id="Fig10"><div class="MediaObject" id="MO26"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1007%2Fs41060-018-0096-z/MediaObjects/41060_2018_96_Fig10_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="41060_2018_96_Fig10_HTML.gif" alt="Fig. 10"></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 10</span> <p class="SimplePara">Changes of emotion about selected sad events in New York</p> </div></figcaption></figure><div id="Tab8" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 8</span> <p class="SimplePara">Detected burst changes in happiness</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"><col class="tcol7 align-left"><col class="tcol8 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Date</p> </th><th> <p class="SimplePara">Nov 26</p> </th><th> <p class="SimplePara">Nov 29</p> </th><th> <p class="SimplePara">Dec 19</p> </th><th> <p class="SimplePara">Dec 20</p> </th><th> <p class="SimplePara">Dec 27</p> </th><th> <p class="SimplePara">Dec 28</p> </th><th> <p class="SimplePara">Dec 30</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Happy rate</p> </td><td> <p class="SimplePara">210</p> </td><td> <p class="SimplePara">175</p> </td><td> <p class="SimplePara">576</p> </td><td> <p class="SimplePara">462</p> </td><td> <p class="SimplePara">463</p> </td><td> <p class="SimplePara">360</p> </td><td> <p class="SimplePara">503</p> </td></tr><tr><td> <p class="SimplePara">Boundary<span class="InlineEquation" id="IEq71">\((\alpha , \beta )\)</span></p> </td><td> <p class="SimplePara">(360, 936)</p> </td><td> <p class="SimplePara">(400, 1040)</p> </td><td> <p class="SimplePara">(641, 1668)</p> </td><td> <p class="SimplePara">(753, 1957)</p> </td><td> <p class="SimplePara">(573, 1491)</p> </td><td> <p class="SimplePara">(461, 1199)</p> </td><td> <p class="SimplePara">(561, 1459)</p> </td></tr></tbody></table></div></div></div></section></div></section><section id="Sec24" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">5 </span>Evaluating the emotex labeling method<span class="section-icon"></span></h2><div class="content"><p id="Par87" class="Para">In
 the preceding sections, we have assumed that hashtags are true labels 
of the emotions expressed in text messages. However, the question still 
remains whether this assumption is correct. To answer this question, we 
need to determine whether human annotators would categorize texts into 
the same emotion classes selected by automatic labeling using hashtags. 
To evaluate the accuracy of hashtags as emotion labels, we performed two
 user studies in which two different classes of annotators participated.
 First, psychology experts (counselors and psychology graduate students)
 and then psychology novices (the crowd) were asked to classify texts 
into emotion classes.</p><section id="Sec25" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">5.1 </span>Comparing hashtag labels with crowdsourced labels</h3><p id="Par88" class="Para">This
 user study compares the accuracy of emotion labels that are created 
automatically using hashtags with labels made by nonexpert annotators 
(the crowd). We design the study by randomly selecting 120 tweets (i.e.,
 30 tweets from each emotion class) from our collected emotion-labeled 
tweets (see Sect.&nbsp;<span class="InternalRef"><a href="#Sec18">4.1</a></span>).
 The tweets are shuffled to make their order random. Any embedded 
hashtags were removed from these 120 tweets as they are to serve as 
potential labels. Then the participants were asked to indicate the 
emotion expressed in each message by selecting the pleasure level (high 
for happy or low for unhappy), and the arousal level (high for active or
 low for inactive). We recruited labelers from the students in an 
introductory psychology class at Worcester Polytechnic Institute. Our 
user study was run online using the Qualtrics<sup><a href="#Fn2" id="Fn2_source">2</a></sup> survey system for three months. Sixty students participated and 49 students completed the survey.</p><p id="Par90" class="Para">The
 perception of emotions expressed in texts tends to be subjective and 
diverse. As expected, inconsistencies occurred in the answers, such that
 in some cases different participants categorized the same text into 
different classes. Thus, we measure to what degree the participants 
agreed on the level of pleasure or activation of each tweet. We utilized
 Fleiss-Kappa to measure the level of agreement between a fixed number 
of labelers in classifying subjects. The Fleiss-Kappa value for 
inter-labeler agreement of the pleasure level of tweets was 0.67, which 
corresponds to a substantial agreement. This value for the activation 
level was 0.25 which shows a low level of agreement. In summary, 
although the annotators substantially agreed on the level of pleasure, 
there was a relatively low agreement among them for the level of 
activation. This conclusion can be explained by the fact that authors of
 text messages tend to express pleasure in explicit and unambiguous 
terms. For example, the tweet “Final weeks is going to be a death of 
me!” shows sadness. However, it does’t clearly indicate the level of 
arousal (i.e., activation).</p><p id="Par91" class="Para">The result of 
this study indicates that the labels created by nonexperts to classify 
emotion in texts are not sufficiently reliable. This casts doubt on the 
use of the crowd (i.e., via Amazon Mechanical Turk) for this particular 
task of emotion classification. Note that participants in our study are a
 relatively notable crowd, as they are students in psychology that are 
trained to do user studies and have a general interest.</p></section><section id="Sec26" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">5.2 </span>Comparing hashtag labels with expert labels</h3><p id="Par92" class="Para">As
 the results of previous study indicates the level of agreement among 
crowd labelers is not sufficient to be able to consider them as ground 
truth especially for evaluating hashtag labels. Instead we sought the 
help of domain experts for labeling. We asked three psychology experts 
to manually label 120 tweets (the same set of tweets that had been 
utilized in Sect.&nbsp;<span class="InternalRef"><a href="#Sec25">5.1</a></span>).
 One of the experts is the director of counseling at WPI Student 
Development and Counseling Centre. The other two experts are graduate 
students in psychology who have been trained to classify emotions.</p><div id="Par93" class="Para">The
 Fleiss-Kappa measure of agreement between experts for the pleasure 
level of tweets is 0.84 which constitutes a high level of agreement. 
This value for the activation level is 0.64 which shows a substantial 
agreement. Table&nbsp;<span class="InternalRef"><a href="#Tab9">9</a></span>
 lists the Fleiss-Kappa values of crowd labelers versus expert labelers.
 The agreement between experts is much higher than the agreement between
 crowd labelers. These results indicate that emotion labeling by trained
 experts is more reliable. It thus is more appropriate to be utilized as
 the ground truth. However, we note that if experts are used to label 
messages, crowdsourcing will be prohibitively expensive.<div id="Tab9" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 9</span> <p class="SimplePara">Comparing Fleiss-Kappa values of crowd and expert labelers</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Labeler</p> </th><th> <p class="SimplePara">Pleasure level</p> </th><th> <p class="SimplePara">Activation level</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Crowd Labeler</p> </td><td> <p class="SimplePara">0.67</p> </td><td> <p class="SimplePara">0.25</p> </td></tr><tr><td> <p class="SimplePara">Expert Labeler</p> </td><td> <p class="SimplePara">0.84</p> </td><td> <p class="SimplePara">0.64</p> </td></tr></tbody></table></div></div><div id="Tab10" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 10</span> <p class="SimplePara">Accuracy of hashtag labels based on expert labels</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Expert</p> </th><th> <p class="SimplePara">Counseling director</p> </th><th> <p class="SimplePara">Trained expert1</p> </th><th> <p class="SimplePara">Trained expert2</p> </th><th> <p class="SimplePara">Experts consensus</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Accuracy</p> </td><td> <p class="SimplePara">81%</p> </td><td> <p class="SimplePara">81%</p> </td><td> <p class="SimplePara">84%</p> </td><td> <p class="SimplePara"><strong class="EmphasisTypeBold ">88</strong>%</p> </td></tr></tbody></table></div></div></div><p id="Par94" class="Para">We now utilize the expert labels to evaluate the accuracy of hashtags. Table&nbsp;<span class="InternalRef"><a href="#Tab10">10</a></span>
 lists the accuracy of hashtags based on expert labels. Hashtag labels 
are same as expert labels in 102 tweets. There are 14 tweets for which 
their hashtag labels are different from the expert labels. Also there is
 no consensus among experts about 4 tweets. Therefore, in about 88% of 
the cases, emotions indicated by hashtags embedded in tweets accurately 
captured the author’s emotion indicated by the ground truth (i.e., 
expert labels). Most of the mismatches between hashtags and expert 
labels belong to the arousal level of tweets (i.e., active or inactive),
 which is not an intuitive concept to understand by nonpsychologists.</p></section></div></section><section id="Sec27" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">6 </span>Related work on emotion detection in text<span class="section-icon"></span></h2><div class="content"><p id="Par95" class="Para">This
 section briefly surveys prior work on classifying emotion in texts. 
Emotion detection methods can be divided into lexicon-based methods and 
machine learning methods.</p><section id="Sec28" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">6.1 </span>Lexicon-based methods</h3><p id="Par96" class="Para">Most research on textual emotion recognition is based on building and employing emotion lexicons [<span class="CitationRef"><a href="#CR22" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">22</a></span>, <span class="CitationRef"><a href="#CR35" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">35</a></span>, <span class="CitationRef"><a href="#CR36" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">36</a></span>].
 Lexicon-based methods rely on lexical resources such as lexicons, set 
of words or ontologies. They usually start with a small set of seed 
words. Then they bootstrap this set through synonym detection or online 
resources to collect a larger lexicon. Ma et al. [<span class="CitationRef"><a href="#CR35" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">35</a></span>] searched WordNet for emotional words for all 6 emotional types defined by Ekman [<span class="CitationRef"><a href="#CR19" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">19</a></span>].
 They then assigned weights to those words according to the proportion 
of Synsets with emotional association that the words belong to. 
Strapparava and Mihalcea [<span class="CitationRef"><a href="#CR22" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">22</a></span>]
 constructed a large lexicon annotated for six basic emotions: anger, 
disgust, fear, joy, sadness and surprise. They used linguistic 
information from WordNet Affect [<span class="CitationRef"><a href="#CR38" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">38</a></span>].</p><p id="Par97" class="Para">In another work, Choudhury et al. [<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>]
 identified a lexicon of more than 200 moods frequently observed on 
Twitter. Inspired by the Circumplex model, they measured the valence and
 arousal of each mood using mechanical turk and psychology literature 
sources. Then, they collected posts which had at least one of the moods 
in their mood lexicon as indicated by a hashtag at the end of a post.</p><p id="Par98" class="Para">Mohammed et al. [<span class="CitationRef"><a href="#CR39" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">39</a></span>] and Wang et al. [<span class="CitationRef"><a href="#CR1" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">1</a></span>]
 collected emotion-labeled tweets using hashtags for several basic 
emotions including joy, sadness, anger, fear, and surprise. They showed 
through experiments that emotion hashtags are relevant and match with 
the annotations of trained judges. Canales et al. also collected 
emotion-labeled corpora using a bootstrapping process [<span class="CitationRef"><a href="#CR40" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">40</a></span>]. They annotated sentences from blogs posts based on the Ekman’s six basic emotions [<span class="CitationRef"><a href="#CR19" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">19</a></span>].</p><p id="Par99" class="Para">Recently,
 researchers have explored social media such as Twitter to investigate 
its potential to detect depressive disorders. Park <em class="EmphasisTypeItalic ">et al.</em> [<span class="CitationRef"><a href="#CR5" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">5</a></span>]
 ran studies to capture the depressive mood of users in Twitter. They 
studied 69 individuals to understand how their depressive states are 
reflected in their tweets. They found that people post about their 
depression and even their treatments on social media. Their results 
showed that participants with depression exhibited an increased usage of
 words related to negative emotions and anger in their tweets. Another 
effort for emotion analysis on Twitter data was undertaken by Bollen et 
al. [<span class="CitationRef"><a href="#CR20" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">20</a></span>].
 They extracted 6 basic emotions (tension, depression, anger, vigor, 
fatigue, confusion) using an extended version of POMS (Profile of Mood 
States). They found that social, political, cultural and economic events
 have a significant and immediate effect on the public mood.</p></section><section id="Sec29" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">6.2 </span>Machine learning-based methods</h3><p id="Par100" class="Para">Machine
 Learning methods apply statistical algorithms on linguistic features, 
which can be supervised or unsupervised. A few researchers applied 
supervised learning methods to identify emotions in texts. Choudhury et 
al. [<span class="CitationRef"><a href="#CR4" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">4</a></span>]
 detected depressive disorders by measuring behavioral attributes 
including social engagement, emotion, language and linguistic styles, 
ego network, and mentions of antidepressant medication. Then they 
leveraged these behavioral features to build a statistical classifier 
that estimates the risk of depression. They crowdsourced data from 
Twitter users who have been diagnosed with mental disorders. Their 
models showed an accuracy of 70% in predicting depression.</p><p id="Par101" class="Para">Another work accomplished by Qadir et al. [<span class="CitationRef"><a href="#CR41" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">41</a></span>]
 to learn lists of emotion hashtags using a bootstrapping framework. 
Starting with a small number of seed hashtags, they trained emotion 
classifiers to identify and score candidate emotion hashtags. They 
collected hashtags for five emotion classes including affection, anger, 
anxiety, joy and sadness.</p><p id="Par102" class="Para">Purver et al. [<span class="CitationRef"><a href="#CR21" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">21</a></span>]
 tried to train supervised classifiers for emotion detection in Twitter 
messages using automatically labeled data. They used the 6 basic 
emotions identified by Ekman [<span class="CitationRef"><a href="#CR19" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">19</a></span>]
 including happiness, sadness, anger, fear, surprise and disgust. They 
used a collection of Twitter messages, all marked with emoticons or 
hashtags corresponding to one of six emotion classes, as their labeled 
data. Their method did better for some emotions (happiness, sadness and 
anger) than others (fear, surprise and disgust). Their work is similar 
to ours, however they used categorical emotion models and their overall 
accuracies (60%) were much lower than the accuracy achieved by our 
approach.</p><p id="Par103" class="Para">Another supervised learning work with categorical emotion models is done by Suttles and Ide [<span class="CitationRef"><a href="#CR42" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">42</a></span>].
 They classify emotions according to a set of eight basic bipolar 
emotions defined by Plutchick including anger, disgust, fear, happiness,
 sadness, surprise, trust and anticipation. This allows them to treat 
the multi-class problem of emotion classification as a binary problem 
for opposing emotion pairs.</p><p id="Par104" class="Para">An unsupervised method was proposed by Agrawal and An [<span class="CitationRef"><a href="#CR43" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">43</a></span>].
 They presented an unsupervised context-based approach based on a 
methodology that does not depend on any existing affect lexicon; 
therefore, their model is flexible to classify texts beyond Ekman’s 
model of six basic emotions. Another unsupervised approach was developed
 by Calvo et al. [<span class="CitationRef"><a href="#CR24" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">24</a></span>]. They proposed an unsupervised method using dimensional emotion model. They used a normative database ANEW [<span class="CitationRef"><a href="#CR26" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">26</a></span>]
 to produce tree-dimensional vectors (valence, arousal, dominance) for 
each document. They also compared this method with different categorical
 approaches. For the categorical approaches three dimensionality 
reduction techniques: Latent Semantic Analysis (LSA), Probabilistic 
Latent Semantic Analysis (PLSA) and Nonnegative Matrix Factorization 
(NMF) were evaluated. Their experiments showed that the categorical 
model using NMF and the dimensional model tend to perform best.</p></section></div></section><section id="Sec30" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1"><span class="HeadingNumber">7 </span>Conclusion<span class="section-icon"></span></h2><div class="content"><p id="Par105" class="Para">In
 this paper, we study the problem of automatic emotion detection in text
 stream messages. We develop and evaluate a supervised machine learning 
system to automatically classify emotion in text streams. Our approach 
includes two main tasks: an offline training task and an online 
classification task. We develop a system called Emotex to create models 
for classifying emotion during the first task. Our experiments show that
 created models correctly classify emotion in 90% of text messages. For 
the second task, we develop a two-stage framework called EmotexStream to
 classify live streams of tweets for the real-time emotion tracking. 
First it creates a binary classifier to separate tweets with explicit 
emotion from tweets without emotion. Then it conducts a fine-grained 
emotion classification on tweets with explicit emotion using Emotex. 
Moreover, we propose an online method to measure public emotion and 
detect emotion-intensive moments in live streams of text messages.</p><p id="Par106" class="Para">To
 address the problem of fuzzy boundary and variations in expression and 
perception of emotions, a dimensional emotion model is utilized to 
define emotion classes. Furthermore, a soft (fuzzy) classification 
approach is proposed to measure the probability of assigning a message 
into each emotion class.</p></div></section><section id="Footnotes" class="FootnoteSection Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1">Footnotes<span class="section-icon"></span></h2><div class="content"><ol><li class="Footnote"><span class="FootnoteNumber"><a href="#Fn1_source">1</a>.</span><div class="FootnoteContent" id="Fn1"><p id="Par85" class="Para"><span class="ExternalRef"><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Death_of_Eric_Garner"><span class="RefSource">https://en.wikipedia.org/wiki/Death_of_Eric_Garner</span></a></span>.</p></div></li><li class="Footnote"><span class="FootnoteNumber"><a href="#Fn2_source">2</a>.</span><div class="FootnoteContent" id="Fn2"><p id="Par89" class="Para"><span class="ExternalRef"><a target="_blank" rel="noopener" href="http://www.qualtrics.com/"><span class="RefSource">http://www.qualtrics.com</span></a></span>.</p></div></li></ol></div></section></div><section class="Section1 RenderAsSection1" id="Bib1" tabindex="-1"><h2 class="Heading" data-role="collapsible-handle" tabindex="-1">References<span class="section-icon"></span></h2><div class="content"><ol class="BibliographyWrapper"><li class="Citation"><div class="CitationNumber">1.</div><div class="CitationContent" id="CR1">Wang,
 W., Chen, L., Thirunarayan, K., Sheth, AP.: Harnessing twitter big data
 for automatic emotion identification. In: 2012 International Conference
 on Social Computing (SocialCom), pp 587–592. IEEE (2012)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Wang%2C%20W.%2C%20Chen%2C%20L.%2C%20Thirunarayan%2C%20K.%2C%20Sheth%2C%20AP.%3A%20Harnessing%20twitter%20big%20data%20for%20automatic%20emotion%20identification.%20In%3A%202012%20International%20Conference%20on%20Social%20Computing%20%28SocialCom%29%2C%20pp%20587%E2%80%93592.%20IEEE%20%282012%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">2.</div><div class="CitationContent" id="CR2">De&nbsp;Choudhury,
 M., Counts, S., Gamon, M.: Not all moods are created equal! exploring 
human emotional states in social media. In: ICWSM’12 (2012)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=De%C2%A0Choudhury%2C%20M.%2C%20Counts%2C%20S.%2C%20Gamon%2C%20M.%3A%20Not%20all%20moods%20are%20created%20equal%21%20exploring%20human%20emotional%20states%20in%20social%20media.%20In%3A%20ICWSM%E2%80%9912%20%282012%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">3.</div><div class="CitationContent" id="CR3">Wakamiya,
 S., Belouaer, L., Brosset, D., Lee, R., Kawai, Y., Sumiya, K., 
Claramunt, C.: Measuring crowd mood in city space through twitter. In: 
International Symposium on Web and Wireless Geographical Information 
Systems, pp 37–49. Springer (2015)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Wakamiya%2C%20S.%2C%20Belouaer%2C%20L.%2C%20Brosset%2C%20D.%2C%20Lee%2C%20R.%2C%20Kawai%2C%20Y.%2C%20Sumiya%2C%20K.%2C%20Claramunt%2C%20C.%3A%20Measuring%20crowd%20mood%20in%20city%20space%20through%20twitter.%20In%3A%20International%20Symposium%20on%20Web%20and%20Wireless%20Geographical%20Information%20Systems%2C%20pp%2037%E2%80%9349.%20Springer%20%282015%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">4.</div><div class="CitationContent" id="CR4">Choudhury, MD., Gamon, M., Counts,S., Horvitz, E.: Predicting depression via social media. In: ICWSM’13, The AAAI Press (2013)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Choudhury%2C%20MD.%2C%20Gamon%2C%20M.%2C%20Counts%2CS.%2C%20Horvitz%2C%20E.%3A%20Predicting%20depression%20via%20social%20media.%20In%3A%20ICWSM%E2%80%9913%2C%20The%20AAAI%20Press%20%282013%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">5.</div><div class="CitationContent" id="CR5">Park,
 M., Cha, C., Cha, M .: (2012) Depressive moods of users portrayed in 
twitter. In: Proceedings of the ACM SIGKDD Workshop on Healthcare 
Informatics, HI-KDD<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Park%2C%20M.%2C%20Cha%2C%20C.%2C%20Cha%2C%20M%20.%3A%20%282012%29%20Depressive%20moods%20of%20users%20portrayed%20in%20twitter.%20In%3A%20Proceedings%20of%20the%20ACM%20SIGKDD%20Workshop%20on%20Healthcare%20Informatics%2C%20HI-KDD"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">6.</div><div class="CitationContent" id="CR6">Guthier,
 B., Alharthi, R., Abaalkhail, R., El&nbsp;Saddik A.: Detection and 
visualization of emotions in an affect-aware city. In: Proceedings of 
the 1st International Workshop on Emerging Multimedia Applications and 
Services for Smart Cities, pp 23–28. ACM (2014)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Guthier%2C%20B.%2C%20Alharthi%2C%20R.%2C%20Abaalkhail%2C%20R.%2C%20El%C2%A0Saddik%20A.%3A%20Detection%20and%20visualization%20of%20emotions%20in%20an%20affect-aware%20city.%20In%3A%20Proceedings%20of%20the%201st%20International%20Workshop%20on%20Emerging%20Multimedia%20Applications%20and%20Services%20for%20Smart%20Cities%2C%20pp%2023%E2%80%9328.%20ACM%20%282014%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">7.</div><div class="CitationContent" id="CR7">Resch,
 B., Summa, A., Zeile, P., Strube, M.: Citizen-centric urban planning 
through extracting emotion information from twitter in an 
interdisciplinary space-time-linguistics algorithm. Urban Plann. <strong class="EmphasisTypeBold ">1</strong>(2), 114–127 (2016)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.17645/up.v1i2.617"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Citizen-centric%20urban%20planning%20through%20extracting%20emotion%20information%20from%20twitter%20in%20an%20interdisciplinary%20space-time-linguistics%20algorithm&amp;author=B.%20Resch&amp;author=A.%20Summa&amp;author=P.%20Zeile&amp;author=M.%20Strube&amp;journal=Urban%20Plann.&amp;volume=1&amp;issue=2&amp;pages=114-127&amp;publication_year=2016"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">8.</div><div class="CitationContent" id="CR8">Kanhabua,
 N., Nejdl, W.: (2013) Understanding the diversity of tweets in the time
 of outbreaks. In: Proceedings of the 22nd international conference on 
World Wide Web companion, International World Wide Web Conferences 
Steering Committee, pp. 1335–1342<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kanhabua%2C%20N.%2C%20Nejdl%2C%20W.%3A%20%282013%29%20Understanding%20the%20diversity%20of%20tweets%20in%20the%20time%20of%20outbreaks.%20In%3A%20Proceedings%20of%20the%2022nd%20international%20conference%20on%20World%20Wide%20Web%20companion%2C%20International%20World%20Wide%20Web%20Conferences%20Steering%20Committee%2C%20pp.%201335%E2%80%931342"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">9.</div><div class="CitationContent" id="CR9">Hasan,
 M., Agu, E., Rundensteiner, E.: (2014) Using hashtags as labels for 
supervised learning of emotions in twitter messages. In: Proceedings of 
the ACM SIGKDD Workshop on Healthcare Informatics, HI-KDD<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Hasan%2C%20M.%2C%20Agu%2C%20E.%2C%20Rundensteiner%2C%20E.%3A%20%282014%29%20Using%20hashtags%20as%20labels%20for%20supervised%20learning%20of%20emotions%20in%20twitter%20messages.%20In%3A%20Proceedings%20of%20the%20ACM%20SIGKDD%20Workshop%20on%20Healthcare%20Informatics%2C%20HI-KDD"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">10.</div><div class="CitationContent" id="CR10">Go,
 A., Bhayani, R., Huang, L.: Twitter sentiment classification using 
distant supervision. CS224N Project Report, Stanford, pp 1–12 (2009)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Go%2C%20A.%2C%20Bhayani%2C%20R.%2C%20Huang%2C%20L.%3A%20Twitter%20sentiment%20classification%20using%20distant%20supervision.%20CS224N%20Project%20Report%2C%20Stanford%2C%20pp%201%E2%80%9312%20%282009%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">11.</div><div class="CitationContent" id="CR11">Pak,
 A., Paroubek, P.: Twitter as a corpus for sentiment analysis and 
opinion mining. In: Proceedings of the Seventh conference on 
International Language Resources and Evaluation (LREC’10), ELRA, 
Valletta, Malta (2010)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Pak%2C%20A.%2C%20Paroubek%2C%20P.%3A%20Twitter%20as%20a%20corpus%20for%20sentiment%20analysis%20and%20opinion%20mining.%20In%3A%20Proceedings%20of%20the%20Seventh%20conference%20on%20International%20Language%20Resources%20and%20Evaluation%20%28LREC%E2%80%9910%29%2C%20ELRA%2C%20Valletta%2C%20Malta%20%282010%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">12.</div><div class="CitationContent" id="CR12">Barbosa,
 L., Feng, J.: Robust sentiment detection on twitter from biased and 
noisy data. In: Proceedings of the 23rd ACL: Posters, Association for 
Computational Linguistics, pp 36–44 (2010)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Barbosa%2C%20L.%2C%20Feng%2C%20J.%3A%20Robust%20sentiment%20detection%20on%20twitter%20from%20biased%20and%20noisy%20data.%20In%3A%20Proceedings%20of%20the%2023rd%20ACL%3A%20Posters%2C%20Association%20for%20Computational%20Linguistics%2C%20pp%2036%E2%80%9344%20%282010%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">13.</div><div class="CitationContent" id="CR13">Kouloumpis,
 E., Wilson, T., Moore, J.: Twitter sentiment analysis: The good the bad
 and the omg! In: ICWSM’11, The AAAI Press (2011)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kouloumpis%2C%20E.%2C%20Wilson%2C%20T.%2C%20Moore%2C%20J.%3A%20Twitter%20sentiment%20analysis%3A%20The%20good%20the%20bad%20and%20the%20omg%21%20In%3A%20ICWSM%E2%80%9911%2C%20The%20AAAI%20Press%20%282011%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">14.</div><div class="CitationContent" id="CR14">Gunes,
 H., Schuller, B., Pantic, M., Cowie, R.: Emotion representation, 
analysis and synthesis in continuous space: A survey. In: 2011 IEEE 
International Conference on Automatic Face &amp; Gesture Recognition and
 Workshops (FG 2011), pp. 827–834. IEEE (2011)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Gunes%2C%20H.%2C%20Schuller%2C%20B.%2C%20Pantic%2C%20M.%2C%20Cowie%2C%20R.%3A%20Emotion%20representation%2C%20analysis%20and%20synthesis%20in%20continuous%20space%3A%20A%20survey.%20In%3A%202011%20IEEE%20International%20Conference%20on%20Automatic%20Face%20%26%20Gesture%20Recognition%20and%20Workshops%20%28FG%202011%29%2C%20pp.%20827%E2%80%93834.%20IEEE%20%282011%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">15.</div><div class="CitationContent" id="CR15">Wang,
 X., Wei, F., Liu, X., Zhou, M., Zhang, M.: Topic sentiment analysis in 
twitter: a graph-based hashtag sentiment classification approach. In: 
Proceedings of the 20th ACM international conference on Information and 
knowledge management, pp 1031–1040. ACM (2011)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Wang%2C%20X.%2C%20Wei%2C%20F.%2C%20Liu%2C%20X.%2C%20Zhou%2C%20M.%2C%20Zhang%2C%20M.%3A%20Topic%20sentiment%20analysis%20in%20twitter%3A%20a%20graph-based%20hashtag%20sentiment%20classification%20approach.%20In%3A%20Proceedings%20of%20the%2020th%20ACM%20international%20conference%20on%20Information%20and%20knowledge%20management%2C%20pp%201031%E2%80%931040.%20ACM%20%282011%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">16.</div><div class="CitationContent" id="CR16">Russell, J.A.: A circumplex model of affect. J. Personal. Soc. Psychol. <strong class="EmphasisTypeBold ">39</strong>, 1161–1178 (1980)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1037/h0077714"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=A%20circumplex%20model%20of%20affect&amp;author=JA.%20Russell&amp;journal=J.%20Personal.%20Soc.%20Psychol.&amp;volume=39&amp;pages=1161-1178&amp;publication_year=1980"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">17.</div><div class="CitationContent" id="CR17">Hasan,
 M., Rundensteiner, E., Agu, E.: Emotex: Detecting emotions in twitter 
messages. In: Proceedings of the Sixth ASE International Conference on 
Social Computing (SocialCom 2014), Academy of Science and Engineering 
(ASE), USA (2014)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Hasan%2C%20M.%2C%20Rundensteiner%2C%20E.%2C%20Agu%2C%20E.%3A%20Emotex%3A%20Detecting%20emotions%20in%20twitter%20messages.%20In%3A%20Proceedings%20of%20the%20Sixth%20ASE%20International%20Conference%20on%20Social%20Computing%20%28SocialCom%202014%29%2C%20Academy%20of%20Science%20and%20Engineering%20%28ASE%29%2C%20USA%20%282014%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">18.</div><div class="CitationContent" id="CR18">Russell,
 J.A., Barrett, L.F.: Core affect, prototypical emotional episodes, and 
other things called emotion: dissecting the elephant. J. Personal. Soc. 
Psychol. <strong class="EmphasisTypeBold ">76</strong>(5), 805 (1999)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1037/0022-3514.76.5.805"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Core%20affect%2C%20prototypical%20emotional%20episodes%2C%20and%20other%20things%20called%20emotion%3A%20dissecting%20the%20elephant&amp;author=JA.%20Russell&amp;author=LF.%20Barrett&amp;journal=J.%20Personal.%20Soc.%20Psychol.&amp;volume=76&amp;issue=5&amp;pages=805&amp;publication_year=1999"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">19.</div><div class="CitationContent" id="CR19">Ekman, P.: Basic emotions. Handb. Cognit. Emot. <strong class="EmphasisTypeBold ">98</strong>, 45–60 (1999)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Basic%20emotions&amp;author=P.%20Ekman&amp;journal=Handb.%20Cognit.%20Emot.&amp;volume=98&amp;pages=45-60&amp;publication_year=1999"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">20.</div><div class="CitationContent" id="CR20">Bollen,
 J., Mao, H., Pepe, A.: Modeling public mood and emotion: Twitter 
sentiment and socio-economic phenomena. In: ICWSM’11 (2011)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Bollen%2C%20J.%2C%20Mao%2C%20H.%2C%20Pepe%2C%20A.%3A%20Modeling%20public%20mood%20and%20emotion%3A%20Twitter%20sentiment%20and%20socio-economic%20phenomena.%20In%3A%20ICWSM%E2%80%9911%20%282011%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">21.</div><div class="CitationContent" id="CR21">Purver,
 M., Battersby, S.: Experimenting with distant supervision for emotion 
classification. In: Proceedings of the 13th EACL, Association for 
Computational Linguistics, pp. 482–491 (2012)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Purver%2C%20M.%2C%20Battersby%2C%20S.%3A%20Experimenting%20with%20distant%20supervision%20for%20emotion%20classification.%20In%3A%20Proceedings%20of%20the%2013th%20EACL%2C%20Association%20for%20Computational%20Linguistics%2C%20pp.%20482%E2%80%93491%20%282012%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">22.</div><div class="CitationContent" id="CR22">Strapparava,
 C., Mihalcea, R.: Learning to identify emotions in text. In: 
Proceedings of the 2008 ACM symposium on Applied computing, pp. 
1556–1560. ACM (2008)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Strapparava%2C%20C.%2C%20Mihalcea%2C%20R.%3A%20Learning%20to%20identify%20emotions%20in%20text.%20In%3A%20Proceedings%20of%20the%202008%20ACM%20symposium%20on%20Applied%20computing%2C%20pp.%201556%E2%80%931560.%20ACM%20%282008%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">23.</div><div class="CitationContent" id="CR23">Liu,
 H., Lieberman, H., Selker, T.: A model of textual affect sensing using 
real-world knowledge. In: Proceedings of the 8th international 
conference on Intelligent user interfaces, pp. 125–132. ACM (2003)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Liu%2C%20H.%2C%20Lieberman%2C%20H.%2C%20Selker%2C%20T.%3A%20A%20model%20of%20textual%20affect%20sensing%20using%20real-world%20knowledge.%20In%3A%20Proceedings%20of%20the%208th%20international%20conference%20on%20Intelligent%20user%20interfaces%2C%20pp.%20125%E2%80%93132.%20ACM%20%282003%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">24.</div><div class="CitationContent" id="CR24">Calvo, R.A., Mac Kim, S.: Emotions in text: dimensional and categorical models. Computat. Intell. <strong class="EmphasisTypeBold ">29</strong>(3), 527–543 (2013)<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=3093845"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1111/j.1467-8640.2012.00456.x"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Emotions%20in%20text%3A%20dimensional%20and%20categorical%20models&amp;author=RA.%20Calvo&amp;author=S.%20Mac%20Kim&amp;journal=Computat.%20Intell.&amp;volume=29&amp;issue=3&amp;pages=527-543&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">25.</div><div class="CitationContent" id="CR25">Princeton, U.: (2010) Wordnet. <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://wordnet.princeton.edu/"><span class="RefSource">http://wordnet.princeton.edu</span></a></span>
                     <span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">26.</div><div class="CitationContent" id="CR26">Bradley,
 M.M., Lang, P.J.: Affective norms for english words (anew): Instruction
 manual and affective ratings. In: Technical Report Citeseer (1999)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Bradley%2C%20M.M.%2C%20Lang%2C%20P.J.%3A%20Affective%20norms%20for%20english%20words%20%28anew%29%3A%20Instruction%20manual%20and%20affective%20ratings.%20In%3A%20Technical%20Report%20Citeseer%20%281999%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">27.</div><div class="CitationContent" id="CR27">Pennebaker,
 JW., Francis, ME., Booth, RJ.: Linguistic inquiry and word count: Liwc 
2001. Mahway: Lawrence Erlbaum Associates p. 71 (2001)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Pennebaker%2C%20JW.%2C%20Francis%2C%20ME.%2C%20Booth%2C%20RJ.%3A%20Linguistic%20inquiry%20and%20word%20count%3A%20Liwc%202001.%20Mahway%3A%20Lawrence%20Erlbaum%20Associates%20p.%2071%20%282001%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">28.</div><div class="CitationContent" id="CR28">rup
 Nielsen, F.: A new anew: evaluation of a word list for sentiment 
analysis in microblogs. In: Proceedings of the ESWC2011 Workshop on 
’Making Sense of Microposts’: Big things come in small packages, vol. 
718, pp. 93–98 (2011)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=rup%20Nielsen%2C%20F.%3A%20A%20new%20anew%3A%20evaluation%20of%20a%20word%20list%20for%20sentiment%20analysis%20in%20microblogs.%20In%3A%20Proceedings%20of%20the%20ESWC2011%20Workshop%20on%20%E2%80%99Making%20Sense%20of%20Microposts%E2%80%99%3A%20Big%20things%20come%20in%20small%20packages%2C%20vol.%20718%2C%20pp.%2093%E2%80%9398%20%282011%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">29.</div><div class="CitationContent" id="CR29">Liu, Y., Zhang, H.H., Wu, Y.: Hard or soft classification? Large-margin unified machines. J. Am. Stat. Assoc. <strong class="EmphasisTypeBold ">106</strong>(493), 166–177 (2011)<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2816711"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1198/jasa.2011.tm10319"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?06446594"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Hard%20or%20soft%20classification%3F%20Large-margin%20unified%20machines&amp;author=Y.%20Liu&amp;author=HH.%20Zhang&amp;author=Y.%20Wu&amp;journal=J.%20Am.%20Stat.%20Assoc.&amp;volume=106&amp;issue=493&amp;pages=166-177&amp;publication_year=2011"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">30.</div><div class="CitationContent" id="CR30">Zadrozny,
 B., Elkan, C.: Transforming classifier scores into accurate multiclass 
probability estimates. In: Proceedings of the eighth ACM SIGKDD 
international conference on Knowledge discovery and data mining, pp. 
694–699. ACM (2002)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Zadrozny%2C%20B.%2C%20Elkan%2C%20C.%3A%20Transforming%20classifier%20scores%20into%20accurate%20multiclass%20probability%20estimates.%20In%3A%20Proceedings%20of%20the%20eighth%20ACM%20SIGKDD%20international%20conference%20on%20Knowledge%20discovery%20and%20data%20mining%2C%20pp.%20694%E2%80%93699.%20ACM%20%282002%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">31.</div><div class="CitationContent" id="CR31">Platt,
 J., et al.: Probabilistic outputs for support vector machines and 
comparisons to regularized likelihood methods. Adv. Large Margin 
Classif. <strong class="EmphasisTypeBold ">10</strong>(3), 61–74 (1999)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Probabilistic%20outputs%20for%20support%20vector%20machines%20and%20comparisons%20to%20regularized%20likelihood%20methods&amp;author=J.%20Platt&amp;journal=Adv.%20Large%20Margin%20Classif.&amp;volume=10&amp;issue=3&amp;pages=61-74&amp;publication_year=1999"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">32.</div><div class="CitationContent" id="CR32">Hasan,
 M., Rundensteiner, E., Kong, X., Agu, E.: Using social sensing to 
discover trends in public emotion. In: 2017 IEEE 11th International 
Conference on Semantic Computing (ICSC), pp. 172–179. IEEE (2017)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Hasan%2C%20M.%2C%20Rundensteiner%2C%20E.%2C%20Kong%2C%20X.%2C%20Agu%2C%20E.%3A%20Using%20social%20sensing%20to%20discover%20trends%20in%20public%20emotion.%20In%3A%202017%20IEEE%2011th%20International%20Conference%20on%20Semantic%20Computing%20%28ICSC%29%2C%20pp.%20172%E2%80%93179.%20IEEE%20%282017%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">33.</div><div class="CitationContent" id="CR33">Branco, P., Torgo, L., Ribeiro, R.P.: A survey of predictive modeling on imbalanced domains. ACM Comput. Surv. (CSUR) <strong class="EmphasisTypeBold ">49</strong>(2), 31 (2016)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1145/2907070"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=A%20survey%20of%20predictive%20modeling%20on%20imbalanced%20domains&amp;author=P.%20Branco&amp;author=L.%20Torgo&amp;author=RP.%20Ribeiro&amp;journal=ACM%20Comput.%20Surv.%20%28CSUR%29&amp;volume=49&amp;issue=2&amp;pages=31&amp;publication_year=2016"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">34.</div><div class="CitationContent" id="CR34">Joachims,
 T.: Making large-scale SVM learning practical. In: Schölkopf, B., 
Burges, C.J., Smola, A. (eds.) Advances in Kernel Methods-Support Vector
 Learning. MIT Press, Cambridge (1999)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Making%20large-scale%20SVM%20learning%20practical&amp;author=T.%20Joachims&amp;publication_year=1999"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">35.</div><div class="CitationContent" id="CR35">Ma,
 C., Prendinger, H., Ishizuka, M.: Emotion estimation and reasoning 
based on affective textual interaction. In: Affective Computing and 
Intelligent Interaction, pp. 622–628. Springer (2005)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Ma%2C%20C.%2C%20Prendinger%2C%20H.%2C%20Ishizuka%2C%20M.%3A%20Emotion%20estimation%20and%20reasoning%20based%20on%20affective%20textual%20interaction.%20In%3A%20Affective%20Computing%20and%20Intelligent%20Interaction%2C%20pp.%20622%E2%80%93628.%20Springer%20%282005%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">36.</div><div class="CitationContent" id="CR36">Neviarouskaya,
 A., Prendinger, H., Ishizuka, M.: Textual affect sensing for sociable 
and expressive online communication. In: Affective Computing and 
Intelligent Interaction, pp. 218–229. Springer (2007)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Neviarouskaya%2C%20A.%2C%20Prendinger%2C%20H.%2C%20Ishizuka%2C%20M.%3A%20Textual%20affect%20sensing%20for%20sociable%20and%20expressive%20online%20communication.%20In%3A%20Affective%20Computing%20and%20Intelligent%20Interaction%2C%20pp.%20218%E2%80%93229.%20Springer%20%282007%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">37.</div><div class="CitationContent" id="CR37">Dodds,
 P.S., Danforth, C.M.: Measuring the happiness of large-scale written 
expression: songs, blogs, and presidents. J. Happiness Stud. <strong class="EmphasisTypeBold ">11</strong>(4), 441–456 (2010)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1007/s10902-009-9150-9"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Measuring%20the%20happiness%20of%20large-scale%20written%20expression%3A%20songs%2C%20blogs%2C%20and%20presidents&amp;author=PS.%20Dodds&amp;author=CM.%20Danforth&amp;journal=J.%20Happiness%20Stud.&amp;volume=11&amp;issue=4&amp;pages=441-456&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">38.</div><div class="CitationContent" id="CR38">Strapparava,
 C., Valitutti, A.: Wordnet affect: an affective extension of wordnet. 
In: Proceedings of 4th International Conference on Language Resources 
and Evaluation, LREC, vol 4, pp. 1083–1086 (2004)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Strapparava%2C%20C.%2C%20Valitutti%2C%20A.%3A%20Wordnet%20affect%3A%20an%20affective%20extension%20of%20wordnet.%20In%3A%20Proceedings%20of%204th%20International%20Conference%20on%20Language%20Resources%20and%20Evaluation%2C%20LREC%2C%20vol%204%2C%20pp.%201083%E2%80%931086%20%282004%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">39.</div><div class="CitationContent" id="CR39">Mohammad,
 SM.: # emotional tweets. In: Proceedings of the First Joint Conference 
on Lexical and Computational Semantics, Association for Computational 
Linguistics, pp. 246–255 (2012)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Mohammad%2C%20SM.%3A%20%23%20emotional%20tweets.%20In%3A%20Proceedings%20of%20the%20First%20Joint%20Conference%20on%20Lexical%20and%20Computational%20Semantics%2C%20Association%20for%20Computational%20Linguistics%2C%20pp.%20246%E2%80%93255%20%282012%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">40.</div><div class="CitationContent" id="CR40">Canales,
 L., Strapparava, C., Boldrini, E., Martnez-Barco, P.: Exploiting a 
bootstrapping approach for automatic annotation of emotions in texts. 
In: 2016 IEEE International Conference on Data Science and Advanced 
Analytics (DSAA), pp. 726–734. IEEE (2016)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Canales%2C%20L.%2C%20Strapparava%2C%20C.%2C%20Boldrini%2C%20E.%2C%20Martnez-Barco%2C%20P.%3A%20Exploiting%20a%20bootstrapping%20approach%20for%20automatic%20annotation%20of%20emotions%20in%20texts.%20In%3A%202016%20IEEE%20International%20Conference%20on%20Data%20Science%20and%20Advanced%20Analytics%20%28DSAA%29%2C%20pp.%20726%E2%80%93734.%20IEEE%20%282016%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">41.</div><div class="CitationContent" id="CR41">Qadir, A., Riloff, E.: Bootstrapped learning of emotion hashtags# hashtags4you. WASSA <strong class="EmphasisTypeBold ">2013</strong>, 2 (2013)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Bootstrapped%20learning%20of%20emotion%20hashtags%23%20hashtags4you&amp;author=A.%20Qadir&amp;author=E.%20Riloff&amp;journal=WASSA&amp;volume=2013&amp;pages=2&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">42.</div><div class="CitationContent" id="CR42">Suttles,
 J., Ide, N.: Distant supervision for emotion classification with 
discrete binary values. In: International Conference on Intelligent Text
 Processing and Computational Linguistics, pp. 121–136. Springer (2013)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Suttles%2C%20J.%2C%20Ide%2C%20N.%3A%20Distant%20supervision%20for%20emotion%20classification%20with%20discrete%20binary%20values.%20In%3A%20International%20Conference%20on%20Intelligent%20Text%20Processing%20and%20Computational%20Linguistics%2C%20pp.%20121%E2%80%93136.%20Springer%20%282013%29"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">43.</div><div class="CitationContent" id="CR43">Agrawal,
 A., An, A .: Unsupervised emotion detection from text using semantic 
and syntactic relations. In: Proceedings of the The 2012 IEEE/WIC/ACM 
International Joint Conferences on Web Intelligence and Intelligent 
Agent Technology-Volume 01, pp. 346–353. IEEE Computer Society (2012)<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Agrawal%2C%20A.%2C%20An%2C%20A%20.%3A%20Unsupervised%20emotion%20detection%20from%20text%20using%20semantic%20and%20syntactic%20relations.%20In%3A%20Proceedings%20of%20the%20The%202012%20IEEE%2FWIC%2FACM%20International%20Joint%20Conferences%20on%20Web%20Intelligence%20and%20Intelligent%20Agent%20Technology-Volume%2001%2C%20pp.%20346%E2%80%93353.%20IEEE%20Computer%20Society%20%282012%29"><span><span>Google Scholar</span></span></a></span></span></div></li></ol></div></section><section class="Section1 RenderAsSection1"><h2 class="Heading" id="copyrightInformation" data-role="collapsible-handle" tabindex="-1">Copyright information<span class="section-icon"></span></h2><div class="ArticleCopyright content"><div class="ArticleCopyright">©&nbsp;Springer International Publishing AG, part of Springer Nature&nbsp;2018</div></div></section></div>
                        </article>
                        <aside class="section section--collapsible" id="AboutThisContent">
    <h2 class="section__heading" id="aboutcontent" data-role="collapsible-handle" tabindex="-1">About this article<span class="section-icon"></span></h2>
    <div class="section__content bibliographic-information">
                <div id="crossMark" class="crossmark">
            <a data-crossmark="10.1007%2Fs41060-018-0096-z" class="gtm-crossmark" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007%2Fs41060-018-0096-z" title="Verify currency and authenticity via CrossMark">
                <span class="u-screenreader-only">CrossMark</span>
                <svg class="CrossMark" id="crossmark-icon" width="57" height="81">
                    <image width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="/springerlink-static/439917616/images/png/crossmark.png" xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/439917616/images/svg/crossmark.svg"></image>
                </svg>
            </a>
        </div>

        <div class="crossmark__adjacent">
            <dl class="citation-info u-highlight-target u-mb-16" id="citeas" tabindex="-1">
    <dt class="test-cite-heading">
        Cite this article as:
    </dt>
    <dd id="citethis-text">Hasan, M., Rundensteiner, E. &amp; Agu, E. Int J Data Sci Anal (2018). https://doi.org/10.1007/s41060-018-0096-z</dd>
</dl>
                <ul class="bibliographic-information__list bibliographic-information__list--inline">
        <li class="bibliographic-information__item">
            <span class="bibliographic-information__title"><abbr title="Digital Object Identifier">DOI</abbr></span>
            <span class="bibliographic-information__value u-overflow-wrap" id="doi-url">https://doi.org/10.1007/s41060-018-0096-z</span>
        </li>
            <li class="bibliographic-information__item">
                <span class="bibliographic-information__title">Publisher Name</span>
                <span class="bibliographic-information__value" id="publisher-name">Springer International Publishing</span>
            </li>
            <li class="bibliographic-information__item">
                <span class="bibliographic-information__title">Print ISSN</span>
                <span class="bibliographic-information__value" id="print-issn">2364-415X</span>
            </li>
            <li class="bibliographic-information__item ">
                <span class="bibliographic-information__title">Online ISSN</span>
                <span class="bibliographic-information__value" id="electronic-issn">2364-4168</span>
            </li>

        
    </ul>

            <ul class="bibliographic-information__list">
        <li class="bibliographic-information__item">
            <a id="about-journal" class="bibliographic-information__misc-links gtm-about-this" title="Visit Springer.com for information about this article's journal" href="https://www.springer.com/journal/41060/about">About this journal</a>
        </li>
        <li class="bibliographic-information__item">
            <a id="reprintsandpermissions-link" target="_blank" rel="noopener" href="https://s100.copyright.com/AppDispatchServlet?publisherName=SpringerNature&amp;orderBeanReset=true&amp;orderSource=SpringerLink&amp;copyright=Springer+International+Publishing+AG%2C+part+of+Springer+Nature&amp;author=Maryam+Hasan%2C+Elke+Rundensteiner%2C+Emmanuel+Agu&amp;contentID=10.1007%2Fs41060-018-0096-z&amp;openAccess=false&amp;endPage=17&amp;publicationDate=2018&amp;startPage=1&amp;title=Automatic+emotion+detection+in+text+streams+by+analyzing+Twitter+data&amp;imprint=Springer+International+Publishing+AG%2C+part+of+Springer+Nature&amp;publication=2364-415X" title="Visit RightsLink for information about reusing this article">Reprints and Permissions</a>
        </li>
</ul>



        </div>
      
      
          
    </div>
</aside>

                        <div class="section section--collapsible uptodate-recommendations gtm-recommendations">
    <h2 class="uptodate-recommendations__title section__heading gtm-recommendations__title" id="uptodaterecommendations" data-role="collapsible-handle" tabindex="-1">Personalised recommendations<span class="section-icon"></span></h2>
    <div class="section__content">
        <div class="uptodate-recommendations__container">
             <iframe style="width: 100%; height: 411px; bottom: 0px; right: 0px; z-index: 100000;" scrolling="no" src="https://recommended.springernature.com/v2197/generated/client.html?source=https://link.springer.com" name="uptodate-client" id="uptodate-client" title="Personalised recommendations" allowtransparency="true" frameborder="0"></iframe>
        </div>
    </div>
</div>
                                <div id="doubleclick-native-ad" data-component="SpringerLink.GoogleAds" data-namespace="native"><div id="google_ads_iframe_270604982/springerlink/41060/article_1__container__" style="border: 0pt none;"><iframe id="google_ads_iframe_270604982/springerlink/41060/article_1" title="3rd party ad content" name="google_ads_iframe_270604982/springerlink/41060/article_1" scrolling="no" marginwidth="0" marginheight="0" style="border: 0px none; vertical-align: bottom;" srcdoc="" width="2" frameborder="0" height="2"></iframe></div></div>

                                    <div class="sticky-banner u-interface u-js-screenreader-only" aria-hidden="true" data-component="SpringerLink.StickyBanner" data-namespace="hasButton">
                <div class="sticky-banner__container"><span class="sticky-banner__title sticky-banner__title--short u-overflow-ellipsis" title="Automatic emotion detection in text streams by analyzing Twitter data">Automatic emotion detection in text streams by analyzing Twitter data</span>
                        <div class="citations c-button-dropdown" data-component="SV.Dropdown" data-namespace="citationsSticky" aria-label="button with dropdown options">
        <button id="button-Dropdown-citationsSticky-dropdown" type="button" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown-citationsSticky-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</span><span class="c-button-dropdown__icon"></span></button>
<div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown-citationsSticky-dropdown"><ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" class="gtm-cite-dropdown" tabindex="-1">How to cite?</a>
    </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=refman&amp;flavour=citation" title="Download this article's citation as a .RIS file" class="gtm-export-citation" data-gtmlabel="RIS" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=endnote&amp;flavour=citation" title="Download this article's citation as a .ENW file" class="gtm-export-citation" data-gtmlabel="ENW" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=bibtex&amp;flavour=citation" title="Download this article's citation as a .BIB file" class="gtm-export-citation" data-gtmlabel="BIB" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul></div>
    </div>

                            <div>
        <a class="c-button share-this gtm-shareby-sharelink-link test-shareby-sharelink-link" data-test="shareable-link" target="_blank" rel="noopener" href="https://link.springer.com/sharelink/10.1007/s41060-018-0096-z">
            <span>Share</span>
            <span class="hide-text-small">article</span>
        </a>
    </div>




                                    <div>
            <a href="https://link.springer.com/content/pdf/10.1007%2Fs41060-018-0096-z.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right gtm-pdf-link" title="Download this article in PDF format" rel="noopener">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"></path></g></g></g></svg>
                <span class="hide-text-small">Download</span>
                <span>PDF</span>
            </a>
        </div>

                </div>
            </div>




                    </div>
                    <aside class="main-sidebar-right u-interface">
                        <div data-role="sticky-wrapper">
                            <div class="main-sidebar-right__content u-composite-layer" data-component="SpringerLink.StickySidebar">
                                <div class="article-actions" id="article-actions">
                                    <h2 class="u-screenreader-only">Actions</h2>


                                    <div class="u-js-hide u-js-show-two-col">
                                        

                                                <div class="download-article test-pdf-link">
                                                            <div>
            <a href="https://link.springer.com/content/pdf/10.1007%2Fs41060-018-0096-z.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right gtm-pdf-link" title="Download this article in PDF format" rel="noopener">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"></path></g></g></g></svg>
                <span class="hide-text-small">Download</span>
                <span>PDF</span>
            </a>
        </div>

                                                </div>


                                            <div class="citations c-button-dropdown" data-component="SV.Dropdown" data-namespace="citations" aria-label="button with dropdown options">
        <button id="button-Dropdown-citations-dropdown" type="button" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown-citations-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</span><span class="c-button-dropdown__icon"></span></button>
<div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown-citations-dropdown"><ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" class="gtm-cite-dropdown" tabindex="-1">How to cite?</a>
    </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=refman&amp;flavour=citation" title="Download this article's citation as a .RIS file" class="gtm-export-citation" data-gtmlabel="RIS" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=endnote&amp;flavour=citation" title="Download this article's citation as a .ENW file" class="gtm-export-citation" data-gtmlabel="ENW" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1007/s41060-018-0096-z?format=bibtex&amp;flavour=citation" title="Download this article's citation as a .BIB file" class="gtm-export-citation" data-gtmlabel="BIB" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul></div>
    </div>

                                                <div>
        <a class="c-button share-this gtm-shareby-sharelink-link test-shareby-sharelink-link" data-test="shareable-link" target="_blank" rel="noopener" href="https://link.springer.com/sharelink/10.1007/s41060-018-0096-z">
            <span>Share</span>
            <span class="hide-text-small">article</span>
        </a>
    </div>




                                    </div>
                                </div>
                                <nav class="toc" aria-label="article contents">
    <h2 class="u-h4 u-screenreader-only">Table of contents</h2>
    <ul id="article-contents" class="article-contents" role="menu" tabindex="-1">
            <li role="menuitem">
                <a title="Article" href="#enumeration"><span class="u-overflow-ellipsis">Article</span></a>
            </li>
            <li role="menuitem">
                <a title="Abstract" href="#Abs1"><span class="u-overflow-ellipsis">Abstract</span></a>
            </li>
            <li role="menuitem">
                <a title="1 Introduction" href="#Sec1"><span class="u-overflow-ellipsis">1 Introduction</span></a>
            </li>
            <li role="menuitem">
                <a title="2 Models of emotion" href="#Sec5"><span class="u-overflow-ellipsis">2 Models of emotion</span></a>
            </li>
            <li role="menuitem">
                <a title="3 Proposed approach to detect emotion in text stream messages" href="#Sec8"><span class="u-overflow-ellipsis">3 Proposed approach to detect emotion in text stream messages</span></a>
            </li>
            <li role="menuitem">
                <a title="4 Experimental results on classifying streams of Twitter messages" href="#Sec17"><span class="u-overflow-ellipsis">4 Experimental results on classifying streams of Twitter messages</span></a>
            </li>
            <li role="menuitem">
                <a title="5 Evaluating the emotex labeling method" href="#Sec24"><span class="u-overflow-ellipsis">5 Evaluating the emotex labeling method</span></a>
            </li>
            <li role="menuitem">
                <a title="6 Related work on emotion detection in text" href="#Sec27"><span class="u-overflow-ellipsis">6 Related work on emotion detection in text</span></a>
            </li>
            <li role="menuitem">
                <a title="7 Conclusion" href="#Sec30"><span class="u-overflow-ellipsis">7 Conclusion</span></a>
            </li>
            <li role="menuitem">
                <a title="Footnotes" href="#Footnotes"><span class="u-overflow-ellipsis">Footnotes</span></a>
            </li>
            <li role="menuitem">
                <a title="References" href="#Bib1"><span class="u-overflow-ellipsis">References</span></a>
            </li>
            <li role="menuitem">
                <a title="Copyright information" href="#copyrightInformation"><span class="u-overflow-ellipsis">Copyright information</span></a>
            </li>
            
            <li role="menuitem">
                <a title="About this article" href="#aboutcontent"><span class="u-overflow-ellipsis">About this article</span></a>
            </li>
    </ul>
</nav>

                            </div>
                                <div class="skyscraper-ad u-hide" data-component="SpringerLink.GoogleAds" data-namespace="skyscraper">
        <div class="skyscraper-ad__wrapper">
            <p class="skyscraper-ad__label">Advertisement</p>
            <button class="skyscraper-ad__hide" title="Hide this advertisement">Hide</button>
            <div id="doubleclick-ad" class="skyscraper-ad__ad"></div>
        </div>
    </div>

                        </div>
                    </aside>
                </div>
            </main>
                <footer class="footer u-interface">
        <div class="footer__aside-wrapper">
            <div class="footer__content">
                <div class="footer__aside">
                    <p class="footer__strapline">Over 10 million scientific documents at your fingertips</p>
                                <div class="footer__edition c-button-dropdown c-button-dropdown--ghost" data-component="SpringerLink.EditionSwitcher" aria-label="button with dropdown options">
                                    <button id="button-EditionSwitcher-9000154101-dropdown" type="button" title="Switch between Academic &amp; Corporate Edition" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="EditionSwitcher-9000154101-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">Academic Edition</span><span class="c-button-dropdown__icon"></span></button>
                                    <div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="EditionSwitcher-9000154101-dropdown"><ul data-role="button-dropdown__content">
                                        <li class="selected"><a href="https://link.springer.com/siteEdition/link?previousUrl=/article/10.1007/s41060-018-0096-z&amp;id=siteedition-academic-link" id="siteedition-academic-link">Academic Edition</a></li>
                                        <li><a href="https://link.springer.com/siteEdition/rd?previousUrl=/article/10.1007/s41060-018-0096-z&amp;id=siteedition-corporate-link" id="siteedition-corporate-link" tabindex="-1">Corporate Edition</a></li>
                                    </ul></div>
                                </div>
                </div>
            </div>
        </div>
        <div class="footer__content">
            <ul class="footer__nav">
                <li>
                    <a href="https://link.springer.com/">Home</a>
                </li>
                <li>
                    <a href="https://link.springer.com/impressum">Impressum</a>
                </li>
                <li>
                    <a href="https://link.springer.com/termsandconditions">Legal information</a>
                </li>
                <li>
                    <a href="https://link.springer.com/privacystatement">Privacy statement</a>
                </li>
                <li>
                    <a href="https://link.springer.com/cookiepolicy">How we use cookies</a>
                </li>
                <li>
                    <a href="https://link.springer.com/accessibility" class="gtm-footer-accessibility">Accessibility</a>
                </li>
                <li>
                    <a id="contactus-footer-link" href="https://link.springer.com/contactus">Contact us</a>
                </li>
            </ul>
            <a class="parent-logo" target="_blank" rel="noopener" href="https://www.springernature.com/" title="Go to Springer Nature">
                <span class="u-screenreader-only">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" src="/springerlink-static/439917616/images/png/springernature.png" xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/439917616/images/svg/springernature.svg">
                    </image>
                </svg>
            </a>

            <p class="footer__copyright">© 2017 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="https://www.springernature.com/">Springer Nature</a>.</p>
                <p class="footer__user-access-info">
                    <span>Not logged in</span>
                    <span>CAPES MEC (3000197460) - Universidade Tecnologica Federal do Parana (3000201946)</span>
                    <span>200.17.97.45</span>
                </p>
        </div>
    </footer>

        </div>
          <script type="text/javascript">
    (function() {
        document.addEventListener('readystatechange', function () {
            if (document.readyState === 'complete') {
                var linkEl = document.querySelector('.js-ctm');
                if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
                    var scriptMathJax = document.createElement('script');
                    scriptMathJax.async = true;
                    scriptMathJax.src = '/springerlink-static/439917616/js/mathJax.js';
                    var s0 = document.getElementsByTagName('script')[0];
                    s0.parentNode.insertBefore(scriptMathJax, s0);
                }
            }
        });
    })();
</script>

<script type="text/javascript">

    (function() {
        var linkEl = document.querySelector('.js-ctm');
        var scriptsList = [];
        var polyfillFeatures = '';

        window.SpringerLink = window.SpringerLink || {};
        window.SpringerLink.staticLocation = '/springerlink-static/439917616';

        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
            (function(h){h.className = h.className.replace('no-js', 'js')})(document.documentElement);
            
            polyfillFeatures = 'default,fetch,Promise,Object.setPrototypeOf,Object.entries,Number.isInteger,MutationObserver,startsWith,Array.prototype.includes,Array.from,IntersectionObserver';
            
            scriptsList = [
                'https://cdn.polyfill.io/v2/polyfill.js?features=' + polyfillFeatures,
                window.SpringerLink.staticLocation + '/js/main.js'
            ];

            scriptsList.forEach(function(script) {
                var tag = document.createElement('script');
                
                tag.async = false;
                tag.src = script;

                document.body.appendChild(tag);
            });
        }
    })();
</script><script src="polyfill.js"></script><script src="main.js"></script>

<script type="text/javascript" class="optanon-category-2">

   function viewport() {
        if (document.documentElement.clientWidth < 620) {
            size = 'small';
        }
        else if(document.documentElement.clientWidth < 1075 ) {
            size = 'medium';
        }
        else {
            size = 'wide';
        }
        return size;
    };

    function reportForMouseEvents(linkCssSelectors, nolardUrl, experiment, abgroup) {
        var counter = 0;
        linkCssSelectors.forEach(function(cssSelector) {
            $('body').delegate(cssSelector, 'click', function() {
                if(counter == 0) {
                    reportConversion(nolardUrl, experiment, abgroup);
                    counter++;
                }
            });
        });
    };

    function reportConversion(nolardUrl, experiment, abgroup) {
        $.ajax({ url: nolardUrl + '/convert/' + experiment + '/' + abgroup });
    };

    function reportForMouseEvent(linkCssSelector, nolardUrl, experiment, abgroup) {
        var counter = 0;
        var elem = document.querySelector(linkCssSelector)

        if (elem.addEventListener) {
            elem.addEventListener("click", function(e) {
                if(counter == 0) {
                    reportConversion(nolardUrl, experiment, abgroup);
                    counter++;
                }
            });
        } else  {
            elem.attachEvent("click", function(e) {
                if(counter == 0) {
                    reportConversion(nolardUrl, experiment, abgroup);
                    counter++;
                }
            });
        }
    };

    function reportParticipation(nolardUrl, experiment, abgroup, participations) {
        if (participations)
            participations.push(experiment + '/' + abgroup)

        var xhr = new XMLHttpRequest()
        xhr.open('GET', nolardUrl + '/participate/' + experiment + '/' + abgroup);
        xhr.send();
    };

</script>
    <script type="text/javascript" id="googletag-push">
        
            var adSlot = '270604982/springerlink/41060/article';
        

        var definedSlots = [
                {slot: [728, 90], containerName: 'doubleclick-leaderboard-ad'},
                {slot: [160, 600], containerName: 'doubleclick-ad'},
            {slot: [2, 2], containerName: 'doubleclick-native-ad'}
        ];
    </script>


        
        <span id="chat-widget" class="u-hide"></span>
                    <noscript>
                <img aria-hidden="true" role="presentation" src="https://ssl-springer.met.vgwort.de/na/pw-vgzm.415900-10.1007-s41060-018-0096-z" width='1' height='1' alt='' />
            </noscript>

    

<div style="display: none; visibility: hidden;"><script id="gpt-control-script" src="gpt.js"></script>

<script id="gpt-control-setup">var googletag=googletag||{};googletag.cmd=googletag.cmd||[];</script></div><script type="text/javascript" id="gtm-in-page-section-view">(function(d,z){function n(){for(var a in dataLayer)if(dataLayer.hasOwnProperty(a)&&dataLayer[a]["Event Category"])return dataLayer[a]["Event Category"];return"warning: no event category"}function v(a,b,c,h){"undefined"!==typeof dataLayer?dataLayer.push({event:"Scroll To Section",eventCategory:n(),eventAction:a,eventLabel:b,eventValue:1,eventNonInteraction:h}):("undefined"!==typeof ga&&ga("send","event",n(),a,b,1,{nonInteraction:1}),"undefined"!==typeof _gaq&&_gaq.push(["_trackEvent",n(),a,b,1,!0]))}
function k(b,g,c,h){if(-1===a[c].cache.indexOf(c+"-"+h)&&document.querySelectorAll(b).length){var f="viewed"===h?document.querySelectorAll(b)[0].getBoundingClientRect().height:0,x=document.querySelectorAll(b)[0].getBoundingClientRect().top+d.pageYOffset;g>=x+f&&(v(p(c)+" "+p(h),b,c,!1),a[c].cache.push(c+"-"+h),q++)}}function r(a){a=document.querySelectorAll(a);return a.length?a[0].offsetHeight||0:0}function m(b,g,c){var f=d.pageYOffset+d.innerHeight;if(q>=w)"handleClick"===g&&d.removeEventListener(b,
t),"throttle"===g&&d.removeEventListener(b,u);else if(c)setTimeout(function(){0<r(a[c].content)&&(a[c].reached&&k(a[c].content,f,c,"reached"),a[c].viewed&&k(a[c].content,f,c,"viewed"))},10);else for(var e in a)a.hasOwnProperty(e)&&0<r(a[e].content)&&(a[e].reached&&k(a[e].content,f,e,"reached"),a[e].viewed&&k(a[e].content,f,e,"viewed"))}function y(b){b=document.querySelectorAll(a[b].content).length;return 0<b?!0:!1}function p(a){return a.charAt(0).toUpperCase()+a.slice(1)}function u(a,b){var c,f,e,
g=null,d=0,k=function(){d=new Date;g=null;e=a.apply(c,f)};return function(){var h=new Date;d||(d=h);var l=b-(h-d);c=this;f=arguments;0>=l?(clearTimeout(g),g=null,d=h,e=a.apply(c,f)):g||(g=setTimeout(k,l));return e}}function t(a,b){return function(c){a(c,b)}}var w=0,q=0,a={recommendations:{content:".gtm-recommendations iframe",clickable:".gtm-recommendations .gtm-recommendations__title",exists:!1,reached:!1,viewed:!0,size:0,cache:[]},"abstract":{content:"Section.Abstract",clickable:null,exists:!0,
reached:!1,viewed:!0,size:0,cache:[]},references:{content:".Bibliography \x3e .content, [id^\x3dBib1] \x3e .content",clickable:".Bibliography \x3e .Heading, [id^\x3dBib1] \x3e .Heading",exists:!0,reached:!0,viewed:!0,size:0,cache:[]},about:{content:"#AboutThisContent",clickable:"#AboutThisContent \x3e #aboutcontent",exists:!1,reached:!1,viewed:!0,size:0,cache:[]}};d.addEventListener("scroll",u(function(){m("scroll","throttle")},500));d.addEventListener("orientationchange",u(function(){m("orientationchange",
"throttle")},500));for(var b in a)if(a.hasOwnProperty(b)&&(a[b].exists&&a[b].size++,a[b].reached&&a[b].size++,a[b].viewed&&a[b].size++,w+=a[b].size,a[b].exists&&y(b)||!a[b].exists)){a[b].exists&&-1===a[b].cache.indexOf(b+"-exists")&&(v(p(b)+" Exists",a[b].content,b,!0),a[b].cache.push(b+"-exists"),q++);if(0<r(a[b].content)){var l=d.pageYOffset+d.innerHeight;a[b].reached&&k(a[b].content,l,b,"reached");a[b].viewed&&k(a[b].content,l,b,"viewed")}a[b].clickable&&(l=document.querySelectorAll(a[b].clickable)[0])&&
(l.addEventListener("click",t(function(a,b){m("click","handleClick",b)},b)),l.addEventListener("click",t(function(a,b){13==a.keyCode&&m("click","handleClick",b)},b)))}})(window);</script><script type="text/javascript" id="gtm-recommendations-script" src="entry-point"></script><script type="text/javascript" id="gtm-polar" src="polar.js"></script><script type="text/javascript" id="gtm-krux-control">window.Krux||((Krux=function(){Krux.q.push(arguments)}).q=[]);(function(){var a=document.createElement("script");a.type="text/javascript";a.async=!0;a.src=("https:"===location.protocol?"https:":"http:")+"//cdn.krxd.net/controltag/KDqyaFZ_.js";var b=document.getElementsByTagName("script")[0];b.parentNode.insertBefore(a,b)})();</script><script type="text/javascript" id="">window.Krux||((Krux=function(){Krux.q.push(arguments)}).q=[]);(function(){function c(b){b="kxmacmillan_"+b;try{var a=window.localStorage}catch(d){a=null}return a?a[b]||"":navigator.cookieEnabled?(a=document.cookie.match(b+"\x3d([^;]*)"))&&unescape(a[1])||"":""}Krux.user=c("user");Krux.segments=c("segs")?c("segs").split(","):[]})();</script><script type="text/javascript" id="gtm-krux-consent">var allowed=google_tag_manager["GTM-WCF9Z9"].macro(29);allowed=!0===allowed?1:0;Krux("consent:set",{dc:allowed,al:allowed,tg:allowed,cd:!1,sh:!1,re:!1},function(a,b){a?console.error(a):console.log("consent flags set ",b)});</script><script type="text/javascript" id="gtm-gpt-setup">window.Krux||((Krux=function(){Krux.q.push(arguments)}).q=[]);
googletag.cmd.push(function(){googletag.pubads().setTargeting("doi",google_tag_manager["GTM-WCF9Z9"].macro(30));googletag.pubads().setTargeting("kwrd",google_tag_manager["GTM-WCF9Z9"].macro(31));googletag.pubads().setTargeting("pmc",google_tag_manager["GTM-WCF9Z9"].macro(32));googletag.pubads().setTargeting("BPID",google_tag_manager["GTM-WCF9Z9"].macro(33));googletag.pubads().setTargeting("edition",google_tag_manager["GTM-WCF9Z9"].macro(34));googletag.pubads().setTargeting("sucode",google_tag_manager["GTM-WCF9Z9"].macro(35));googletag.pubads().setTargeting("eissn",google_tag_manager["GTM-WCF9Z9"].macro(36));googletag.pubads().setTargeting("pissn",
google_tag_manager["GTM-WCF9Z9"].macro(37));googletag.pubads().setTargeting("eisbn",google_tag_manager["GTM-WCF9Z9"].macro(38));googletag.pubads().setTargeting("pisbn",google_tag_manager["GTM-WCF9Z9"].macro(39));googletag.pubads().setTargeting("logged",google_tag_manager["GTM-WCF9Z9"].macro(40));googletag.pubads().setTargeting("EventCategory",google_tag_manager["GTM-WCF9Z9"].macro(41));googletag.pubads().setTargeting("ksg",Krux.segments);googletag.pubads().setTargeting("kuid",Krux.uid);googletag.pubads().setRequestNonPersonalizedAds(google_tag_manager["GTM-WCF9Z9"].macro(45)?0:1);googletag.pubads().disableInitialLoad();
googletag.enableServices()});</script><div id="optanon" class="modern"><div id="optanon-popup-bg"></div><div id="optanon-popup-wrapper" role="dialog" aria-modal="true" tabindex="-1" lang="en-GB"><div id="optanon-popup-top"><a href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Close Button');" class="optanon-close-link optanon-close optanon-close-ui" title="Close Preference Centre"><div id="optanon-close" style="background: url(https://optanon.blob.core.windows.net/skins/default_flat_bottom_two_button_white/v2/images/optanon-pop-up-close.png);width:34px;height:34px;"></div></a></div><div id="optanon-popup-body"><div id="optanon-popup-body-left"><div id="optanon-popup-body-left-shading"></div><div id="optanon-branding-top-logo" style="background-image: url(https://optanon.blob.core.windows.net/logos/5138/5138:link.springer.com/springer.png) !important;"></div><ul id="optanon-menu"><li class="menu-item-on menu-item-about" title="Your Privacy"><p><a href="#">Your Privacy</a></p></li><li class="menu-item-necessary menu-item-on" title="Strictly Necessary Cookies"><p><a href="#">Strictly Necessary Cookies</a></p></li><li class="menu-item-on menu-item-performance" title="Performance Cookies"><p><a href="#">Performance Cookies</a></p></li><li class="menu-item-on menu-item-functional" title="Functional Cookies"><p><a href="#">Functional Cookies</a></p></li><li class="menu-item-on menu-item-advertising" title="Targeting Cookies"><p><a href="#">Targeting Cookies</a></p></li><li class="menu-item-moreinfo menu-item-off" title="More Information"><p><a target="_blank" href="https://link.springer.com/cookiepolicy" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Cookie Policy');">More Information</a></p></li></ul></div><div id="optanon-popup-body-right"><h2 aria-label="true">Privacy Preference Centre</h2><h3></h3><div id="optanon-popup-more-info-bar"><div class="optanon-status"><div class="optanon-status-editable"><form><fieldset><p><input value="check" id="chkMain" checked="checked" class="optanon-status-checkbox" type="checkbox"><label for="chkMain">Active</label></p></fieldset></form></div><div class="optanon-status-always-active optanon-status-on"><p>Always Active</p></div></div></div><div id="optanon-main-info-text"></div></div><div class="optanon-bottom-spacer"></div></div><div id="optanon-popup-bottom"> <a href="https://onetrust.com/poweredbyonetrust" target="_blank"><div id="optanon-popup-bottom-logo" style="background: url(https://optanon.blob.core.windows.net/skins/default_flat_bottom_two_button_white/v2/images/cookie-collective-top-bottom.png);width:155px;height:35px;" title="powered by OneTrust"></div></a><div class="optanon-button-wrapper optanon-save-settings-button optanon-close optanon-close-consent"><div class="optanon-white-button-left"></div><div class="optanon-white-button-middle"><a href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Save Settings');">Save Settings</a></div><div class="optanon-white-button-right"></div></div><div class="optanon-button-wrapper optanon-allow-all-button optanon-allow-all" style="display: none;"><div class="optanon-white-button-left"></div><div class="optanon-white-button-middle"><a href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Allow All');">Allow All</a></div><div class="optanon-white-button-right"></div></div></div></div></div><div class="optanon-alert-box-wrapper  " style="bottom: 0px;"><div class="optanon-alert-box-bottom-top"><div class="optanon-alert-box-corner-close"><a class="optanon-alert-box-close" href="#" title="Close Banner" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Banner Close Button');"></a></div></div><div class="optanon-alert-box-bg"><div class="optanon-alert-box-logo"> </div><div class="optanon-alert-box-body"><p>We
 use cookies to personalise content and ads, to provide social media 
features and to analyse our traffic. We also share information about 
your use of our site with our social media, advertising and analytics 
partners in accordance with our <a href="https://link.springer.com/privacystatement">Privacy Statement</a>. You can manage your preferences in Manage Cookies.</p></div><div class="optanon-clearfix"></div><div class="optanon-alert-box-button-container"><div class="optanon-alert-box-button optanon-button-close"><div class="optanon-alert-box-button-middle"><a class="optanon-alert-box-close" href="#">Close</a></div></div><div class="optanon-alert-box-button optanon-button-allow"><div class="optanon-alert-box-button-middle"><a class="optanon-allow-all" href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Banner Accept Cookies');">OK</a></div></div><div class="optanon-alert-box-button optanon-button-more"><div class="optanon-alert-box-button-middle"><a class="optanon-toggle-display" href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Banner Open Preferences');">Manage Cookies</a></div></div></div><div class="optanon-clearfix optanon-alert-box-bottom-padding"></div></div></div><div class="kxhead" data-id="KDqyaFZ_" style="display:none !important;"><span class="kxtag kxinvisible" data-id="28134"><script>
(function() {

    // cient only wants to collect first two paths
    Krux('scrape', {
        'page_attr_Springer_Link_url_path_1': {
            'url_path': '1'
        }
    });
    Krux('scrape', {
        'page_attr_Springer_Link_url_path_2': {
            'url_path': '2'
        }
    });
    // Krux('scrape',{'page_attr_url_path_3':{'url_path':'3'}});
    // Krux('scrape',{'page_attr_meta_keywords':{meta_name:'keywords'}});

    // Krux('scrape',{'page_attr_domain':{url_domain: '2'}});

})();
</script></span><span class="kxtag kxinvisible" data-id="20651"><script type="text/javascript">Krux('social.init');</script></span><span class="kxtag kxinvisible" data-id="24671"><script>
(function() {

    Krux('scrape', {
        'page_attr_Citation_Title_Springer': {
            'meta_name': 'citation_title'
        },
        'page_attr_Citation_DOI_Springer': {
            'meta_name': 'citation_doi'
        },
        'page_attr_Product_Name_Springer': {
            'meta_name': 'citation_journal_title'
        },
        'page_attr_Article_Type_Springer': {
            'meta_name': 'citation_article_type'
        },
        'page_attr_Citation_Author_Springer': {
            'dom_multi': 'meta[name="citation_author"]:@content'
        }
    });

    if (typeof dataLayer !== 'undefined' && dataLayer[0]) {
        Krux('set', 'page_attr_Article_Keywords_Springer', dataLayer[0].Keywords);
        Krux('set', 'page_attr_Business_Partner_ID_Springer', dataLayer[0].Bpids);
        Krux('set', 'page_attr_Business_Partner_Names_Springer', dataLayer[0].Bpnames);
        Krux('set', 'page_attr__Subject_Codes_Srpinger', dataLayer[0].SubjectCodes);
    }

})();
</script></span></div></body><iframe id="kx-proxy-KDqyaFZ_" src="https://cdn.krxd.net/partnerjs/xdi/proxy.3d2100fd7107262ecb55ce6847f01fa5.html#%21kxcid=KDqyaFZ_&amp;kxt=https%3A%2F%2Flink.springer.com&amp;kxcl=cdn&amp;kxp=" style="display: none; visibility: hidden; height: 0; width: 0;"></iframe></html>