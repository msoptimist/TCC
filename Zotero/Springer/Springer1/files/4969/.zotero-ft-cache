
close
close
close
Skip to main content Skip to sections

This service is more advanced with JavaScript available, learn more at http://activatejavascript.org

Advertisement
Hide
SpringerLink
Search

    Home
    Contact us
    Log in

Menu

    Home
    Contact us
    Log in

Social Network Analysis and Mining
Download PDF

Social Network Analysis and Mining

December 2014 , 4:237 | Cite as
Clustering memes in social media streams

    Authors
    Authors and affiliations

    Mohsen JafariAsbagh
    Emilio Ferrara Email author
    Onur Varol
    Filippo Menczer
    Alessandro Flammini

    Mohsen JafariAsbagh
        1
    Emilio Ferrara
        1
    Email author
    Onur Varol
        1
    Filippo Menczer
        1
    Alessandro Flammini
        1

    1. School of Informatics and Computing Indiana University Bloomington USA

Original Article
First Online: 18 November 2014
Received: 03 June 2014
Revised: 22 September 2014
Accepted: 01 November 2014

    62 Shares
    752 Downloads
    11 Citations

Abstract

The problem of clustering content in social media has pervasive applications, including the identification of discussion topics, event detection, and content recommendation. Here, we describe a streaming framework for online detection and clustering of memes in social media, specifically Twitter. A pre-clustering procedure, namely protomeme detection, first isolates atomic tokens of information carried by the tweets. Protomemes are thereafter aggregated, based on multiple similarity measures, to obtain memes as cohesive groups of tweets reflecting actual concepts or topics of discussion. The clustering algorithm takes into account various dimensions of the data and metadata, including natural language, the social network, and the patterns of information diffusion. As a result, our system can build clusters of semantically, structurally, and topically related tweets. The clustering process is based on a variant of Online K -means that incorporates a memory mechanism, used to “forget” old memes and replace them over time with the new ones. The evaluation of our framework is carried out using a dataset of Twitter trending topics. Over a 1-week period, we systematically determined whether our algorithm was able to recover the trending hashtags. We show that the proposed method outperforms baseline algorithms that only use content features, as well as a state-of-the-art event detection method that assumes full knowledge of the underlying follower network. We finally show that our online learning framework is flexible, due to its independence of the adopted clustering algorithm, and best suited to work in a streaming scenario.
Keywords
Cluster Algorithm  Ground Truth  Cosine Similarity  Twitter User  Stream Cluster 
These keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.
Cite article

    How to cite?
    .RIS Papers Reference Manager RefWorks Zotero
    .ENW EndNote
    .BIB BibTeX JabRef Mendeley

1 Introduction

Social media have become one of the main platforms for communication and information sharing. Popularity, high message exchange rate, social network structure, and accessibility across different devices make Twitter, in particular, ideal for spreading news (Bakshy et al. 2011 ; Kwak et al. 2010 ), discussing politics and social issues (Conover et al. 2013a , b ; Varol et al. 2014 ; Morales et al. 2012 ; Skoric et al. 2011 ), and reaching out to groups or individuals with similar interests (Wu et al. 2011 ). On the other hand, social media are also used to disseminate misleading information such as rumors and spam (Chew and Eysenbach 2010 ; Metaxas and Mustafaraj 2010 ; Ferrara et al. 2014 ). The ability to automatically detect, in real time, patterns of information diffusion or topics of conversation is of great interest. This task cannot be accomplished by classifying each single piece of content observed in real time on the platform; the classes cannot be predetermined because new memes constantly appear in the social stream, and labeling tweets for training is not feasible due to the large volume of content produced.

The alternative proposal pursued in this article is to design an unsupervised framework to cluster tweets based on similarity measures that account for content as well as other metadata features. A single tweet may not contain sufficient information to identify a topic of conversation, due to its brevity. Topic modeling techniques have proved ineffective in this task due to the sparsity of textual content (Hong and Davison 2010 ). Metadata may help overcome this problem, as shown in other contexts (Mei et al. 2008 ). For example, in an attempt to mitigate the 140-character limitation, users may include URLs to provide external resources. Yet, most tweets don’t contain URLs, and URLs may be abused to promote irrelevant content. Another form of metadata is the mention , a mechanism to include a specific user in a conversation. A mention can be either a direct reply to a user or a way of drawing her/his attention to the contents of the tweet. Mentions start with the @ character, followed by the user screen name. They can be exploited by spammers to grab someone’s attention. Users also enrich tweets with hashtags to identify topics of conversation. Hashtags are user-defined terms starting with the # character, and have been used as proxies for topics on Twitter (Tsur and Rappoport 2012 ; Yang et al. 2012 ). Relying on hashtags alone as indicators of a topic has some limitations as well (Ferrara et al. 2013 ). For instance, they can be used to refer to a broad subject (e.g., #tcot captures many conservative discussions on Twitter); or, two or more different hashtags can be used to refer to the same topic (e.g., #AffordableCareAct and #ObamaCare both talk about the Patient Protection and Affordable Care Act of 2010). Furthermore, users can adopt an organic hashtag to inject content into an ongoing conversation (Conover et al. 2011 ). 1

In our approach, we combine content and different sources of metadata to infer semantic similarity between groups of tweets. We adopt the term meme to denote sets of topically coherent tweets. A meme represents an idea or a concept that can spread from person to person in the social network. The goal of our unsupervised learning framework is to meaningfully cluster tweets from a social stream into potentially overlapping sets, each of which corresponds to a meme.

We leverage the various forms of metadata entities present in each tweet along with its content to bootstrap the clustering process. Specifically, we pre-aggregate tweets into initial sets based on shared metadata entities (URLs, mentions, and hashtags) and phrases—sequences of word in the tweet text, excluding metadata entities. In the remainder of the paper, we refer to these initial sets as protomemes .

Our approach is based on the assumption that a protomeme represents a suitable atomic unit for the clustering algorithm, namely a semantically homogeneous set of tweets. On the other hand, there is a many-to-many relationship between tweets and protomemes: each tweet can contain more than one entity. As a result, protomemes do not commit the algorithm to assigning a tweet to a single cluster. From a practical point of view, a protomeme allows to build a textual representation that is less sparse than that of a single tweet. Protomemes yield higher accuracy in reconstructing political rumors in a static clustering scenario (Ferrara et al. 2013 ).

Although protomemes consist of a group of related tweets, they are an oversimplified representation of a meme, and therefore, they cannot often capture all nuances of a topic. Protomemes can be too specific and only capture a particular aspect of a conversation, whereas a meme can have a more complex structure and may aggregate multiple perspectives into a single concept. Therefore, we assume that putting together protomemes in a meaningful way may yield sets of tweets which represent sophisticated memes better than any individual protomeme. In other words, our proposed approach benefits from protomemes as a pre-aggregation step and then it clusters them to identify memes.

Traditional clustering algorithms have been devised to perform in an offline scenario or stationary/static data. In such a case, the algorithm assumes unlimited access to all data points as well as boundless memory and processing resources. This scenario is far from reality: in the case of social media data, for example, posts arrive at varying rates and in a streaming fashion. In this situation, there is only a limited amount of time and resources available to process newly arrived data before they swamp the whole system. To operate in such an environment, it is essential to bear in mind that we can only afford one pass over the data or a few passes over a subset of the data. Problems of this sort have been studied in the area of data stream mining (Babcock et al. 2002 ; Gaber et al. 2005 ), and they fall in the broader field of online learning (Albers and Leonardi 1999 ; Blum 1998 ; Cesa-Bianchi 2006 ; Fiat and Woeginger 1998 ). Data stream clustering algorithms process a sequence of data points arriving over time. Various such algorithms have been proposed in the literature (Gama and Gaber 2007 ; Gama et al. 2010 ; Sayed-Mouchaweh and Lughofer 2012 ; Shalev-Shwartz 2011 ). Online K -means (Banerjee and Ghosh 2004 ; Zhong 2005 ) is one well-known algorithm suitable for this purpose. While running, the algorithm maintains K clusters and it assigns each incoming data point to the closest cluster based on the distance between the new point and the centroid of the cluster. Here, we tailor this algorithm to take into account the notion of protomemes and our proposed similarity measures. This will allow us to design a system for clustering a social stream of content into memes.
1.1 Contributions and outline
In this paper, we propose a framework to extract content- and network-based features from Twitter data and use them to cluster the stream of tweets. A summary of the present contributions follows:

    We use the notion of protomemes (Ferrara et al. 2013 ) as the result of our pre-aggregation step to group together tweets sharing some common information token. We test the hypothesis that protomemes provide the clustering algorithm with useful atomic units.

    We define various similarity measures between protomemes, based on content, metadata, and network features of Twitter data. We also introduce different ways to combine these similarity measures.

    We design a stream clustering framework able to group protomemes together in topically cohesive clusters. Our method requires only one pass on the data, therefore, is suitable to work with different online learning algorithms. We implement it using a variant of Online K -means that works with protomemes and incorporates a sliding window mechanism.

    We evaluate the performance of the proposed system on a stream of tweets. We show that our method outperforms two baseline algorithms, one solely based on tweet content and one based on tweet content plus the underlying social network structure. Our results demonstrate the advantage of adopting protomemes and various metadata features for meme clustering in social stream.

2 Online clustering framework

In the following, we propose a general framework for clustering memes in social media data streams. Our system can be applied to any social media system that supports directed relationships among users, and that generates a stream of messages produced by them. Twitter, Google Plus, and Tumblr are examples of such platforms. Hence, we will take the former as use case and we will adopt Twitter terminology to describe our platform. Twitter users can engage in directed social relationships. One user can follow others ( followees ), and, in turn, be followed by her/his own followers . Following is commonly used to receive other users’ posts ( tweets ) in one’s news feed. Each user can also address others directly, by mentioning their screen names in her/his tweets. Finally, users can re-broadcast ( retweet ) messages from other users to make them visible by their followers.

Next, let us first define the notion of protomeme as the basic building block of our clustering framework. We then introduce various similarity measures between protomemes, and explain the data model that incorporates protomemes and allows us to design our meme stream clustering framework.
2.1 Protomemes
We recently proposed the notion of protomemes as a simple way of grouping single messages into bigger blocks (Ratkiewicz et al. 2011 ; Ferrara et al. 2013 ). Our assumption is that these blocks yield topically cohesive groups and therefore represent natural units that can be aggregated into broader memes. To identify protomemes we simply group together tweets that share one instance of entities from the following types:

    Hashtags Twitter users can incorporate in the text of their tweets one or more hashtags , textual tokens prefixed by hash marks (#), which identify the topic of the message. In a sense, hashtags leverage the wisdom of the crowd (Golder and Huberman 2006 ; Mika 2007 ): broad topics of interest emerge from the tagging activity of many users.

    Mentions we say that a tweet mentions a user when it includes the target user’s screen name preceded by the ‘@’ symbol, thus addressing that specific user.

    URLs tweets may include links to external sources of information. A URL is the Web address identifying a linked resource.

    Phrases we define the textual content of a tweet that remains after removing hashtags, mentions, URLs, stop words, and punctuation, and after stemming words (Porter 1980 ) as a phrase . Phrases may help capture semantically equivalent variations of textual messages.

To demonstrate these different protomeme types, consider the following example: “Tell your friends: #Obamacare is helping young people afford health insurance. (via @OFATruthTeam) pic.twitter.com/s9QHilsSjO.”

This tweet contains the hashtag #Obamacare , the mention @OFATruthTeam , the URL pic.twitter.com/s9QHilsSjO , and the phrase Tell friends help young people afford health insurance . Each of these elements represents a different protomeme entity. All tweets containing the same entity will be grouped together. This way of defining protomemes also allows a single tweet to belong to multiple protomemes; the example above belongs to four protomemes. In the remainder of the paper we will interchangeably use the term protomeme to refer to a set of tweets sharing the same entity, or to the entity itself.

In practice, the pre-aggregation step to extract protomemes requires only the application of a regular expression to the tweets in the data stream, which can be accomplished in real time (Ratkiewicz et al. 2011 ). Therefore, protomeme extraction can be achieved efficiently in a streaming scenario while requiring only a single pass on the data.

Next, we define various similarity measures between protomemes to further aggregate tweets and identify broader memes.
2.2 Metadata and similarity measures
Figure  1 illustrates the mutual relations between protomemes, the tweets they contain, their content, the users who post them, and the underlying follower network. We can define similarity measures between protomemes (or any sets of tweets) by considering the projections of the protomemes onto spaces induced by these features.
Open image in new window
Fig. 1

Relations among protomemes, tweets, users, and tweet content. There is a many-to-many relationship between memes and tweets. A user may be connected to a tweet as its author, by being mentioned in the tweet, or from retweeting the message

Let us provide a few preliminary definitions. Let p be a protomeme, and \(\mathbf {p}^{f}\) a vector representation of p according to feature f . We can now define a set of similarity measures based on content and metadata.
Common user similarity \(S^{u}\) between protomemes p and q is the cosine similarity
$$\begin{aligned} S^{u}(p,\,q)=\frac{{\mathbf {p}}^{u} \cdot {\mathbf {q}}^{u} }{||{\mathbf {p}}^{u}|| ||{\mathbf {q}}^{u}||}, \end{aligned}$$
(1)
where \({\mathbf {p}}^{u}\) and \({\mathbf {q}}^{u}\) are the vectors representing the number of tweets in p and q , respectively, produced by each user.
Content similarity \(S^{c}\) between p and q is the cosine similarity
$$\begin{aligned} S^{c}(p,\,q) = \frac{{\mathbf {p}}^{c} \cdot {\mathbf {q}}^{c} }{||{\mathbf {q}}^{c}|| ||{\mathbf {q}}^{c}||}, \end{aligned}$$
(2)
where \({\mathbf {p}}^{c}\) and \({\mathbf {q}}^{c}\) are the vectors representing the term frequency (TF) weights assigned to each word of the two documents obtained by concatenating all the tweets in p and q , respectively. 2
Common tweet similarity \(S^{t}\) between p and q is the cosine similarity
$$\begin{aligned} S^{t}(p,\,q) = \frac{|p \cap q|}{\sqrt{|p||q|}}. \end{aligned}$$
(3)
We wish to introduce a fourth similarity measure based on the social network of users involved in a set of tweets (see illustration of the follower network in Fig.  1 ). Since we assume that information about the follower social network is not available to the clustering algorithm, let us exploit mention and retweet metadata as proxies for the underlying network and community structure whose role in information diffusion is crucial (Nematzadeh et al. 2014 ). Let \(N_{p} = U_{p} \cup M_{p} \cup R_{p}\) be the diffusion set of p , where \(U_{p}\) is the set of authors of tweets in \(p,\,M_{p}\) is the set of users mentioned in tweets in p , and \(R_{p}\) is the set of authors of tweets with retweets in p . 3 The diffusion set is a subset of the neighbors of users involved in the protomeme on the mention and retweet networks.
Network similarity \(S^{n}\) between p and q is the cosine similarity between their diffusion sets
$$\begin{aligned} S^{n}(p,\,q) = \frac{|N_{p} \cap N_{q}|}{\sqrt{|N_{p}| |N_{q}|}}. \end{aligned}$$
(4)
These four similarity measures can be combined to obtain a single similarity value between two protomemes. One common approach is to generate a linear combination of similarity measures in the form of a weighted average (Sayyadi et al. 2009 ; Yih and Qazvinian 2012 ). Formally, we have
$$\begin{aligned} S_{\mathcal {L}}(p,\,q) = \sum \limits _k \omega _{k} S^{k}(p,\,q), \end{aligned}$$
(5)
with the constraint that \(\sum \nolimits _{k} \omega _k = 1,\) allowing for a normalized combination such that \(S_{\mathcal {L}}(p,\,q) \in [0,\,1]\) (given that \(\forall k \; S^{k} \in [0,\,1]\) ). The set of parameters \(\omega _{1}, \ldots , \omega _{n}\) yields an n -dimensional parameter space. Searching this space is necessary to identify the combination(s) of similarity measures that provide the optimal clustering performance. This is not a trivial task.
A second approach is to choose the highest value among all similarity measures when computing the pairwise similarity between two protomemes. The rationale is that the relatedness of two protomemes may be best captured by different dimensions on a per case base: for example, the similarity of a pair of protomemes might be best described by their content, while that of two other protomemes may be better reflected, for instance, by the social network dimension. Taking the maximum value of similarity among the four dimensions would account for such heterogeneity. Given a set of similarity measures \(S^{1}, \ldots , S^{n},\) the maximum pairwise similarity is formally defined as
$$\begin{aligned} S_{\max }(p,\,q) = \max _{k} \left\{ S^{k}(p,\,q)\right\} . \end{aligned}$$
(6)
The maximum pairwise similarity has an advantage over the linear combination, namely is that it does not need any parameter space exploration. More importantly, we found in previous work (Ferrara et al. 2013 ) that the maximum pairwise similarity provides performance as good as the best linear combination in meme clustering. Hence, our next experiments will be based on maximum pairwise similarity.
2.3 Data processing model

The model assumption in data stream clustering is that, due to the large amount of incoming data, the system cannot store all of it in memory (Babcock et al. 2002 ; Gaber et al. 2005 ). In addition, a data stream evolves with time and patterns in recent data are more relevant for the clustering algorithm than those in older data. An established way to de-emphasize older data is to represent the stream through a window-based model. There are three well-known window models in the literature: landmark window, damped window, and sliding window (Pramod and Vyas 2012 ). In all cases, without loss of generality, we assume the stream to start at time \(t=0\) and discretize time into steps of fixed duration \(\Delta t.\)

A landmark window contains all data points from \(t=0\) until the present time \(t=T.\) This model is not feasible for fast-growing data streams.

A damped window model assigns a weight to each data point in the data stream. It uses a decay function based on time, which gives more weight to recent data points. The most commonly used function attributes to an event occurring at time t an exponentially decreasing weight \(w(t)=2^{-\lambda (T-t)},\) where \(\lambda >0.\) The higher the value of \(\lambda ,\) the higher the importance of more recent data.

A sliding window has a fixed length of \(\ell \) steps and at each moment T it contains only the data points received during last \(\ell \) steps, giving them equal importance. The window interval is \(W =(T-\ell \Delta t,\,T].\) Algorithms that adopt this model either ignore data points older than \(T - \ell \Delta t,\) or consider a summary of them. The sliding window is a simple yet effective model in data stream processing. Due to its simplicity and generality, we choose this data processing model in our clustering algorithm.
2.4 Protomeme stream clustering

Online K -means (Banerjee and Ghosh 2004 ; Zhong 2005 ) is a simple data stream clustering algorithm based on iterative K -means for stationary data. In general, Online K -means starts with K randomly chosen initial cluster seeds and every new point arriving in the stream is assigned to the closest existing cluster. The closest cluster is chosen based on the distance between the arriving point and the centroid of the cluster. A cluster centroid has the same features as the data points and the value of each feature is averaged across the data points that are members of the cluster.

This general algorithm does not take into account the fact that new concepts might appear in the stream, which are different from what has been observed before. These new concepts should represent new clusters; assigning them to the existing clusters might jeopardize the quality of clustering. To overcome this problem, one suggested approach (Aggarwal and Subbian 2012 ) is to check whether the distance from the closest cluster centroid is an outlier in comparison to the other closest distances that have been observed so far. If not, the new data point is added to the nearest cluster. Otherwise, the least recently updated cluster is replaced by a new cluster with the new point as the only member. The least recently updated cluster is the one to which no new points have been assigned for the longest time. The outlier detection function uses a history of closest distances from previously observed data points to determine whether a given distance is an outlier. Every time a data point arrives in the stream, its distance to the closest centroid is added to the list. This method assumes that the distances follow a normal distribution. If the new distance exceeds the historical average by n standard deviations or more, where n is a parameter, the new point is deemed an outlier.
The proposed clustering algorithm, that we call Protomeme stream clustering (PSC), works as follows:

    (1)

    At the beginning of each step, the sliding window is advanced by \(\Delta t\) and protomemes are extracted from arriving tweets in the stream, i.e., those in the new time step \((T-\Delta t,\,T].\) Each protomeme is treated as a data point to be clustered. Before any of these new points are assigned, all clusters are examined and data points with time stamps older than \(T - \ell \Delta t\) (i.e., those that are no longer in the sliding window) are removed. From now on, we will refer to these points as old . If a cluster consists only of old points, it becomes empty and is removed from the list of clusters.
     
    (2)

    Since we are using protomemes as a pre-aggregation step, in our algorithm we tend to assign the same protomemes to the same clusters whenever possible. If an arriving protomeme matches any of the ones present in any of the existing clusters, we assign it to that cluster and continue to the next protomeme. Otherwise, we move to the next step.
     
    (3)

    A new protomeme is assigned to the closest cluster or to a new cluster based on the outcome of the outlier test. The protomeme is assigned to a new cluster if its distance from the nearest centroid \(d > \mu + n \sigma ,\) where \(\mu \) and \(\sigma \) are the mean and standard deviation, respectively, of the values in the historical list of closest distance values. The historical distance values in the list are kept since the beginning of the clustering process.
     

All the steps of the PSC clustering algorithm are depicted in Fig.  2 .
Open image in new window
Fig. 2

PSC stream clustering algorithm. a The window is shifted, old protomemes are removed, and new protomemes are extracted. b If an incoming protomeme exists, it is assigned to the same cluster. c1 , c2 If an incoming protomeme is new, it is assigned to the closest cluster if it is not an outlier ( c1 ), otherwise it replaces the least recently updated (LRU) cluster ( c2 )
3 Evaluation

In this section, we present the experimental procedure carried out to evaluate the performance of our clustering algorithm on a real dataset. First, we describe the dataset on which we performed the experiments. Then, we introduce the metric used to assess the quality of clustering.
3.1 Ground truth dataset
For the purpose of evaluation, we use a dataset collected from Twitter, comprised of trending hashtags between 23 and 29 March 2013. The data were obtained by monitoring and recording the trends appearing on the Twitter platform at regular intervals of 10 min. A detailed analysis of geographic and temporal trend diffusion based on this data is reported in prior work (Ferrara et al. 2013 ). We extracted all tweets containing those trending hashtags from a 10 % sample of the full stream of public tweets, for a time interval of 7 days before and 3 days after the trending point. The trending hashtags represent the ground truth memes—we assume that tweets sharing a trending hashtag should be clustered together, even by an algorithm that does not have any knowledge of this cluster label. Figure  3 shows a stream graph of the volume of tweets per hour, for the 10 most popular trending hashtags in our dataset.
Open image in new window
Fig. 3

Tweet volume time series for the top 10 hashtags in the trending dataset. For each trending hashtag, we report the total number of tweets with that hashtag in our 10 % Twitter sample (in parenthesis). Each bin is 1 h
3.2 Evaluation metric
To assess the quality of algorithmic cluster assignments, we adopt a measure based on normalized mutual information , NMI (Danon et al. 2005 ). The NMI assumes the availability of a ground truth that represents the correct clusters. Let A be the correct cluster assignment, and suppose that it contains \(c_{A}\) clusters. Let B be the output of a clustering algorithm operating on the same data and producing \(c_{B}\) clusters. We can define a \(c_{A} \times c_{B}\) confusion matrix \(\mathbf {N},\) whose rows correspond to the clusters in A and whose columns represent clusters in B . Each entry \(N_{ij}\) of this confusion matrix reports the number of elements of the correct i th cluster that also happen to be present in the j th cluster found by the clustering algorithm. Formally, the NMI is defined as
$$\begin{aligned} {\mathrm{NMI}}(A,\,B) = \frac{-2 \sum \nolimits _{i = 1}^{c_{A}}\sum \nolimits _{j =1}^{c_{B}} N_{ij} \log \left( \frac{N_{ij}N}{N_{i\cdot }N_{\cdot j}}\right) }{\sum \nolimits _{i=1}^{c_{A}}N_{i \cdot } \log \left( \frac{N_{i \cdot }}{N}\right) + \sum \nolimits _{j=1}^{c_{B}}N_{\cdot j} \log \left( \frac{N_{\cdot j}}{N}\right) }, \end{aligned}$$
(7)
where \(N_{i \cdot }\) (resp., \(N_{\cdot j}\) ) is the sum of the elements in the i th row (resp., j th column) of the confusion matrix, and N is the sum of all elements of \(\mathbf {N}.\) The output of this measure is normalized between zero (when the clusters in the two solutions are totally independent), and one (when they exactly coincide). Therefore, the higher the value of NMI, the better the quality of the clusters found by the algorithm.

Measures based on mutual information have been proved to best capture different facets of a clustering process, such as how well a clustering algorithm reflects the number, size, and composition of clusters with respect to the ground truth, as opposed to traditional information retrieval and data mining measures, like accuracy or purity, which usually produce biased evaluations (Meilă 2007 ). Our investigation with accuracy, precision, recall, and \(F_{1}\) confirmed the limitations of these measures, all of which report indistinguishable results due to the dominance of true negatives. Purity, on the other hand, is by definition biased toward rewarding the presence of tiny clusters, which tend to be pure. For these reasons, NMI has been recently adopted in the evaluation of tasks such as event detection in social media (Becker et al. 2010 ).

Due to the fact that our algorithm can produce overlapping clusters of protomemes, we adopt a variant of NMI, called LFK-NMI after its authors (Lancichinetti et al. 2009 ), that is best suited to measure the quality of overlapping clusters thanks to a slightly different normalization criterion. In the remainder of the paper, we shall refer to LFK-NMI as NMI for simplicity.
4 Results

Let us now discuss the details of the PSC algorithm implementation and the values of the parameters for its configuration. We also introduce two baseline clustering algorithms against which to compare PSC.
4.1 Experiment setup
Our experiments aim at assessing whether protomemes and our metadata-driven features and similarity measures bring an observable advantage in the task of clustering memes from social streams. To this end, we compare our framework against two baseline clustering algorithms that are also based on Online K -means, but operate directly on individual tweets and with different features and similarities. The description of the two baselines follows.

    Baseline B1 this configuration is an implementation of the Online K -means clustering of simple tweets along with outlier handling as explained earlier. The only feature used in this algorithm is text content. The TF vector of each tweet is used to compute the content similarity between tweets and aggregate them.

    Baseline B2 this configuration is an implementation of the event detection system recently proposed by Aggarwal and Subbian ( 2012 ), which is a tweet clustering algorithm based on a combination of content and network features. To the best of our knowledge, this approach represents the current state of the art in streaming clustering of tweets. It relies on the full knowledge of the follower network of all users present in the dataset. Such information provides a very significant advantage, but it also creates a practical challenge in that it is very time consuming to obtain, making the algorithm infeasible in real-time, streaming scenarios. To compute tweet similarity, the original algorithm adopts TF-IDF, but we use TF in our implementation as it provides better performance on our dataset. This algorithm is also based on Online K -means and incorporates the same outlier handling procedure. To make use of this algorithm for comparison, we extracted in batch the follower network of all users present in our dataset.

As described in previous sections, all our Online K -means algorithms (PSC and baselines) have four parameters:

    K initial number of clusters,

    \(\Delta t\) time step by which the window advances,

    \(\ell \) length of sliding window, in time steps,

    n number of standard deviations from the mean to identify outliers.

For all the algorithms, we set \(\Delta t = 60\)  min, \(\ell = 6\) steps, and \(n=2.\) Therefore, a sliding window has duration \(\ell \Delta t = 360\)  min. To set K for Online K -means, we computed the average number of hashtags across all sliding windows, yielding \(K=11\) initial clusters. To evaluate the clustering solutions, we treat the trending hashtags as the actual (ground truth) cluster labels. Therefore, while extracting protomemes as data points to be clustered, we remove these trending hashtags from the set of protomemes, and from the text of the tweets as well. This prevents any bias in favor of our algorithm, and makes the clustering task very challenging. The evaluation score is computed at the end of each window, to which we will refer as evaluation period.
4.2 Performance evaluation
Figure  4 plots cumulative NMI over all the evaluation periods. Each point on the x axis represents a 6-h sliding window terminating at the indicated hour. To compute NMI correctly for each evaluation period, it is essential to have the same set of tweets in the ground truth and evaluated clusters. Therefore, we only use tweets and their labels in the ground truth for the same period of time. As explained earlier, whenever a cluster becomes empty after removing old data points, we remove it from the list of clusters. In a real-world scenario, we might decide to ignore these clusters because they have not been updated during the last \(\ell \) time steps; for evaluation purposes, we keep them in a separate list and account for them when assessing the quality in the present window, then delete them afterwards.
Open image in new window
Fig. 4

Performance of different clustering algorithms as a function of the evaluation period. For each algorithm, the NMI values at each step are averaged across five runs. These values are then accumulated over the course of the experiment. The inset plots the time-averaged NMI, with error bars corresponding to \(\pm \) 1 standard error

Our algorithm performs consistently better than the two baselines. The performance improvement is more apparent after the online clustering has been carried out for an extended time. Figure  4 shows that after about half of the running time, PSC provides a consistent improvement in cluster quality with respect to the baselines. This is due to the characteristic fast-paced churning time of the topics of discussion in social media. The inset of Fig.  4 demonstrates that the differences in NMI among PSC and the baseline algorithms are statistically significant. On average PSC outperforms B1 and B2 by 49 and 26 %, respectively.

NMI is a quantitative measure that captures the overlap between the algorithmic clusters and the classes in the ground truth. It reports a single-number summary, but it does not provide any details about the resemblance between clusters and classes in terms of their numbers and size. For instance, if there is a huge class in the ground truth along with several small ones, an algorithm can achieve high NMI by assigning all the data points to a single cluster.

To investigate the performance in greater detail, let us consider the confusion matrix containing the Jaccard coefficient between the set of tweets of every cluster in the solution and in the ground truth, respectively. Figure  5 shows the confusion matrices for the three algorithms. The rows and columns in these matrices represent the clusters in the solution and classes in the ground truth, respectively. The number next to each row (resp., column) shows the number of tweets in each cluster (resp., class). These matrices are computed at an evaluation period in which all three algorithms display local maxima in NMI. Although this period does not represent the best quality for any of the algorithms, it has the advantage that the ground truth classes are the same for all three algorithms, which is crucial for performance comparison.
A good clustering solution will have a confusion matrix with a dark colored cell (high value of Jaccard coefficient) in each row or column. The perfect clustering would show only dark cells on the diagonal of a square confusion matrix. As Fig.  5 illustrates, PSC does a good job at capturing the actual clusters in the data; we observe greater confusion in the clusters generated by the two baseline algorithms. In particular, our method is able to recover eight clusters whose overlap with the ground truth cluster is above 60 %, while both the baseline methods identify at most three clusters faithfully resembling the ground truth. Although the performance of the clustering methods fluctuates over time, PSC is able to outperform the state of the art and discover memes in a streaming scenario with reasonable accuracy. Our method also introduces great benefits in terms of computational cost: PSC processes streaming data points online, and its cost is linear in terms of the size of the input, similarly to the classic Online K -means (Gaber et al. 2005 ). Other methods require quadratic time and memory (for example hierarchical clustering Ferrara et al. 2013 ), or access and storage of external information (e.g., B2 relies on the availability of the full follower network Aggarwal and Subbian 2012 ).
Open image in new window
Fig. 5

Overlap (Jaccard coefficient) between ground truth classes and clusters detected by PSC ( left ), B2 ( middle ), and B1 ( right )
4.3 Parameter tuning

The stream clustering methods we presented here are all based on the setting of two parameters: the sliding window length \(\ell \) and the step size \(\Delta t.\) We now investigate how the choice of such parameters affects the overall clustering performance. Let us explore the parameter space defined over the two dimensions of window length and step size. Figure  6 shows three heatmaps that illustrate how the clustering quality of each algorithm, measured by NMI, is affected by varying \(\ell \) (represented on the y -axis) and \(\Delta t\) (on the x -axis). All three algorithms achieve the best performance with the shortest time window ( \(\ell = 4\,\mathrm{h}\) ) and the smallest step size ( \(\Delta t = 30\,\mathrm{min}\) ). This is somehow intuitive: the heterogeneity of data points (and, therefore, memes) collected with shorter windows is lower, and smaller steps allow to react more responsively to the fast-paced churning time of memes emerging on social platforms. With this parameter configuration, PSC outperforms both baselines, obtaining an average NMI score of 0.23, an increment of 43.75 % over B1 and 15 % over B2.
As the window length and/or step size grows, the performance of all clustering methods worsens. However, the performance deterioration of PSC is very limited if compared with B1 and (especially) B2: the difference between best and worst PSC performance is 34.78 % (from an average NMI of 0.23 down to 0.15), whereas for B1, the amounts decrease up to 43.75 % (from 0.16 down to 0.09) and for B2 is 80 % (from 0.20 down to 0.04). This analysis shows that PSC is a more robust and flexible solution for stream clustering in social media, as it depends less on the optimal tuning of window size and step. Even if the computational resources are scarce, requiring coarser granularity, PSC displays reasonable accuracy and performs better than existing state-of-the-art methods.
Open image in new window
Fig. 6

Performance (measured by NMI) for varying sliding window length \(\ell \) and step size \(\Delta t\) of PSC ( left ), B1 ( center ) and B2 ( right )
Open image in new window
Fig. 7

Clustering quality over time (measured by NMI) achieved by PSC , B1 and B2 . The gray bands in the background show the day–night cycle, with midnight in white
4.4 Success and fail scenarios

Understanding when stream clustering performs well and when it fails is a challenging task. Here we try to identify what dynamics affect the outcome of the clustering process. We first focus on the temporal dimension: previous work shows that circadian rhythms of day–night activity affect the patterns of content generation and the volume of tweets (and memes) observed in social media (Golder and Macy 2011 ). We hypothesize that different rates of content production might determine how effective the clustering is: Fig.  7 illustrates the performance of the three clustering algorithms over time. The background gray bands show the day–night cycle over a week-long period. All algorithms exhibit fluctuations in performance corresponding with the circadian clock: highs correspond to peek hours, where more content is generated and, therefore, more information is available to describe memes and their clusters; lows correspond with nightly hours, when the production of content is slowed and the clustering is based on fewer data points. PSC is consistently the best performing algorithms, as it reaches the highest peaks in clustering accuracy and the mildest dips. Over time, PSC seems to build on the accumulation of information over time to produce better results, as evident from the second part of the time series in Fig.  7 . The other methods do not exhibit any benefit as time unfolds.
Let us explore a few examples of successful and unsuccessful stream meme clustering. Our goal is to identify other dynamics that might affect the quality of the clusters at the level of the single meme. To determine the quality of clustering of a single meme over time, let us introduce a new measure, called maximum cluster ratio (MCR), defined as follows:
$$\begin{aligned} {\mathrm{MCR}}(p) = \frac{\max _{c\in C}\left( N_{c}(p)\right) }{N(p)}, \end{aligned}$$
(8)
where \(N(p)\) is the total number of tweets exhibiting trending hashtag p , and \(N_{c}(p)\) is the number of tweets with hashtag p in cluster \(c\in C.\) This measure allows us to determine how well the algorithm is capturing a target meme over time; the higher the MCR, the better.
Figure  8 shows two scenarios: on the left, we display two memes (#nyias and #rallycry) whose clustering is of consistently high quality (high MCR); on the right, two examples of less successful clustering (#blackberry10 and #thehost) exhibit lower values of MCR. From our per case analysis, a few considerations emerge: PSC performs generally better with short-lived memes (like #nyias), and with memes whose content is produced mostly during daytime hours, as opposed to memes with sustained audience (see #thehost); moreover, when content is abundant the performance is steady and the clustering of single meme is consistent and high quality (see #rallycry), while when the volume of tweets associated with memes is smaller the clustering quality can fluctuate (for example, see #blackberry10). Another interesting fact is that the algorithm performs generally better with organic and grassroots memes (like in the examples on the left) rather than with memes related to promoted content. This difference might be attributed to the crucially different characteristics that such memes exhibit in terms of content generation and diffusion (Ferrara et al. 2013 ).
Open image in new window
Fig. 8

Examples of two successful ( left ) and failed ( right ) attempts of capturing trending hashtag clusters over time with PSC. Clustering quality is measured by MCR . The size of the circles is proportional to the total number of tweets with that hashtag at a given point in time
5 Related work

Problems related to clustering in social media platforms include the identification of topics or memes (Leskovec et al. 2009 ; Xie et al. 2011 ; Simmons et al. 2011 ), and event detection in social streams (Becker et al. 2011 ; Marcus et al. 2011 ; Lehmann et al. 2012 ; Thom et al. 2012 ; Cataldi et al. 2013 ). Meme and topic identification techniques usually emphasize the terms and keywords as signatures of the content. Detection methods usually take into account temporal features and keywords occurrence to identify trending conversation, whereas to detect events happening in the physical world they mostly rely on temporal and geographical information. The present work, to the best of our knowledge, is the first to formalize the problem of clustering memes from online social media streams.

Leskovec et al. ( 2009 ) presented memetracker , a platform for tracking memes originated in online media such as mainstream news sites and weblogs. Memetracker can group together short, distinctive phrases that act as signatures of specific topics. The system can also identify small variations of them. It then creates groups of news on related topics that can be tracked over time to define patterns of diffusion in the news cycle. Memetracker assumes that the memes identified by aggregation on the basis of textual similarity are disjoint and correct: no systematic evaluation of the quality of the retrieved memes is provided. Our work instead focuses on the assessment of the quality of the meme clustering process, and allows for overlapping memes.

The problem of tracking news for meme extraction has been tackled also by Simmons et al. ( 2011 ). Based on the memetracker dataset, the authors investigated whether information evolves and mutates while being consumed by social media users. Our definition of protomemes is rooted on the findings of both Leskovec et al. ( 2009 ) and Simmons et al. ( 2011 ), expanding on the aggregation of meme variants based not only on textual similarity, but also on other network and metadata features.

Our framework shares some similarities also with another line of research on event detection systems. Aggarwal and Subbian ( 2012 ) presented a clustering algorithm that exploits both content- and network-based features to detect events in social streams. We adapted their algorithm to work in the context of meme clustering, to use it as a baseline. Unfortunately, the algorithm assumes preexisting knowledge about the follower network of Twitter users. In a streaming scenario, such information is expensive to obtain, especially when encountering popular users. In our framework, we proposed to rely on mention and retweet diffusion sets, which can be inferred in real time from the observed data. Also, our system provides better performance by pre-clustering based on protomemes and by metadata-driven measures of similarity between clusters.

Becker et al. ( 2010 ) formulated the clustering problem for event detection on social media by defining a set of features and a supervised approach to combine them. The authors defined three types of features: textual (e.g., title, description, tags), time/date, and location. They proposed an ensemble clustering approach based on labeled data to combine the similarity revealed by each group of features. However, they did not consider the social network underlying social media platforms. The same authors presented an event classification system designed for Twitter (Becker et al. 2011 ). It incorporates a clustering module that exploits temporal, social, and topical features.

Finally, Thom et al. ( 2012 ) developed a system for interactive analysis of location-based microblog messages, which can assist in the detection of real-world events in real time. This approach benefits from an online clustering algorithm based on X -means, a variation of K -means, to detect spatiotemporal dense topic clusters with a single term in common. The clustering algorithm extracts the terms from the messages and attaches a geolocation and a timestamp to each term. Then, comparison of Euclidean distance with a predefined threshold is used to assign each term to the closest cluster centroid or to a new cluster.
6 Conclusions

In this work, we proposed a framework to deal with the problem of clustering memes in social media streams, Twitter in particular. Our system is based on a pre-clustering procedure, called protomeme detection, aimed at identifying atomic tokens of information contained in each tweet. This strategy only requires text processing, therefore, is particularly efficient and well suited for a streaming scenario. Memes are thereafter obtained by aggregating protomemes on the basis of the similarity among them, computed by ad hoc measures defined according to various dimensions including content, the social network, and information diffusion patterns. Such measures only adopt information that can be extracted in a streaming fashion from observed data, and they allow to build clusters of topically related tweets. The meme clustering is carried out using a variant of Online K -means, which integrates a memory mechanism to keep track of the least recently updated memes.

We used a dataset comprised of trending hashtags on Twitter to systematically evaluate the performance of our algorithm and we showed that our method outperforms a baseline that only uses tweet text, as well as one that assumes full knowledge of the underlying social network.

One crucial feature of our system is that it can be extended to work with any clustering algorithm based on similarity (or distances). In this paper, for example, we chose to present Online K-means because of its simplicity; however, during our design, we also tested other methods including density-based and hierarchical data stream clustering algorithms (e.g., DenStream Cao et al. 2006 and LiarTree Kranen et al. 2011 ). Although a complete benchmark and tuning of these alternative methods was out of the scope of our analysis, we collected evidence of the ease of extension of our framework to different algorithms.

In the future, one could extend the set of features incorporated by our clustering framework, considering for instance entities such as images. Furthermore, our preliminary analysis suggests that the introduction of time series as features may yield significant performance improvements. Our long-term plan is to integrate the meme clustering framework with a meme classifier to distinguish engineered types of social media communication from spontaneous ones. This platform will adopt supervised learning techniques to classify memes and determine their legitimacy, with the aim to detect misinformation and deception campaigns in their early stages. The platform will be optimized to work with the real-time, high-volume streams of messages typical of Twitter and other online social media.
Footnotes

    1 .

    Example of hashtag injections include hijacked campaigns such as those by McDonald and the NYPD (CNBC 2013 ; BBC 2014 ).
    2 .

    Term vectors might or might not include retweets; in all our experiments, we include retweets. Our framework does not make any assumption on the language of the tweets either, therefore, it is flexible to work with multiple languages.
    3 .

    Note that \(R_{p}\) is not necessarily a subset of \(U_{p}\) when only a sample of the tweets is considered in the stream; the sample may include a retweeted message but not the original one.

References

    Aggarwal C, Subbian K (2012) Event detection in social streams. In: Proceedings of SIAM international conference on data mining, 2012 Google Scholar
    Albers S, Leonardi S (1999) Online algorithms. ACM Comput Surv 31(3) Google Scholar
    Babcock B, Babu S, Datar M, Motwani R, Widom J (2002) Models and issues in data stream systems. In: Proceedings of the twenty-first ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, 2002. ACM, New York, pp 1–16 Google Scholar
    Bakshy E, Hofman J, Mason W, Watts D (2011) Everyone’s an influencer: quantifying influence on twitter. In: Proceedings of the 4th ACM international conference on web search and data mining, 2011. ACM, New York, pp 65–74 Google Scholar
    Banerjee A, Ghosh J (2004) Frequency-sensitive competitive learning for scalable balanced clustering on high-dimensional hyperspheres. IEEE Trans Neural Netw 15(3):702–719 CrossRef Google Scholar
    BBC (2014) NYPD Twitter campaign ‘backfires’ after hashtag hijacked. http://www.bbc.com/news/technology-27126041
    Becker H, Naaman M, Gravano L (2010) Learning similarity metrics for event identification in social media. In: Proceedings of the 3rd ACM international conference on web search and data mining, 2010. ACM, New York, pp 291–300 Google Scholar
    Becker H, Naaman M, Gravano L (2011) Beyond trending topics: real-world event identification on twitter. In: Proceedings of the 5th international AAAI conference on weblogs and social media, 2011 Google Scholar
    Blum A (1998) On-line algorithms in machine learning. Springer, Berlin Google Scholar
    Cao F, Ester M, Qian W, Zhou A (2006) Density-based clustering over an evolving data stream with noise. In: 2006 SIAM conference on data mining, 2006, pp 328–339 Google Scholar
    Cataldi M, Caro LD, Schifanella C (2013) Personalized emerging topic detection based on a term aging model. ACM Trans Intell Syst Technol 5(1):7 CrossRef Google Scholar
    Cesa-Bianchi N (2006) Prediction, learning, and games. Cambridge University Press, Cambridge CrossRef MATH Google Scholar
    Chew C, Eysenbach G (2010) Pandemics in the age of twitter: content analysis of tweets during the 2009 H1N1 outbreak. PLoS One 5(11):e14118 CrossRef Google Scholar
    CNBC (2013) #McFail? McDonald’s Twitter campaign gets hijacked. http://www.cnbc.com/id/46132132
    Conover M, Ratkiewicz J, Francisco M, Gonçalves B, Menczer F, Flammini A (2011) Political polarization on twitter. In: ICWSM, 2011 Google Scholar
    Conover MD, Davis C, Ferrara E, McKelvey K, Menczer F, Flammini A (2013) The geospatial characteristics of a social movement communication network. PLoS One 8(3):e55957 CrossRef Google Scholar
    Conover MD, Ferrara E, Menczer F, Flammini A (2013) The digital evolution of Occupy Wall Street. PLoS One 8(5):e64679 CrossRef Google Scholar
    Danon L, Díaz-Guilera A, Duch J, Arenas A (2005) Comparing community structure identification. J Stat Mech Theory Exp 2005(09):P09008 CrossRef Google Scholar
    Ferrara E, JafariAsbagh M, Varol O, Qazvinian V, Menczer F, Flammini A (2013) Clustering memes in social media. In: Proceedings of the 2013 IEEE/ACM international conference on advances in social networks analysis and mining, 2013. IEEE/ACM, pp 548–555 Google Scholar
    Ferrara E, Varol O, Davis C, Menczer F, Flammini A (2014) The rise of social bots. arXiv preprint arXiv:1407.5225
    Ferrara E, Varol O, Menczer F, Flammini A (2013) Traveling trends: social butterflies or frequent fliers? In: Proceedings of the first ACM conference on Online social networks, 2013. ACM, pp 213–222 Google Scholar
    Fiat A, Woeginger G (1998) Online algorithms: the state of the art. Springer, Heidelberg CrossRef MATH Google Scholar
    Gaber MM, Zaslavsky A, Krishnaswamy S (2005) Mining data streams: a review. ACM Sigmod Rec 34(2):18–26 CrossRef Google Scholar
    Gama J, Gaber MM (2007) Learning from data streams. Springer, Berlin CrossRef MATH Google Scholar
    Gama J, Rodrigues PP, Spinosa EJ, de Carvalho ACPLF (2010) Knowledge discovery from data streams. Chapman and Hall/CRC, Boca Raton CrossRef MATH Google Scholar
    Golder S, Huberman B (2006) Usage patterns of collaborative tagging systems. J Inf Sci 32(2):198–208 CrossRef Google Scholar
    Golder SA, Macy MW (2011) Diurnal and seasonal mood vary with work, sleep, and daylength across diverse cultures. Science 333(6051):1878–1881 CrossRef Google Scholar
    Hong L, Davison B (2010) Empirical study of topic modeling in twitter. In: Proceedings of the 1st workshop on social media analytics, 2010. ACM, New York, pp 80–88 Google Scholar
    Kranen P, Reidl F, Villaamil FS, Seidl T (2011) Hierarchical clustering for real-time stream data with noise. In: Proceedings of the 23rd international conference on scientific and statistical database management (SSDBM 2011), Portland, Oregon, USA, 2011. Springer, Heidelberg, pp 405–413 Google Scholar
    Kwak H, Lee C, Park H, Moon S (2010) What is twitter, a social network or a news media? In: Proceedings of the 19th international conference on world wide web, 2010. ACM, New York, pp 591–600 Google Scholar
    Lancichinetti A, Fortunato S, Kertész J (2009) Detecting the overlapping and hierarchical community structure in complex networks. N J Phys 11(3):033015 CrossRef Google Scholar
    Lehmann J, Gonçalves B, Ramasco J, Cattuto C (2012) Dynamical classes of collective attention in twitter. In: Proceedings of the 21st international conference on world wide web, 2012, pp 251–260 Google Scholar
    Leskovec J, Backstrom L, Kleinberg J (2009) Meme-tracking and the dynamics of the news cycle. In: Proceedings of the 15th ACM SIGKDD international conference on knowledge discovery and data mining, 2009. ACM, New York, pp 497–506 Google Scholar
    Marcus A, Bernstein M, Badar O, Karger D, Madden S, Miller R (2011) Twitinfo: aggregating and visualizing microblogs for event exploration. In: Proceedings of the 2011 annual conference on human factors in computing systems, 2011. ACM, New York, pp 227–236 Google Scholar
    Mei Q, Cai D, Zhang D, Zhai C (2008) Topic modeling with network regularization. In: Proceedings of the 17th international conference on world wide web, 2008. ACM, New York, pp 101–110 Google Scholar
    Meilă M (2007) Comparing clusterings—an information based distance. J Multivar Anal 98(5):873–895 CrossRef MATH Google Scholar
    Metaxas P, Mustafaraj E (2010) From obscurity to prominence in minutes:political speech and real-time search. In: Proceedings of web science: extending the frontiers of society on-line, 2010 Google Scholar
    Mika P (2007) Ontologies are us: a unified model of social networks and semantics. Web Seman Sci Serv Agents World Wide Web 5(1):5–15 CrossRef MathSciNet Google Scholar
    Morales A, Losada J, Benito R (2012) Users structure and behavior on an online social network during a political protest. Users structure and behavior on an online social network during a political protest 391(21):5244–5253 Google Scholar
    Nematzadeh A, Ferrara E, Flammini A, Ahn Y-Y (2014) Optimal network modularity for information diffusion. Phys Rev Lett 113(8):088701 CrossRef Google Scholar
    Porter M (1980) An algorithm for suffix stripping. Program 14(3):130–137 CrossRef Google Scholar
    Pramod S, Vyas O (2012) Data stream mining: a review on windowing approach. Glob J Comput Sci Technol Softw Data Eng 12(11):26–30 Google Scholar
    Ratkiewicz J, Conover M, Meiss M, Gonçalves B, Patil S, Flammini A, Menczer F (2011) Truthy: mapping the spread of astroturf in microblog streams. In: Proceedings of the 20th international conference companion on world wide web, 2011. ACM, New York, pp 249–252 Google Scholar
    Sayed-Mouchaweh M, Lughofer E (2012) Learning in non-stationary environments. Springer, New York CrossRef MATH Google Scholar
    Sayyadi H, Hurst M, Maykov A (2009) Event detection and tracking in social streams. In: Proceedings of the 3rd international AAAI conference on weblogs and social media, 2009 Google Scholar
    Shalev-Shwartz S (2011) Online learning and online convex optimization. Found Trends Mach Learn 4(2):107–194 CrossRef MATH Google Scholar
    Simmons M, Adamic LA, Adar E (2011) Memes online: extracted, subtracted, injected, and recollected. In: Proceedings of the 5th international AAAI conference on weblogs and social media, 2011. AAAI, Barcelona Google Scholar
    Skoric M, Poor N, Liao Y, Tang S (2011) Online organization of an offline protest: from social to traditional media and back. In: Proceedings of the 44th Hawaii international conference on system sciences, 2011 Google Scholar
    Thom D, Bosch H, Koch S, Worner M, Ertl T (2012) Spatiotemporal anomaly detection through visual analysis of geolocated twitter messages. In: IEEE Pacific visualization symposium, pp 41–48 Google Scholar
    Tsur O, Rappoport A (2012) What’s in a hashtag?: content based prediction of the spread of ideas in microblogging communities. In: Proceedings of the fifth ACM international conference on Web search and data mining, 2012. ACM, New York, pp 643–652 Google Scholar
    Varol O, Ferrara E, Ogan CL, Menczer F, Flammini A (2014) Evolution of online user behavior during a social upheaval. In: Proceedings of the 2014 ACM conference on Web science, 2014. ACM, New York, pp 81–90 Google Scholar
    Wu S, Hofman J, Mason W, Watts D (2011) Who says what to whom on twitter. In: Proceedings of the 20th international conference on world wide web, 2011. ACM, New York, pp 705–714 Google Scholar
    Xie L, Natsev A, Kender JR, Hill M, Smith JR (2011) Visual memes in social media: tracking real-world news in youtube videos. In: Proceedings of the 19th ACM international conference on multimedia, 2011. ACM, New York, pp 53–62 Google Scholar
    Yang L, Sun T, Zhang M, Mei Q (2012) We know what@ you# tag: does the dual role affect hashtag adoption? In: Proceedings of the 21st international conference on World Wide Web, 2012. ACM, New York, pp 261–270 Google Scholar
    Yih W, Qazvinian V (2012) Measuring word relatedness using heterogeneous vector space models. In: Proceedings of annual conference of the North American chapter of ACL, 2012 Google Scholar
    Zhong S (2005) Efficient online spherical k-means clustering. In: Proceedings of the 2005 IEEE international joint conference on neural networks, IJCNN’05, vol 5. IEEE, pp 3180–3185 Google Scholar

Copyright information
© Springer-Verlag Wien 2014
About this article
CrossMark

Cite this article as:
    JafariAsbagh, M., Ferrara, E., Varol, O. et al. Soc. Netw. Anal. Min. (2014) 4: 237. https://doi.org/10.1007/s13278-014-0237-x

    DOI https://doi.org/10.1007/s13278-014-0237-x
    Publisher Name Springer Vienna
    Print ISSN 1869-5450
    Online ISSN 1869-5469

    About this journal
    Reprints and Permissions

Personalised recommendations
Clustering memes in social media streams
Cite article

    How to cite?
    .RIS Papers Reference Manager RefWorks Zotero
    .ENW EndNote
    .BIB BibTeX JabRef Mendeley

Share article Download PDF
Actions
Download PDF
Cite article

    How to cite?
    .RIS Papers Reference Manager RefWorks Zotero
    .ENW EndNote
    .BIB BibTeX JabRef Mendeley

Share article
Table of contents

    Article
    Abstract
    1 Introduction
    2 Online clustering framework
    3 Evaluation
    4 Results
    5 Related work
    6 Conclusions
    Footnotes
    References
    Copyright information
    About this article

Over 10 million scientific documents at your fingertips
Academic Edition

    Academic Edition
    Corporate Edition

    Home
    Impressum
    Legal information
    Privacy statement
    How we use cookies
    Accessibility
    Contact us

Springer Nature

© 2017 Springer International Publishing AG. Part of Springer Nature .

Not logged in CAPES MEC (3000197460) - Universidade Tecnologica Federal do Parana (3000201946) 168.181.51.234

    Your Privacy

    Strictly Necessary Cookies

    Performance Cookies

    Functional Cookies

    Targeting Cookies

    More Information

Privacy Preference Centre

Active

Always Active
Save Settings
Allow All

We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners in accordance with our Privacy Statement . You can manage your preferences in Manage Cookies.
Close
OK
Manage Cookies
