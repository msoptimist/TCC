<!DOCTYPE html>
<html class="js" lang="en-gb"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=2.5,user-scalable=yes">
    <meta name="citation_publisher" content="Springer International Publishing">
    <meta name="citation_title" content="Big Data: Deep Learning for financial sentiment analysis">
    <meta name="citation_doi" content="10.1186/s40537-017-0111-6">
    <meta name="citation_language" content="en">
    <meta name="citation_abstract_html_url" content="https://link.springer.com/article/10.1186/s40537-017-0111-6">
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1186/s40537-017-0111-6">
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1186%2Fs40537-017-0111-6.pdf">
    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1186/s40537-017-0111-6&amp;api_key=">
    <meta name="citation_firstpage" content="3">
    <meta name="citation_author" content="Sahar Sohangir">
    <meta name="citation_author_institution" content="Florida Atlantic University">
    <meta name="citation_author_email" content="ssohangir2014@fau.edu">
    <meta name="citation_author" content="Dingding Wang">
    <meta name="citation_author_institution" content="Florida Atlantic University">
    <meta name="citation_author" content="Anna Pomeranets">
    <meta name="citation_author_institution" content="Florida Atlantic University">
    <meta name="citation_author" content="Taghi M. Khoshgoftaar">
    <meta name="citation_author_institution" content="Florida Atlantic University">
    <meta name="dc.identifier" content="10.1186/s40537-017-0111-6">
    <meta name="format-detection" content="telephone=no">
    <meta name="citation_fulltext_world_readable" content="">
    <meta name="description" content="Deep Learning and Big Data analytics are two focal points of data science. Deep Learning models have achieved remarkable results in speech recognition and computer vision in recent years. Big Data is...">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Big Data: Deep Learning for financial sentiment analysis">
    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/40537/5/1.jpg">
    <meta name="twitter:image:alt" content="Content cover image">
    <meta name="twitter:site" content="SpringerLink">
    <meta name="twitter:description" content="Deep Learning and Big Data analytics are two focal points of data science. Deep Learning models have achieved remarkable results in speech recognition and computer vision in recent years. Big Data is...">
    <meta name="citation_journal_title" content="Journal of Big Data">
    <meta name="citation_journal_abbrev" content="J Big Data">
    <meta name="citation_volume" content="5">
    <meta name="citation_issue" content="1">
    <meta name="citation_issn" content="2196-1115">
    <meta name="citation_online_date" content="2018/01/25">
    <meta name="citation_cover_date" content="2018/12/01">
    <meta name="citation_article_type" content="Research">
    <meta property="og:title" content="Big Data: Deep Learning for financial sentiment analysis">
    <meta property="og:type" content="Article">
    <meta property="og:url" content="https://link.springer.com/article/10.1186/s40537-017-0111-6">
    <meta property="og:image" content="https://static-content.springer.com/cover/journal/40537/5/1.jpg">
    <meta property="og:site_name" content="SpringerLink">
    <meta property="og:description" content="Deep Learning and Big Data analytics are two focal points of data science. Deep Learning models have achieved remarkable results in speech recognition and computer vision in recent years. Big Data is...">

        <title>Big Data: Deep Learning for financial sentiment analysis | SpringerLink</title>
        <link rel="canonical" href="https://link.springer.com/article/10.1186/s40537-017-0111-6">
        <link rel="shortcut icon" href="https://link.springer.com/springerlink-static/481091012/images/favicon/favicon.ico">
<link rel="icon" sizes="16x16 32x32 48x48" href="https://link.springer.com/springerlink-static/481091012/images/favicon/favicon.ico">
<link rel="icon" sizes="16x16" type="image/png" href="https://link.springer.com/springerlink-static/481091012/images/favicon/favicon-16x16.png">
<link rel="icon" sizes="32x32" type="image/png" href="https://link.springer.com/springerlink-static/481091012/images/favicon/favicon-32x32.png">
<link rel="icon" sizes="48x48" type="image/png" href="https://link.springer.com/springerlink-static/481091012/images/favicon/favicon-48x48.png">
<link rel="apple-touch-icon" href="https://link.springer.com/springerlink-static/481091012/images/favicon/app-icon-iphone@3x.png">
<link rel="apple-touch-icon" sizes="72x72" href="https://link.springer.com/springerlink-static/481091012/images/favicon/ic_launcher_hdpi.png">
<link rel="apple-touch-icon" sizes="76x76" href="https://link.springer.com/springerlink-static/481091012/images/favicon/app-icon-ipad.png">
<link rel="apple-touch-icon" sizes="114x114" href="https://link.springer.com/springerlink-static/481091012/images/favicon/app-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="https://link.springer.com/springerlink-static/481091012/images/favicon/app-icon-iphone@2x.png">
<link rel="apple-touch-icon" sizes="144x144" href="https://link.springer.com/springerlink-static/481091012/images/favicon/ic_launcher_xxhdpi.png">
<link rel="apple-touch-icon" sizes="152x152" href="https://link.springer.com/springerlink-static/481091012/images/favicon/app-icon-ipad@2x.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://link.springer.com/springerlink-static/481091012/images/favicon/app-icon-iphone@3x.png">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="/springerlink-static/481091012/images/favicon/ic_launcher_xxhdpi.png">
        <link rel="dns-prefetch" href="https://fonts.gstatic.com/">
<link rel="dns-prefetch" href="https://fonts.googleapis.com/">
<link rel="dns-prefetch" href="https://google-analytics.com/">
<link rel="dns-prefetch" href="https://www.google-analytics.com/">
<link rel="dns-prefetch" href="https://www.googletagservices.com/">
<link rel="dns-prefetch" href="https://www.googletagmanager.com/">
<link rel="dns-prefetch" href="https://static-content.springer.com/">
        <link rel="stylesheet" href="basic.css" media="screen">
<link rel="stylesheet" href="styles.css" class="js-ctm" media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
<link rel="stylesheet" href="print.css" media="print">


            <script type="text/javascript" src="https://beacon.krxd.net/optout_check?request_id=405f037f-9987-44e9-b69b-f9014542ddb3&amp;callback=Krux.ns._default.kxjsonp_optOutCheck"></script><script type="text/javascript" src="https://consumer.krxd.net/consent/set/bd339c69-af54-4a21-b4f1-654bcfcd83ca?request_id=cb90deae-de4f-45db-aba9-4688dadae4ee&amp;idt=device&amp;dt=kxcookie&amp;dc=1&amp;al=1&amp;tg=1&amp;cd=0&amp;sh=0&amp;re=0&amp;callback=Krux.ns._default.kxjsonp_consent_set_1"></script><script type="text/javascript" src="https://consumer.krxd.net/consent/get/bd339c69-af54-4a21-b4f1-654bcfcd83ca?idt=device&amp;dt=kxcookie&amp;callback=Krux.ns._default.kxjsonp_consent_get_0"></script><script type="text/javascript" async="" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async="" src="//cdn.krxd.net/ctjs/controltag.js.8f9c5605187855d5a137991abae6f700"></script><script type="text/javascript" async="" src="KDqyaFZ_.js"></script><script type="text/javascript" async="" src="analytics.js"></script><script async="" src="mathJax.js"></script><script async="" src="gtm.js"></script><script>
        window.Krux||((Krux=function(){Krux.q.push(arguments);}).q=[]);
        var dataLayer = [{
                'GA Key':'UA-26408784-1',
                'Features':["leaderboardadverts","abtesting","reprintsandpermissionsabtest"],
                'Event Category':'Article',
                'Open Access':'Y',
                'Labs':'Y',
                'DOI':'10.1186\/s40537-017-0111-6',
                'VG Wort Identifier':'vgzm.415900-10.1186-s40537-017-0111-6',
                'HasAccess':'Y',
                'Full HTML':'Y',
                'Has Body':'Y',
                'Static Hash':'481091012',
                'Has Preview':'N',
                'user':{'license': {'businessPartnerID': ['3000197460', '3000201946'], 'businessPartnerIDString': '3000197460|3000201946'}},
                'content':{'type': 'article', 'serial': {'eissn': '2196-1115', 'pissn': ''}, 'category': {'pmc': {'primarySubject': 'Computer Science', 'primarySubjectCode': 'I', 'secondarySubjects': {'4': 'Computational Science and Engineering', '5': 'Mathematical Applications in Computer Science', '6': 'Communications Engineering, Networks', '1': 'Database Management', '2': 'Information Storage and Retrieval', '3': 'Data Mining and Knowledge Discovery'}, 'secondarySubjectCodes': {'4': 'M14026', '5': 'M13110', '6': 'T24035', '1': 'I18024', '2': 'I18032', '3': 'I18030'}}, 'sucode': 'Computer Science'}},
                'Access Type':'subscription',
                'Page':'article',
                'Bpids':'3000197460, 3000201946',
                'Bpnames':'CAPES MEC, Universidade Tecnologica Federal do Parana',
                'SubjectCodes':'SCI, SCI18024, SCI18032, SCI18030, SCM14026, SCM13110, SCT24035',
                'session':{'authentication': {'loginStatus': 'N'}, 'attributes': {'edition': 'academic'}},
                'Keywords':'Deep Learning, Big Data, Sentiment analysis, Information retrieval',
                'Country':'BR',
                'Journal Id':'40537',
                'Journal Title':'Journal of Big Data',

                'doi': "10.1186-s40537-017-0111-6",
                'kwrd': ["Deep_Learning","Big_Data","Sentiment_analysis","Information_retrieval"],
                'pmc': ["I","I18024","I18032","I18030","M14026","M13110","T24035"],
                'BPID': ["3000197460","3000201946"],
                'ksg': Krux.segments,
                'kuid': Krux.uid,

        }];
    </script>

    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
                new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WCF9Z9');</script>

    <style>@font-face{font-family:'Source Sans Pro';font-weight:400;src:url(data:application/font-woff;base64,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) format('woff')}@font-face{font-family:'Source Sans Pro';font-weight:600;src:url(data:application/font-woff;base64,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) format('woff')}</style><link type="text/css" href="optanon.css" rel="stylesheet"><style>#optanon ul#optanon-menu li { background-color: #F7FBFE !important }#optanon ul#optanon-menu li.menu-item-selected { background-color: #FFFFFF !important }#optanon #optanon-popup-wrapper .optanon-white-button-middle { background-color: #3365A4 !important }.optanon-alert-box-wrapper .optanon-alert-box-button-middle { background-color: #3365A4 !important; border-color: #3365A4 !important; }#optanon #optanon-popup-wrapper .optanon-white-button-middle a { color: #ffffff !important }.optanon-alert-box-wrapper .optanon-alert-box-button-middle a { color: #ffffff !important }#optanon #optanon-popup-bottom { background-color: #F7FBFE !important }#optanon.modern #optanon-popup-top, #optanon.modern #optanon-popup-body-left-shading { background-color: #F7FBFE !important }.optanon-alert-box-wrapper { background-color:#F7FBFE !important }.optanon-alert-box-wrapper .optanon-alert-box-bg p { color:#333333 !important }</style><link rel="preload" href="integrator_002.js"><script type="text/javascript" src="integrator_002.js"></script><link rel="preload" href="integrator.js"><script type="text/javascript" src="integrator.js"></script><script src="pubads_impl_216.js" async=""></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/config/TeX-AMS-MML_HTMLorMML.js?V=2.7.4"></script></head>
    <body><button href="javascript:;" title="focus catcher" class="js-focus-catcher u-screenreader-only" tabindex="-1"></button><div id="popup-references" class="u-composite-layer popup-base-theme" style="top:-60px;left:-60px;visibility:hidden;opacity:0;" aria-hidden="true" aria-label="popup"><svg class="popup-arrow" xmlns="http://www.w3.org/2000/svg" width="33.7" height="18.4" viewBox="0 0 33.7 18.4"><path class="fill" fill="#F7FBFE" d="M1.4 18.4h30.9l-15.5-16.9z"></path><path class="stroke" fill="#98BED7" d="M0 18.4h1.4l15.4-16.9 15.5 16.9h1.4l-16.9-18.4z"></path></svg><div class="popup-arrow popup-arrow-shadow icon--popup-arrow-shadow"></div><div class="popup__references"><div class="popup-base-theme__inner" data-component="SpringerLink-Popup-inner"></div></div><button tabindex="-1" class="popup-close icon--close-btn" data-component="SpringerLink-Popup-close">close</button></div><div id="popup-article-dates" class="u-composite-layer popup-base-theme" style="top:-60px;left:-60px;visibility:hidden;opacity:0;" aria-hidden="true" aria-label="popup"><svg class="popup-arrow" xmlns="http://www.w3.org/2000/svg" width="33.7" height="18.4" viewBox="0 0 33.7 18.4"><path class="fill" fill="#F7FBFE" d="M1.4 18.4h30.9l-15.5-16.9z"></path><path class="stroke" fill="#98BED7" d="M0 18.4h1.4l15.4-16.9 15.5 16.9h1.4l-16.9-18.4z"></path></svg><div class="popup-arrow popup-arrow-shadow icon--popup-arrow-shadow"></div><div class="popup__article-dates"><div class="popup-base-theme__inner" data-component="SpringerLink-Popup-inner"></div></div><button tabindex="-1" class="popup-close icon--close-btn" data-component="SpringerLink-Popup-close">close</button></div><div id="popup-search" class="u-composite-layer popup-search-theme" style="top:-60px;left:-60px;visibility:hidden;opacity:0;" aria-hidden="true" aria-label="popup"><svg class="popup-arrow" xmlns="http://www.w3.org/2000/svg" width="33.7" height="18.4" viewBox="0 0 33.7 18.4"><path class="fill" fill="#F7FBFE" d="M1.4 18.4h30.9l-15.5-16.9z"></path><path class="stroke" fill="#98BED7" d="M0 18.4h1.4l15.4-16.9 15.5 16.9h1.4l-16.9-18.4z"></path></svg><div class="popup-arrow popup-arrow-shadow icon--popup-arrow-shadow"></div><div class="popup__search"><div class="popup-base-theme__inner" data-component="SpringerLink-Popup-inner"></div></div><button tabindex="-1" class="popup-close icon--close-btn" data-component="SpringerLink-Popup-close">close</button></div>
        <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                      height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <nav class="skip-to">
    <a class="skip-to__link skip-to__link--article" href="#main-content">Skip to main content</a>
        <a class="skip-to__link skip-to__link--contents" href="#article-contents">Skip to sections</a>
</nav>
        <div class="page-wrapper">
            <noscript>
    <div class="nojs-banner u-interface">
        <p>This service is more advanced with JavaScript available, learn more at <a
                href="http://activatejavascript.org" target="_blank" rel="noopener">http://activatejavascript.org</a>
        </p>
    </div>
</noscript>
                    <div id="leaderboard" class="leaderboard u-hide" data-component="SpringerLink.GoogleAds" data-namespace="leaderboard"><div class="leaderboard__wrapper"><p class="leaderboard__label">Advertisement</p><button class="leaderboard__hide" title="Hide this advertisement">Hide</button><div id="doubleclick-leaderboard-ad" class="leaderboard__ad"><div id="google_ads_iframe_270604982/springerlink/40537/article_0__container__" style="border: 0pt none;"><iframe id="google_ads_iframe_270604982/springerlink/40537/article_0" title="3rd party ad content" name="google_ads_iframe_270604982/springerlink/40537/article_0" scrolling="no" marginwidth="0" marginheight="0" style="border: 0px none; vertical-align: bottom;" srcdoc="" width="728" frameborder="0" height="90"></iframe></div></div></div></div>

                <header id="header" class="header u-interface">
        <div class="header__content">
            <div class="header__menu-container">
                    <a id="logo" class="site-logo" href="https://link.springer.com/" title="Go to homepage">
                <div class="u-screenreader-only">SpringerLink</div>
    <svg class="site-logo__springer" width="148" height="30" role="img" focusable="false" aria-hidden="true">
        <image width="148" height="30" alt="" src="/springerlink-static/481091012/images/png/springerlink.png" xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/481091012/images/svg/springerlink.svg"></image>
    </svg>

    </a>


                    <nav id="search-container" class="u-inline-block">
                        <div class="search">
                            <div class="search__content">
                                <form class="u-form-single-input" action="/search" method="get" role="search">
    <input aria-label="Search SpringerLink" name="query" autocomplete="off" placeholder="Search SpringerLink" type="text">
    <input class="u-hide-text" value="Submit" title="Submit" type="submit">
    <svg class="u-vertical-align-absolute" width="13" height="13" viewBox="222 151 13 13" version="1.1" xmlns="http://www.w3.org/2000/svg" focusable="false" aria-hidden="true" role="presentation">
        <path d="M227 159C228.7 159 230 157.7 230 156 230 154.3 228.7 153 227 153 225.3 153 224 154.3 224 156 224 157.7 225.3 159 227 159L227 159 227 159 227 159ZM230 160.1L231.1 159 233.9 161.7C234.2 162.1 234.2 162.6 233.9 162.9 233.6 163.2 233.1 163.2 232.7 162.9L230 160.1 230 160.1 230 160.1 230 160.1ZM227 161L227 161C224.2 161 222 158.8 222 156 222 153.2 224.2 151 227 151 229.8 151 232 153.2 232 156 232 158.8 229.8 161 227 161L227 161 227 161 227 161 227 161Z" stroke="none" fill-rule="evenodd"></path>
    </svg>
</form>
                            </div>
                        </div>
                    </nav>

                    <nav class="nav-container u-interface">
    <div class="global-nav__wrapper">
        <div class="search-button">
            <a class="search-button__label" href="#search-container" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-search">
                <span class="search-button__title">Search</span><svg width="12" height="12" viewBox="222 151 12 12" version="1.1" xmlns="http://www.w3.org/2000/svg" focusable="false" aria-hidden="true" role="presentation">
                    <path d="M227 159C228.7 159 230 157.7 230 156 230 154.3 228.7 153 227 153 225.3 153 224 154.3 224 156 224 157.7 225.3 159 227 159L227 159 227 159 227 159ZM230 160.1L231.1 159 233.9 161.7C234.2 162.1 234.2 162.6 233.9 162.9 233.6 163.2 233.1 163.2 232.7 162.9L230 160.1 230 160.1 230 160.1 230 160.1ZM227 161L227 161C224.2 161 222 158.8 222 156 222 153.2 224.2 151 227 151 229.8 151 232 153.2 232 156 232 158.8 229.8 161 227 161L227 161 227 161 227 161 227 161Z" stroke="none" fill-rule="evenodd"></path>
                </svg>
            </a>
        </div>

        <ul class="global-nav" data-component="SpringerLink.Menu" data-title="Navigation menu" data-text="Menu">
            <li>
                <a href="https://link.springer.com/">
                    <span class="u-overflow-ellipsis">Home</span>
                </a>
            </li>
            <li>
                <a href="https://link.springer.com/contactus">
                    <span class="u-overflow-ellipsis">Contact us</span>
                </a>
            </li>

                <li class="global-nav__logged-out">
                    <a class="test-login-link" href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1186%2Fs40537-017-0111-6">
                        <span class="u-overflow-ellipsis">Log in</span>
                    </a>
                </li>

        </ul><div class="main-menu u-composite-layer c-button-dropdown c-button-dropdown--ghost" data-component="SV.Dropdown" data-namespace="Menu" aria-label="button with dropdown options" style="width: 75.3333px;"><button type="button" title="Navigation menu" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown.Menu-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">Menu</span><span class="c-button-dropdown__icon"></span></button><div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown.Menu-dropdown"><ul class="main-menu__content" data-role="button-dropdown__content"><li>
                <a href="https://link.springer.com/" tabindex="-1">
                    <span class="u-overflow-ellipsis">Home</span>
                </a>
            </li><li>
                <a href="https://link.springer.com/contactus" tabindex="-1">
                    <span class="u-overflow-ellipsis">Contact us</span>
                </a>
            </li><li class="global-nav__logged-out">
                    <a class="test-login-link" href="https://link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1186%2Fs40537-017-0111-6" tabindex="-1">
                        <span class="u-overflow-ellipsis">Log in</span>
                    </a>
                </li></ul></div></div>
    </div> 
</nav> 
            </div>

        </div>
    </header>

            

            <main id="main-content" class="main-wrapper" tabindex="-1">
                <div class="main-container uptodate-recommendations-off">
                    <aside class="main-sidebar-left">
                        <div class="main-sidebar-left__content">
                            <div class="test-cover cover-image" itemscope="">
        <a class="test-cover-link" href="https://link.springer.com/journal/40537" title="Journal of Big Data">
            <img class="test-cover-image" src="1.jpg" alt="Journal of Big Data" itemprop="image">
        </a>

</div>
                        </div>
                    </aside>
                    <div class="main-body" data-role="NavigationContainer">
                                <div class="cta-button-container cta-button-container--top cta-button-container--stacked u-mb-16 u-hide-two-col">
                    <a href="https://link.springer.com/content/pdf/10.1186%2Fs40537-017-0111-6.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right gtm-pdf-link" title="Download this article in PDF format" rel="noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"></path></g></g></g></svg>
            <span class="hide-text-small">Download</span>
            <span>PDF</span>
        </a>

        </div>



                        <article class="main-body__content">
                            <div xmlns="http://www.w3.org/1999/xhtml" class="FulltextWrapper"><div class="ArticleHeader main-context"><div id="enumeration" class="enumeration"><p><a href="https://link.springer.com/journal/40537" title="Journal of Big Data"><span class="JournalTitle">Journal of Big Data</span></a></p><p class="icon--meta-keyline-before"><span class="ArticleCitation_Year"><time datetime="2018-12">December 2018</time>, </span><span class="ArticleCitation_Volume">5:3</span><span class="u-inline-block u-ml-4"> | <a class="gtm-cite-link" href="#citeas">Cite as</a></span></p></div><div class="MainTitleSection"><h1 class="ArticleTitle" lang="en">Big Data: Deep Learning for financial sentiment analysis</h1></div><div class="authors u-clearfix authors--enhanced" data-component="SpringerLink.Authors"><ul class="u-interface u-inline-list authors__title" data-role="AuthorsNavigation"><li><a href="#authors" class="gtm-tab-authors selected">Authors</a></li><li><a href="#authorsandaffiliations" class="gtm-tab-authorsandaffiliations">Authors and affiliations</a></li></ul><span class="marker" style="width: 160px;"></span><div class="authors__list" data-role="AuthorsList" id="authors"><ul class="test-contributor-names"><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Sahar&nbsp;Sohangir</span><span class="author-information"><span class="authors__contact"><a href="mailto:ssohangir2014@fau.edu" title="ssohangir2014@fau.edu" itemprop="email" class="gtm-email-author">Email author</a></span></span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Dingding&nbsp;Wang</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Anna&nbsp;Pomeranets</span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors__name">Taghi&nbsp;M.&nbsp;Khoshgoftaar</span></li></ul></div><div class="authors__affiliations" id="authorsandaffiliations"><div class="authors-affiliations u-interface"><ul class="test-contributor-names"><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Sahar&nbsp;Sohangir</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul><span class="author-information"><span class="author-information__contact u-icon-before icon--email-before"><a href="mailto:ssohangir2014@fau.edu" title="ssohangir2014@fau.edu" itemprop="email" class="gtm-email-author">Email author</a></span><span class="author-information__orcid u-icon-before icon--ORCID-before"><a class="u-external gtm-orcid-link" href="http://orcid.org/0000-0003-1800-1696" itemprop="url" title="View OrcID profile" target="_blank" rel="noopener">View author's OrcID profile</a></span></span></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Dingding&nbsp;Wang</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Anna&nbsp;Pomeranets</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-2">2</li></ul></li><li itemscope="" itemtype="http://schema.org/Person" class="u-mb-2 u-pt-4 u-pb-4"><span itemprop="name" class="authors-affiliations__name">Taghi&nbsp;M.&nbsp;Khoshgoftaar</span><ul class="authors-affiliations__indexes u-inline-list" data-role="AuthorsIndexes"><li data-affiliation="affiliation-1">1</li></ul></li></ul><ol class="test-affiliations"><li class="affiliation" data-test="affiliation-1" data-affiliation-highlight="affiliation-1" itemscope="" itemtype="http://schema.org/Organization"><span class="affiliation__count">1.</span><span class="affiliation__item"><span itemprop="department" class="affiliation__department">Department of Computer &amp; Electrical Engineering and Computer Science</span><span itemprop="name" class="affiliation__name">Florida Atlantic University</span><span itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress" class="affiliation__address"><span itemprop="addressRegion" class="affiliation__city">Boca Raton</span><span itemprop="addressCountry" class="affiliation__country">USA</span></span></span></li><li class="affiliation" data-test="affiliation-2" data-affiliation-highlight="affiliation-2" itemscope="" itemtype="http://schema.org/Organization"><span class="affiliation__count">2.</span><span class="affiliation__item"><span itemprop="department" class="affiliation__department">College of Business</span><span itemprop="name" class="affiliation__name">Florida Atlantic University</span><span itemprop="address" itemscope="" itemtype="http://schema.org/PostalAddress" class="affiliation__address"><span itemprop="addressRegion" class="affiliation__city">Boca Raton</span><span itemprop="addressCountry" class="affiliation__country">USA</span></span></span></li></ol></div></div></div><div class="main-context__container" data-component="SpringerLink.ArticleMetrics"><div class="main-context__column"><span><div id="open-choice-icon" class="open-access u-text-separator-after-micro"><abbr title="This content is freely available to anyone, anywhere, at any time">Open Access</abbr></div><span class="test-render-category">Research</span></span><div class="article-dates article-dates--enhanced" data-component="SpringerLink.ArticleDates"><div class="article-dates__entry"><span class="article-dates__label">First Online: </span><span class="article-dates__first-online"><a href="#article-dates-history" class="gtm-first-online" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-article-dates">25 January 2018</a></span></div><div class="article-dates__history" id="article-dates-history"><div class="article-dates__entry"><span class="article-dates__label">Received: </span><span><time datetime="2017-04-20">20 April 2017</time></span></div><div class="article-dates__entry"><span class="article-dates__label">Accepted: </span><span><time datetime="2017-12-28">28 December 2017</time></span></div></div></div></div><div class="main-context__column">    <ul id="book-metrics" class="article-metrics u-sansSerif">
            <li class="article-metrics__item">
                    <a class="article-metrics__link gtm-socialmediamentions-count" href="http://www.altmetric.com/details.php?citation_id=32231689&amp;domain=link.springer.com" target="_blank" rel="noopener" title="Visit Altmetric for full social mention details" id="socialmediamentions-link">
                            <span id="socialmediamentions-count-number" class="test-metric-count c-button-circle gtm-socialmediamentions-count">12</span>
                       <span class="test-metric-name article-metrics__label gtm-socialmediamentions-count">Shares</span>
                    </a>
            </li>
            <li class="article-metrics__item">
                     <span class="article-metrics__views">6.5k</span>
                     <span class="article-metrics__label">Downloads</span>
            </li>
            <li class="article-metrics__item">
                    <a class="article-metrics__link gtm-citations-count" href="https://citations.springer.com/item?doi=10.1186/s40537-017-0111-6" target="_blank" rel="noopener" title="Visit Springer Citations for full citation details" id="citations-link">
                            <span id="citations-count-number" class="test-metric-count c-button-circle gtm-citations-count">1</span>
                       <span class="test-metric-name article-metrics__label gtm-citations-count">Citations</span>
                    </a>
            </li>
    </ul>
</div></div><div class="article-collection"><strong>Part of the following topical collections:</strong><ol id="article-collection" class="article-collection__list u-bullet-list"><li><a href="https://link.springer.com/journal/40537/topicalCollection/AC_0b1e5d249fa663acb06e05a37943fac3" title="Advanced Soft Computing Methodologies and Applications in Social Media Big Data Analytics">Advanced Soft Computing Methodologies and Applications in Social Media Big Data Analytics</a></li></ol></div></div><section class="Abstract" id="Abs1" tabindex="-1" lang="en"><h2 class="Heading">Abstract</h2><p id="Par1" class="Para">Deep
 Learning and Big Data analytics are two focal points of data science. 
Deep Learning models have achieved remarkable results in speech 
recognition and computer vision in recent years. Big Data is important 
for organizations that need to collect a huge amount of data like a 
social network and one of the greatest assets to use Deep Learning is 
analyzing a massive amount of data (Big Data). This advantage makes Deep
 Learning as a valuable tool for Big Data. Deep Learning can be used to 
extract incredible information that buried in a Big Data. The modern 
stock market is an example of these social networks. They are a popular 
place to increase wealth and generate income, but the fundamental 
problem of when to buy or sell shares, or which stocks to buy has not 
been solved. It is very common among investors to have professional 
financial advisors, but what is the best resource to support the 
decisions these people make? Investment banks such as Goldman Sachs, 
Lehman Brothers, and Salomon Brothers dominated the world of financial 
advice for more than a decade. However, via the popularity of the 
Internet and financial social networks such as StockTwits and 
SeekingAlpha, investors around the world have new opportunity to gather 
and share their experiences. Individual experts can predict the movement
 of the stock market in financial social networks with the reasonable 
accuracy, but what is the sentiment of a mass group of these expert 
authors towards various stocks? In this paper, we seek to determine if 
Deep Learning models can be adapted to improve the performance of 
sentiment analysis for StockTwits. We applied several neural network 
models such as long short-term memory, doc2vec, and convolutional neural
 networks, to stock market opinions posted in StockTwits. Our results 
show that Deep Learning model can be used effectively for financial 
sentiment analysis and a convolutional neural network is the best model 
to predict sentiment of authors in StockTwits dataset.</p></section><div class="KeywordGroup" lang="en"><h2 class="Heading">Keywords</h2><span class="Keyword">Deep Learning&nbsp;</span><span class="Keyword">Big Data&nbsp;</span><span class="Keyword">Sentiment analysis&nbsp;</span><span class="Keyword">Information retrieval&nbsp;</span></div><div class="article-actions--inline" id="article-actions--inline" data-component="article-actions--inline"><div class="citations u-interface c-button-dropdown" data-component="SV.Dropdown" data-namespace="citations--inline" aria-label="button with dropdown options">
        <button type="button" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown.citations--inline-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</span><span class="c-button-dropdown__icon"></span></button>
<div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown.citations--inline-dropdown"><ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" class="gtm-cite-dropdown" tabindex="-1">How to cite?</a>
    </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=refman&amp;flavour=citation" title="Download this article's citation as a .RIS file" class="gtm-export-citation" data-gtmlabel="RIS" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=endnote&amp;flavour=citation" title="Download this article's citation as a .ENW file" class="gtm-export-citation" data-gtmlabel="ENW" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=bibtex&amp;flavour=citation" title="Download this article's citation as a .BIB file" class="gtm-export-citation" data-gtmlabel="BIB" tabindex="-1">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul></div>
    </div></div><div id="body"><section id="Sec1" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="0">Introduction<span class="section-icon"></span></h2><div class="content"><p id="Par2" class="Para">The
 Internet, as a global system of interconnection, provides a link 
between billions of devices and people around the world. The rapid 
development of social networks causes the tremendous growth of users and
 digital content&nbsp;[<span class="CitationRef"><a href="#CR1" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">1</a></span>].
 It opens opportunities for people with various skills and knowledge to 
share their experiences and wisdom with each other. There are many 
websites like <em class="EmphasisTypeItalic ">Yelp</em>, <em class="EmphasisTypeItalic ">Wikipedia</em>, <em class="EmphasisTypeItalic ">Flickr</em>, etc. that use the power of the Internet to help their users make optimal decisions.</p><p id="Par3" class="Para">Furthermore,
 there are websites that give users the ability to consult with 
professionals, and one topic that is always popular is investment. 
Companies like Goldman Sachs and Lehman Brothers have more than 150 
years of investment advice. In the Internet age, independent analysts 
and retail investors around the world can collaborate with each other 
through the web. Seeking Alpha and StockTwits are two examples of common
 financial social media platforms focused on the stock market, giving 
their users a way to connect with information and each other and grow 
their investments&nbsp;[<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>].</p><p id="Par4" class="Para">Financial
 social media brings people, companies, and organizations together so 
that they can generate ideas and share information with others. It is 
this media that provides a huge amount of unstructured data (Big Data) 
that can be integrated into the decision-making process. Such a Big Data
 can be considered as a great source of real-time estimation because of 
its high frequency of creation and low-cost acquisition.</p><p id="Par5" class="Para"><em class="EmphasisTypeItalic ">Sentiment analysis (SA)</em>
 is a common method which is increasingly used to assess the feelings of
 social media users towards a subject. The most popular approach 
performing sentiment analysis is using data mining. Our central idea is 
to adopt Deep Learning to determine investors expectations about the 
price of stocks and the overall market based on their messages. The 
reason why we select Deep Learning methodology rather than data mining 
is that in data mining, identifying features and selecting the best of 
those features is the most challenging task to undertake especially in a
 Big Data.</p><p id="Par6" class="Para">In contrast to data mining, a 
Deep Learning model, learns features during the process of learning. 
Deep Learning algorithms lead to abstract representation, as a result, 
they can be invariant to the local change in the input data. In 
addition, Big Data problems including semantic indexing, data tagging, 
and fast information retrieval can be addressed better with the aid of 
Deep Learning. Deep Learning provides the opportunity to use a simpler 
model to accomplish complicated Artificial Intelligence tasks. Although 
Deep Learning algorithms have been used for some Big Data domain like 
computer vision&nbsp;[<span class="CitationRef"><a href="#CR3" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">3</a></span>, <span class="CitationRef"><a href="#CR4" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">4</a></span>, <span class="CitationRef"><a href="#CR5" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">5</a></span>, <span class="CitationRef"><a href="#CR17" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">17</a></span>, <span class="CitationRef"><a href="#CR18" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">18</a></span>, <span class="CitationRef"><a href="#CR22" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">22</a></span>]&nbsp;and speech recognition&nbsp;[<span class="CitationRef"><a href="#CR6" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">6</a></span>, <span class="CitationRef"><a href="#CR7" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">7</a></span>, <span class="CitationRef"><a href="#CR8" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">8</a></span>, <span class="CitationRef"><a href="#CR9" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">9</a></span>, <span class="CitationRef"><a href="#CR10" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">10</a></span>, <span class="CitationRef"><a href="#CR11" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">11</a></span>]&nbsp;it
 is still intact in the context of Big Data analysis. In this paper, we 
evaluate the adoption of Deep Learning for sentiment analysis of 
financial data.</p><p id="Par7" class="Para">Deep Learning algorithms 
provide the opportunity to extract complex data at a high level of 
abstraction in a way that high-level features with more abstraction are 
defined in terms of lower-level features with less abstraction&nbsp;[<span class="CitationRef"><a href="#CR12" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">12</a></span>].
 A different source of variation in data (like light, object shapes, and
 object materials in an image) can be separated by using Deep Learning. 
The idea of hierarchical learning in Deep Learning coming from the 
primary sensorial areas of the neocortex in the human brain&nbsp;[<span class="CitationRef"><a href="#CR13" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">13</a></span>].</p><p id="Par8" class="Para">Convolutional neural network (CNN)&nbsp;[<span class="CitationRef"><a href="#CR14" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">14</a></span>]
 is an example of a various number of Deep Learning models. This model 
which is popularly used for image analysis can make use of the internal 
structure of data through convolution layers. Because of the internal 
structure that exists inside the text documents CNN has been gaining 
attention on text data as well. CNN is used in systems for tagging, 
entity search, sentence modeling, etc.&nbsp;[<span class="CitationRef"><a href="#CR15" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">15</a></span>, <span class="CitationRef"><a href="#CR16" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">16</a></span>, <span class="CitationRef"><a href="#CR17" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">17</a></span>, <span class="CitationRef"><a href="#CR18" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">18</a></span>, <span class="CitationRef"><a href="#CR19" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">19</a></span>, <span class="CitationRef"><a href="#CR20" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">20</a></span>, <span class="CitationRef"><a href="#CR21" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">21</a></span>, <span class="CitationRef"><a href="#CR22" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">22</a></span>, <span class="CitationRef"><a href="#CR23" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">23</a></span>].</p><p id="Par9" class="Para">Deep
 Learning algorithms which usually learn data representations in a 
greedy fashion, look more useful to learn from Big Data&nbsp;[<span class="CitationRef"><a href="#CR24" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">24</a></span>, <span class="CitationRef"><a href="#CR25" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">25</a></span>].
 Deep Learning can be used to extract nonlinear complicated features in 
Big Data analytics, then extracted features are used as input to a 
linear model.</p><p id="Par10" class="Para">Deep Learning can be used to make discriminative tasks of Big Data analytics easier. For instance Li et al.&nbsp;[<span class="CitationRef"><a href="#CR26" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">26</a></span>]
 use Deep Learning to do a search in Big Data. They use Deep Learning to
 enable searching of audio and video file with speech. Deep Learning 
ability to extract high-level, complex abstractions from large volumes 
of unsupervised data (Big Data) make it desirable for Big Data 
analytics. High-level features can be extracted from unlabeled images by
 using Deep Learning. For instance, Google provides a deep neural 
network that can learn high-level features from unlabeled data&nbsp;[<span class="CitationRef"><a href="#CR27" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">27</a></span>, <span class="CitationRef"><a href="#CR28" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">28</a></span>].
 Their work clearly shows how Deep Learning methods can extract 
high-level features from unsupervised data and demonstrates the 
advantages of using Deep Learning with unsupervised data (Big Data).</p><p id="Par11" class="Para">The remainder of this paper is organized as follows: <span class="InternalRef"><a href="#Sec2">Related work</a></span> section we look at previous work on financial sentiment analysis and the methods employed therein; <span class="InternalRef"><a href="#Sec5">Big Data</a></span>
 section contains an overview of Big Data analytics. In this section, we
 discuss some Big Data characteristics and specify main problems that 
faced Big Data in data analysis; <span class="InternalRef"><a href="#Sec6">Sentiment analysis</a></span> section we briefly talk about sentiment analysis methods and advantages of using Deep Learning in sentiment analysis; in <span class="InternalRef"><a href="#Sec7">Sentiment analysis with data mining approaches</a></span>
 section we explore other works that use data mining to do sentiment 
analysis on StockTwits dataset. After that, we discuss some feature 
selection methods. In <span class="InternalRef"><a href="#Sec12">Deep Learning in Big Data analytics</a></span>
 section we explore how Deep Learning can be used for Big Data analysis 
also we discuss some challenges that Deep Learning needs to overcome to 
do analysis in the Big Data domain; <span class="InternalRef"><a href="#Sec17">Results and discussion</a></span>
 section explains our experiments, and goes into depth about how we can 
apply Deep Learning to financial sentiment analysis. Our primary 
findings and conclusions are presented in <span class="InternalRef"><a href="#Sec21">Conclusions</a></span> section.</p></div></section><section id="Sec2" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="0">Related work<span class="section-icon"></span></h2><div class="content"><p id="Par12" class="Para">Specific Big Data domains including computer vision&nbsp;[<span class="CitationRef"><a href="#CR29" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">29</a></span>] and speech recognition&nbsp;[<span class="CitationRef"><a href="#CR30" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">30</a></span>],
 have seen the advantages of using Deep Learning to improve 
classification modeling results but, there are a few works on Deep 
Learning architecture for sentiment analysis. In 2006 Alexandrescu et 
al.&nbsp;[<span class="CitationRef"><a href="#CR31" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">31</a></span>]
 present a model where each word is represented as a vector of features.
 A single embedding matrix is used to look up all of these features. 
Luong et al.&nbsp;[<span class="CitationRef"><a href="#CR32" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">32</a></span>]
 use a recursive neural network (RNN) to model the morphological 
structures of words and learn morphologically-aware embeddings. In 2013 
Lazaridou et al. &nbsp;[<span class="CitationRef"><a href="#CR33" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">33</a></span>]
 try to learn meanings of a phrase by using compositional distributional
 semantic models. In 2013 Chrupala use a simple recurrent network (SRN) 
to learn continuous vector representations for sequences of characters. 
They use their model to solve a character level text segmentation and 
labeling task. A meaningful search space via Deep Learning can be 
constructed by using Recurrent Neural Network&nbsp;[<span class="CitationRef"><a href="#CR34" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">34</a></span>] Socher et al. in 2011&nbsp;[<span class="CitationRef"><a href="#CR35" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">35</a></span>], use recursive autoencoders&nbsp;[<span class="CitationRef"><a href="#CR36" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">36</a></span>, <span class="CitationRef"><a href="#CR37" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">37</a></span>, <span class="CitationRef"><a href="#CR38" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">38</a></span>, <span class="CitationRef"><a href="#CR39" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">39</a></span>] for predicting sentiment distribution and proposed a semi-supervised approach model. In 2012 Socher et al.&nbsp;[<span class="CitationRef"><a href="#CR40" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">40</a></span>]
 propose a model for semantic compositionality with the ability to learn
 compositional vector representation for sentences of arbitrary length. 
Their proposed model is a matrix-vector recursive neural network model. 
Recursive Neural Tensor Network (RNTN) architecture proposed in&nbsp;[<span class="CitationRef"><a href="#CR41" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">41</a></span>].
 RNTN use word vector and a parse tree to represent a phrase and then 
use a tensor-based composition function to compute vectors for higher 
nodes &nbsp;[<span class="CitationRef"><a href="#CR42" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">42</a></span>]</p><p id="Par13" class="Para">Regarding convolutional network for NLP tasks, Collobert et al.&nbsp;[<span class="CitationRef"><a href="#CR15" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">15</a></span>]
 for semantic role labeling task avoid excessive feature engineering by 
using the convolutional neural network. In 2011 Collobert used a similar
 network architecture for syntactic parsing. In&nbsp;[<span class="CitationRef"><a href="#CR43" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">43</a></span>]
 a deep convolutional neural network is proposed that exploits the 
character-to sentence-level information to perform sentiment analysis of
 short texts.</p><p id="Par14" class="Para">The experiments in this paper focus on market sentiment. Based on the definition in&nbsp;[<span class="CitationRef"><a href="#CR44" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">44</a></span>],
 market sentiment is the general prevailing attitude of investors as to 
anticipate price development in a market. This attitude is the 
combination of various factors such as world events, history, economic 
reports, seasonal factors, and many others. Market sentiment is found 
through sentiment analysis, also known as opinion mining&nbsp;[<span class="CitationRef"><a href="#CR45" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">45</a></span>], which is the use of natural language processing methods to extract the attitude of a writer from source materials.</p><p id="Par15" class="Para">Wang and Sambasivan in&nbsp;[<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>]
 apply market sentiment on the StockTwits dataset by using supervised 
sentiment analysis classified messages in StockTwits as Bullish or 
Bearish. An investor is considered Bullish if he or she believes that 
the stock price will increase over time and recommends purchasing 
shares. Oppositely, if an investor is Bearish he or she expects downward
 price movement and will recommend selling shares or against buying.</p><p id="Par16" class="Para">One of the most popular works in this field is by Loughran and McDonald&nbsp;[<span class="CitationRef"><a href="#CR46" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">46</a></span>].
 They used the US Security and Exchange Commission portal from 1994 to 
2008 to make a financial lexicon and manually create six-word lists 
including <em class="EmphasisTypeItalic ">positive</em>, <em class="EmphasisTypeItalic ">negative</em>, <em class="EmphasisTypeItalic ">litigious</em>, <em class="EmphasisTypeItalic ">uncertainty</em>, <em class="EmphasisTypeItalic ">model strong</em> and <em class="EmphasisTypeItalic ">model weak</em>. Mao et al. &nbsp;[<span class="CitationRef"><a href="#CR47" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">47</a></span>]
 propose an automatic Chinese financial lexicon constructor. His 
proposed procedure explores many corpora classified as positive or 
negative and attempts to construct a Chinese financial lexicon 
automatically.</p><p id="Par17" class="Para">Supervised classification methods, such as Support Vector Machines&nbsp;[<span class="CitationRef"><a href="#CR48" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">48</a></span>], Nave Bayes&nbsp;[<span class="CitationRef"><a href="#CR49" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">49</a></span>] or ensembles&nbsp;[<span class="CitationRef"><a href="#CR50" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">50</a></span>, <span class="CitationRef"><a href="#CR51" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">51</a></span>]
 have been deployed to perform sentiment analysis in multiple research 
projects. Machine learning techniques mainly use the bag-of-words&nbsp;[<span class="CitationRef"><a href="#CR52" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">52</a></span>]
 model. In the bag-of-words model, a text is represented as the 
collection of its words, disregarding the order of those words in their 
sentences. However, the order of the words in a sentence can change the 
sentiment of a word. For example, consider the word underestimate. 
This word potentially has a negative connotation, but if we consider it 
beside other words like underestimated stock it can become positive.</p><p id="Par18" class="Para">Recently,
 Deep Learning approaches have emerged as a powerful tool in sentiment 
analysis in Big Data due to the advantages they provide over other 
methods. One of these advantages is that features are learned 
hierarchically during the process of Deep Learning instead of the 
feature engineering that is required in data mining. Additionally, in 
Deep Learning methods, each word is considered as part of a sentence. In
 this way, relevant information contained in word order, proximity, and 
relationships is not lost. Furthermore, Deep Learning benefits from a 
similarity model. Word embedding creates a vector representation of 
words with a much lower dimensional space compared to the bag of the 
words model&nbsp;[<span class="CitationRef"><a href="#CR53" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">53</a></span>, <span class="CitationRef"><a href="#CR54" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">54</a></span>].
 The vectors representing similar words in vector space are therefore 
closer together. One of the other main concepts in Deep Learning 
algorithm is the automatic extraction of representation 
(abstractions)&nbsp;[<span class="CitationRef"><a href="#CR55" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">55</a></span>].
 To achieve this goal Deep Learning uses a massive amount of 
unsupervised data (Big Data) and extracts complex representation 
automatically. One of the advantages of abstract representation 
extracted with Deep Learning algorithms is their generalization. 
Features extracted from a given dataset can be used successfully for a 
discriminative task on another dataset. Deep Learning is an important 
aspect of artificial intelligence because it provides a complex 
representation of Big Data and also makes the machine independent of 
human knowledge.</p><p id="Par19" class="Para">Deep Learning constructs 
complicated representations for image and video data with a high level 
of abstraction. High-level data representations provided by Deep 
Learning can be used for simpler linear models for Big Data. This 
representation can be useful for image indexing and retrieval. In other 
words, Deep Learning can be used in the discriminative task of semantic 
tagging in the context of Big Data analysis.</p></div></section><section id="Sec3" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="0">Methodology<span class="section-icon"></span></h2><div class="content"><section id="Sec4" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Dataset</h3><p id="Par20" class="Para">We
 were fortunate to receive permission from StockTwits Inc. to have 
access to their datasets. StockTwits is a financial social network which
 was established in 2009. Information about the stock market, like the 
latest stock prices, price movement, stock exchange history, buying or 
selling recommendations, and so on, are available to StockTwits users. 
In addition, as a social network, it provides the opportunity for 
sharing experience among traders in the stock market. Through the 
StockTwits website, investors, analysts, and others interested in the 
market can contribute a short message limited to 140 characters about 
the stock market. This message will be posted to a public stream visible
 to all site visitors. Moreover, messages can be labeled Bullish or 
Bearish by the authors to specify their sentiment about various stocks.</p><p id="Par21" class="Para">In
 our experiment, we used messages which were posted in the first six 
months of 2015. Each message includes a messageID, a userID, the 
authors number of followers, a timestamp, the current price of the 
stock, and other record-keeping attributes. We examined the posts to see
 if there is any relation between the future stock price and users 
sentiment. In other words, we want to see if we can predict a future 
stock price based on the current sentiment of many users.</p><p id="Par22" class="Para">We can use Pearson Correlation Coefficient&nbsp;[<span class="CitationRef"><a href="#CR6" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">6</a></span>]
 to see if there is a linear relation between a stocks future price and
 the users sentiment. Pearson Correlation is one of the most 
widely-used functions to measure the linear correlation between two 
variables. It returns one if there is a perfect positive correlation 
between the two input variables, <span class="InlineEquation" id="IEq1">\(-\,1\)</span>
 if there is a perfect negative correlation, and 0 if there is no 
correlation. The Pearson Correlation Coefficient between a stock price 
and a general users sentiment is equal to 0.05, which means that only 
53% of the time are users able to predict future stock prices correctly.
 This is a little bit better than a random guess, so we will examine 
whether that accuracy improves if the number of predictions is 
increased.</p><p id="Par23" class="Para">Wang in&nbsp;[<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>]
 tried to find if there are authors in financial social media whose 
contributions provide good predictors of stock price, but buried in the 
noise. They ranked authors based on their performance in predicting 
stock price within the week of their prediction. They use two 
consecutive years of data, the first year as a benchmark to find such 
top authors, and the second year to examine the top authors performance.
 Based on the results published in&nbsp;[<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>],
 the correlation score for top authors is around 0.4, which means that 
top authors can predict stock price movement with the accuracy of about 
75%.</p><p id="Par24" class="Para">Knowing the sentiment of top authors,
 we can predict stock prices with accuracy of 75% but unfortunately, 
only 10% of messages in StockTwits are labeled. To increase the accuracy
 of stock price prediction, we need a powerful method for the sentiment 
analysis of top authors. Deep Learning is beneficial in facing a large 
amount of unsupervised data (Big Data) like data provided in social 
media. In our paper, we adopt Deep Learning to do sentiment analysis of 
top authors. We believe that using Deep Learning can vastly improve 
correct classification in sentiment analysis regarding various stock 
picks and thus exceed the current accuracy of stock price prediction.</p></section><section id="Sec5" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Big Data</h3><p id="Par25" class="Para">The
 term Big Data has been in use since the 1990s. In 2012 Gartner update 
his previous definition regarding Big Data and defines it as follows: 
Big Data is high-volume, high-velocity and/or high-variety information 
assets that demand cost-effective, innovative forms of information 
processing that enable enhanced insight, decision-making, and process 
automation. Big Data is referred to the growing digital data that are 
difficult to manage and analyze using traditional software tools and 
technologies. Big Data often has a large number of samples, a large 
number of class labels and very high dimensionality (attributes). The 
target size of the Big Data moving continually in 2012 was ranging 
around a few dozen terabytes to many petabytes of data. There are four 
attributes including volume, variety, velocity, and veracity that define
 Big Data&nbsp;[<span class="CitationRef"><a href="#CR56" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">56</a></span>]
 Obviously, data volume is the primary attribute of Big Data. By 
increasing the volume of the Big Data, the complexity, and the 
underneath relationships of data increased as well. Raw data in a Big 
Data system is unsupervised and diverse although it can consist a small 
quantity of supervised data. Many social media companies including 
Facebook, Twitter, StockTwits, LinkedIn have a large amount of data. As 
data become bigger Deep Learning approach become more important to 
provide Big Data analysis.</p><p id="Par26" class="Para">The other thing
 that makes Big Data really big is the variety of data. Big Data coming 
from a variety of sources than ever before. Web sources including social
 media, clickstreams, and logs are some example of these resources. One 
of the challenges in Big Data processing is working with a Variety of 
different data. In order to extract a structured representation of data,
 Big Data needs to do preprocessing on unstructured data.</p><p id="Par27" class="Para">Velocity
 is another feature of Big Data. The frequency of data generation in Big
 Data is fast. For example, consider the stream of message coming from 
StockTwits website. Velocity is just as important as the volume and 
variety characteristics of Big Data. The quickness of processing input 
into usable information is important to deal with velocity associated 
with Big Data.</p><p id="Par28" class="Para">Veracity refers to the 
trustworthiness of the data in Big Data. By increasing the number of 
data sources and types trust in Big Data become a practical challenge. 
In addition to the four vs. there are lots of challenges including data 
cleansing, feature engineering&nbsp;[<span class="CitationRef"><a href="#CR57" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">57</a></span>, <span class="CitationRef"><a href="#CR58" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">58</a></span>, <span class="CitationRef"><a href="#CR59" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">59</a></span>],
 high-dimensionality, and data redundancy that Big Data analytics face. 
Deep Learning is used in industrial products that have the opportunity 
to have a large volume of digital data (Big Data). Google uses Deep 
Learning algorithms and Big Data available on the Internet for Googles 
translator. In some Big Data application domains such as social media, 
marketing, and financial data feeds using Deep Learning algorithms and 
architecture for analyzing large-scale&nbsp;[<span class="CitationRef"><a href="#CR60" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">60</a></span>, <span class="CitationRef"><a href="#CR61" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">61</a></span>], fast-moving streaming data is encouraged, but still analyzing Big Data by using Deep Learning application remain unexplored.</p><p id="Par29" class="Para">In
 Big Data environments, it is critical to analyze, decide and act 
quickly and often. Big Data has the potential to make a huge change in 
science and all aspects of our society, but extracting information from 
Big Data is not an easy task. Decentralized control and autonomous data 
sources are two other important characteristics of Big Data. Each data 
source can collect information without any centralized control&nbsp;[<span class="CitationRef"><a href="#CR62" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">62</a></span>].
 Big Data technology is still young, there are many technical problems 
in stream computing, parallel computing, Big Data architecture, Big Data
 model, and software systems that can support Big Data, etc should be 
investigated.</p><p id="Par30" class="Para">Today, machine learning 
techniques especially Deep Learning models, together with powerful 
computers play an important role in Big Data analysis. Deep Learning 
methods can leverage the predictive power of Big Data in fields like 
search engines, medicine, and astronomy. In contrast to conventional 
datasets used for data ming approach which was noise free, Big Data is 
often incomplete because of their disparate origins. Big Data brings 
transformative potential and big opportunities for various fields. 
Typical data mining algorithms require having all data in main memory 
this is a clear technical difficulty for Big Data which is spread across
 different locations. In addition, data mining methods need to overcome 
sparsity, heterogeneity, uncertainty, and incompleteness of Big Data as 
well. Deep Learning and Big Data are considered as the big deals and the
 bases for an American innovation and economic revolution. Even in 
government and society Big Data emerge as a useful remedy to solve some 
problems. In 2012 the Obama Administration announced a Big Data 
research and development initiative to help solve some of the Nations 
most pressing challenges.</p></section><section id="Sec6" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Sentiment analysis</h3><div id="Par31" class="Para">Following the early work in sentiment analysis done in&nbsp;[<span class="CitationRef"><a href="#CR63" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">63</a></span>, <span class="CitationRef"><a href="#CR64" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">64</a></span>],
 we examine source materials and apply natural language processing 
techniques to determine the attitude of the writer towards a subject. 
Generally speaking, sentiment analysis is a form of classifying text 
documents to numerous groups. Most of the time, we need only to classify
 documents into positive and negative classes&nbsp;[<span class="CitationRef"><a href="#CR65" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">65</a></span>].
 Furthermore, there are different methods in sentiment analysis that can
 help us to measure sentiments. These methods include lexical-based 
approaches methods and supervised machine learning methods. Machine 
learning models are more popular because lexical-based approaches, which
 are based on the semantics of words, use a predefined list of positive 
and negative words to extract the sentiment of new documents. Creating 
these predefined lists is time-consuming and we cannot build a unique 
lexical-based dictionary to be used in every separate context. With the 
growing popularity of social media, huge datasets (Big Data) of reviews,
 blogs, and social network feeds are being generated continuously. Big 
Data techniques are used in application domains that we collect and 
maintain a massive amount of data. Growing data, intensive technologies,
 and increasing data storage resources develop Big Data science. The 
main concept in Big Data analytics is extracting a meaningful pattern 
from a huge amount of data. Big Data need special methods that can be 
used to extract patterns from a massive amount of data. Deep Learning 
has this opportunity to provide a solution to address the learning and 
data analysis problem that exists in a massive amount of data (Big Data)
 and also they are better at learning complex data patterns. There are 
other Big Data problems such as domain adoption and streaming data that 
large-scale Deep Learning models for Big Data analytics have to contend 
with them. Concepts and methods from sentiment analysis that can help us
 to extract information from these areas have become increasingly 
important as businesses, organizations, and individuals seek to make 
better use of their Big Data. In the following section, we start our 
investigation the performance of sentiment analysis based on data mining
 approaches for our dataset.<div id="Tab1" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 1</span> <p class="SimplePara">Performance of the logistic regression on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">0.7088</p> </td><td> <p class="SimplePara">0.7134</p> </td><td> <p class="SimplePara">0.6980</p> </td><td> <p class="SimplePara">0.7056</p> </td><td> <p class="SimplePara">0.7088</p> </td></tr></tbody></table></div></div></div></section><section id="Sec7" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Sentiment analysis with data mining approaches</h3><p id="Par32" class="Para">Wang in&nbsp;[<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>]
 uses a supervised data mining approach to find the sentiment of 
messages in the StockTwits dataset. They removed all stopwords, stock 
symbols, and company names from the messages. They consider ground-truth
 messages as training data and test multiple data mining models, 
including Nave Bayes, Support Vector Machines (SVM), and Decision 
Trees. By running tenfold cross validation, they found that the SVM 
model produces the highest accuracy (76.2%). They used unigrams as 
features and removed infrequent unigrams that occur less than 300 times 
over all messages because using n-grams can lead to data sparsity 
problem. As a result, it is necessary to use lower-order n-grams to 
address sparsity problem otherwise performance would be decreased. On 
the other hand, by using lower-order n-grams we lose the order of the 
words in a sentence. As we know the order of the words in a sentence can
 help us to better understanding the sentiment of a document. We believe
 that using Deep Learning to predict sentiment of authors can help us to
 overcome these problems and increase the accuracy of prediction. Deep 
Learning nonlinear feature extraction can improve data mining results 
and classification modeling&nbsp;[<span class="CitationRef"><a href="#CR55" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">55</a></span>].
 Logistic regression uses the logistic sigmoid function to weighted 
input values to classify input data, it is similar to a Deep Learning 
without hidden layers. Logistic regression is used as a classifier in 
the final layer of a Deep Learning. In other words, Deep Learning 
algorithms work as multiple feature learning steps. Logistic regression 
is very fast and simple so it is used for large datasets.</p><div id="Par33" class="Para">We follow Wang&nbsp;[<span class="CitationRef"><a href="#CR2" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">2</a></span>] approach and apply logistic regression&nbsp;[<span class="CitationRef"><a href="#CR3" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">3</a></span>] on the StockTwits dataset. In Table <span class="InternalRef"><a href="#Tab1">1</a></span>,
 we provide the performance of logistic regression on StockTwits data 
based on different performance metrics. Also in Fig.&nbsp;<span class="InternalRef"><a href="#Fig1">1</a></span>, we present the ROC curve&nbsp;[<span class="CitationRef"><a href="#CR66" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">66</a></span>] for this model.<figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig1_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig1_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1</span> <p class="SimplePara">Receiver operating characteristic for logistic regression</p> </div></figcaption></figure></div></section><section id="Sec8" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Increase accuracy by using feature selection</h3><p id="Par34" class="Para">One
 of the problems that prevent us from accurately classifying a Big Data 
is the noise found within it. Feature selection, including the removal 
of noisy features and elimination of ineffective vocabulary, makes 
training and applying a classier more effective&nbsp;[<span class="CitationRef"><a href="#CR67" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">67</a></span>].
 The existing approaches to finding an adequate subset of features fall 
into two groups: feature filters and feature wrappers&nbsp;[<span class="CitationRef"><a href="#CR68" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">68</a></span>].
 In feature filters, the final set of features is selected based on the 
statistical properties of those features. With feature wrappers, an 
iterative search process is applied through a modeling tools results. 
In each iteration, a candidate set of features is used in the modeling 
tool and the results are recorded. Each step uses the results from the 
previous step, and so new tentative sets are generated. This process is 
repeated until some specified convergence criteria are met. In our 
experiment, we had a huge number of features and instances, and thus, 
our data was very sparse. We tried several feature selection methods to 
see how they would affect the accuracy of our sentiment analysis.</p><p id="Par35" class="Para">From
 the methods tested, we selected three feature filters which included 
Chi-squared, ANOVA, and mutual information. The advantages of using 
these feature selection techniques are their speed, scalability and 
their independence of the classification. Our reasoning for choosing 
these methods is their ability to deal with sparse data. On the other 
hand, these methods have some drawbacks as well, they ignore feature 
dependencies and also they ignore interaction with the classifier&nbsp;[<span class="CitationRef"><a href="#CR69" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">69</a></span>]. In this section, we examine these methods and the results of applying them to our dataset.</p><section id="Sec9" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Chi-square</h4><div id="Par36" class="Para">Pearsons Chi-squared&nbsp;[<span class="CitationRef"><a href="#CR70" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">70</a></span>]
 test is used for two types of comparison: a test of independence or a 
test of goodness of fit. We apply the test of independence to our 
dataset to see if the occurrence of a specific feature is independent of
 the class. Our terms are ranked by their score as determined with 
Eq.&nbsp;(<span class="InternalRef"><a href="#Equ1">1</a></span>). In this equation, O stands for observed frequency, and E stands for expected frequency. A high <span class="InlineEquation" id="IEq2">\(X^2\)</span> score rejects the null hypothesis of independence of the term and class.<div id="Equ1" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} X^2 = \sum _{i=1}^n {(O_i - E_i)^2 \over E_i} \end{aligned}$$</div> <div class="EquationNumber">(1)</div></div>Applying
 Chi-squared to our dataset and decreasing the number of features 
gradually allowed us to see how it can affect the performance of 
logistic regression. Classifier results are provided in Table <span class="InternalRef"><a href="#Tab2">2</a></span>.
 Reducing the number of features increases accuracy in some casesfor 
example, by reducing the number of features from 40,000 to 500, accuracy
 increases by seven percent. However, this is an irregularity in our 
dataset and does not mean that Chi-squared is an effective feature 
selection method to increase the accuracy of our classier.<div id="Tab2" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 2</span> <p class="SimplePara">Performance of the Chi-squared feature selection on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Features</p> </th><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">55,820</p> </td><td> <p class="SimplePara">0.7088</p> </td><td> <p class="SimplePara">0.7134</p> </td><td> <p class="SimplePara">0.6980</p> </td><td> <p class="SimplePara">0.7056</p> </td><td> <p class="SimplePara">0.7088</p> </td></tr><tr><td> <p class="SimplePara">40,000</p> </td><td> <p class="SimplePara">0.4796</p> </td><td> <p class="SimplePara">0.4851</p> </td><td> <p class="SimplePara">0.6645</p> </td><td> <p class="SimplePara">0.5608</p> </td><td> <p class="SimplePara">0.4796</p> </td></tr><tr><td> <p class="SimplePara">20,000</p> </td><td> <p class="SimplePara">0.5018</p> </td><td> <p class="SimplePara">0.5013</p> </td><td> <p class="SimplePara">0.6879</p> </td><td> <p class="SimplePara">0.5800</p> </td><td> <p class="SimplePara">0.5018</p> </td></tr><tr><td> <p class="SimplePara">4000</p> </td><td> <p class="SimplePara">0.5274</p> </td><td> <p class="SimplePara">0.5206</p> </td><td> <p class="SimplePara">0.6946</p> </td><td> <p class="SimplePara">0.5951</p> </td><td> <p class="SimplePara">0.5274</p> </td></tr><tr><td> <p class="SimplePara">2000</p> </td><td> <p class="SimplePara">0.5221</p> </td><td> <p class="SimplePara">0.5190</p> </td><td> <p class="SimplePara">0.6036</p> </td><td> <p class="SimplePara">0.5581</p> </td><td> <p class="SimplePara">0.5221</p> </td></tr><tr><td> <p class="SimplePara">400</p> </td><td> <p class="SimplePara">0.5308</p> </td><td> <p class="SimplePara">0.5278</p> </td><td> <p class="SimplePara">0.5834</p> </td><td> <p class="SimplePara">0.5542</p> </td><td> <p class="SimplePara">0.5308</p> </td></tr><tr><td> <p class="SimplePara">200</p> </td><td> <p class="SimplePara">0.5333</p> </td><td> <p class="SimplePara">0.5280</p> </td><td> <p class="SimplePara">0.6284</p> </td><td> <p class="SimplePara">0.5738</p> </td><td> <p class="SimplePara">0.5333</p> </td></tr><tr><td> <p class="SimplePara">50</p> </td><td> <p class="SimplePara">0.5314</p> </td><td> <p class="SimplePara">0.5232</p> </td><td> <p class="SimplePara">0.7071</p> </td><td> <p class="SimplePara">0.6014</p> </td><td> <p class="SimplePara">0.5314</p> </td></tr></tbody></table></div></div></div></section><section id="Sec10" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Analysis of variance</h4><p id="Par37" class="Para">One of the other feature selection methods that we used was the analysis of variance (ANOVA) feature selection. ANOVA&nbsp;[<span class="CitationRef"><a href="#CR71" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">71</a></span>]
 is used to determine if there are any statistically significant 
differences between the arithmetic means of independent groups. By using
 ANOVA for feature selection in our experiment, we clarify the relevance
 of terms by assigning a score to each based on an F-test. Top scoring 
terms are considered as our desired features and sent to the 
classification models.</p><div id="Par38" class="Para">The F-test formula is shown in Eq.&nbsp;(<span class="InternalRef"><a href="#Equ2">2</a></span>).<div id="Equ2" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} F = \frac{MS_B}{MS_w } \end{aligned}$$</div> <div class="EquationNumber">(2)</div></div>In this equation <span class="InlineEquation" id="IEq3">\(MS_B\)</span> is <em class="EmphasisTypeItalic ">between-group variability </em> Eq.&nbsp;(<span class="InternalRef"><a href="#Equ3">3</a></span>), and <span class="InlineEquation" id="IEq4">\(MS_W\)</span> is <em class="EmphasisTypeItalic ">within-group variability </em> Eq.&nbsp;(<span class="InternalRef"><a href="#Equ4">4</a></span>). In between-group variability <span class="InlineEquation" id="IEq5">\(n_i\)</span> is the total number of observations of class <em class="EmphasisTypeItalic ">i</em>, <em class="EmphasisTypeItalic ">m</em> is the number of classes and <span class="InlineEquation" id="IEq6">\(\bar{x}\)</span> denotes the general mean of the data.<div id="Equ3" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} MS_B = \frac{ \sum _{i} n_{i} (\bar{x_i } - \bar{x})^2 }{ m - 1 } \end{aligned}$$</div> <div class="EquationNumber">(3)</div></div>In within-group variability, <span class="InlineEquation" id="IEq7">\(x_{ij}\)</span> denotes the jth observation in the ith class&nbsp;[<span class="CitationRef"><a href="#CR72" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">72</a></span>].<div id="Equ4" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned} MS_W = \frac{ \sum _{ij}( x_{ij} - \bar{x_i })^2 }{ n - m } \end{aligned}$$</div> <div class="EquationNumber">(4)</div></div>By
 extracting more effective features based on F-test scores, we examined 
whether ANOVA feature selection improves the accuracy of the 
classification methods. Per the results provided in Table <span class="InternalRef"><a href="#Tab3">3</a></span>, accuracy is not improved through ANOVA feature selection, so it will not be used for further testing.<div id="Tab3" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 3</span> <p class="SimplePara">Performance of the ANOVA F-test feature selection on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Features</p> </th><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">55,820</p> </td><td> <p class="SimplePara">0.7088</p> </td><td> <p class="SimplePara">0.7134</p> </td><td> <p class="SimplePara">0.6980</p> </td><td> <p class="SimplePara">0.7056</p> </td><td> <p class="SimplePara">0.7088</p> </td></tr><tr><td> <p class="SimplePara">40,000</p> </td><td> <p class="SimplePara">0.7094</p> </td><td> <p class="SimplePara">0.7130</p> </td><td> <p class="SimplePara">0.7010</p> </td><td> <p class="SimplePara">0.7070</p> </td><td> <p class="SimplePara">0.7094</p> </td></tr><tr><td> <p class="SimplePara">20,000</p> </td><td> <p class="SimplePara">0.7091</p> </td><td> <p class="SimplePara">0.7127</p> </td><td> <p class="SimplePara">0.7007</p> </td><td> <p class="SimplePara">0.7066</p> </td><td> <p class="SimplePara">0.7091</p> </td></tr><tr><td> <p class="SimplePara">4000</p> </td><td> <p class="SimplePara">0.5274</p> </td><td> <p class="SimplePara">0.5206</p> </td><td> <p class="SimplePara">0.6946</p> </td><td> <p class="SimplePara">0.5951</p> </td><td> <p class="SimplePara">0.5274</p> </td></tr><tr><td> <p class="SimplePara">2000</p> </td><td> <p class="SimplePara">0.7045</p> </td><td> <p class="SimplePara">0.7048</p> </td><td> <p class="SimplePara">0.7038</p> </td><td> <p class="SimplePara">0.7043</p> </td><td> <p class="SimplePara">0.7045</p> </td></tr><tr><td> <p class="SimplePara">400</p> </td><td> <p class="SimplePara">0.6785</p> </td><td> <p class="SimplePara">0.6638</p> </td><td> <p class="SimplePara">0.7233</p> </td><td> <p class="SimplePara">0.6923</p> </td><td> <p class="SimplePara">0.6785</p> </td></tr><tr><td> <p class="SimplePara">200</p> </td><td> <p class="SimplePara">0.6611</p> </td><td> <p class="SimplePara">0.6378</p> </td><td> <p class="SimplePara">0.7457</p> </td><td> <p class="SimplePara">0.6875</p> </td><td> <p class="SimplePara">0.6611</p> </td></tr><tr><td> <p class="SimplePara">50</p> </td><td> <p class="SimplePara">0.0.6191</p> </td><td> <p class="SimplePara">0.5863</p> </td><td> <p class="SimplePara">0.8084</p> </td><td> <p class="SimplePara">0.6797</p> </td><td> <p class="SimplePara">0.6191</p> </td></tr></tbody></table></div></div></div></section><section id="Sec11" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Information gain</h4><div id="Par39" class="Para">Our
 results show that ANOVA and Chi-square feature selection methods cannot
 considerably increase the accuracy of our classification models. In 
this section, we look at mutual information feature selection, which is 
one of the most commonly used feature selection methods. Mutual 
information is defined as the number of dependencies between two random 
variables. This allows us to determine information gain, which is the 
amount of information acquired about one random variable through another
 random variable. Mutual information between two random variables (X and
 Y) in defined in Eq.&nbsp;(<span class="InternalRef"><a href="#Equ5">5</a></span>).<div id="Equ5" class="Equation EquationMathjax"><div class="EquationContent">$$\begin{aligned}
 I (X ; Y) = \sum _{y\in {Y}} \sum _{x\in {X}} p(x,y) log(\frac{ p( x , y
 ) }{ p ( x ) p ( y ) } ) \end{aligned}$$</div> <div class="EquationNumber">(5)</div></div>In this equation, if x and y are independent, i.e. <span class="InlineEquation" id="IEq8">\(( p(x,y) = p(x) \times p(y) )\)</span>,
 their mutual information will be zero. Which, in turn, means that by 
knowing one of these random variables we cannot gain any information 
about the other one.</div><div id="Par40" class="Para">By using mutual 
information for feature selection, we explore how much information each 
term provides to making the correct classification decision. This method
 extracts features with the highest mutual information value. In this 
way, we will have features that contain the most information about the 
class. In our experiment, mutual information for feature selection was 
also not effective. This is shown by the results provided in Table <span class="InternalRef"><a href="#Tab4">4</a></span>.<div id="Tab4" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 4</span> <p class="SimplePara">Performance of the mutual information feature selection on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Features</p> </th><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">55,820</p> </td><td> <p class="SimplePara">0.7088</p> </td><td> <p class="SimplePara">0.7134</p> </td><td> <p class="SimplePara">0.6980</p> </td><td> <p class="SimplePara">0.7056</p> </td><td> <p class="SimplePara">0.7088</p> </td></tr><tr><td> <p class="SimplePara">40,000</p> </td><td> <p class="SimplePara">0.5417</p> </td><td> <p class="SimplePara">0.5311</p> </td><td> <p class="SimplePara">0.7115</p> </td><td> <p class="SimplePara">0.6082</p> </td><td> <p class="SimplePara">0.5417</p> </td></tr><tr><td> <p class="SimplePara">20,000</p> </td><td> <p class="SimplePara">0.5123</p> </td><td> <p class="SimplePara">0.5087</p> </td><td> <p class="SimplePara">0.7144</p> </td><td> <p class="SimplePara">0.5943</p> </td><td> <p class="SimplePara">0.5123</p> </td></tr><tr><td> <p class="SimplePara">4000</p> </td><td> <p class="SimplePara">0.5391</p> </td><td> <p class="SimplePara">0.5337</p> </td><td> <p class="SimplePara">0.6190</p> </td><td> <p class="SimplePara">0.5732</p> </td><td> <p class="SimplePara">0.5391</p> </td></tr><tr><td> <p class="SimplePara">2000</p> </td><td> <p class="SimplePara">0.5406</p> </td><td> <p class="SimplePara">0.5350</p> </td><td> <p class="SimplePara">0.6193</p> </td><td> <p class="SimplePara">0.5741</p> </td><td> <p class="SimplePara">0.5406</p> </td></tr><tr><td> <p class="SimplePara">400</p> </td><td> <p class="SimplePara">0.5665</p> </td><td> <p class="SimplePara">0.5540</p> </td><td> <p class="SimplePara">0.6815</p> </td><td> <p class="SimplePara">0.6112</p> </td><td> <p class="SimplePara">0.5665</p> </td></tr><tr><td> <p class="SimplePara">200</p> </td><td> <p class="SimplePara">0.4713</p> </td><td> <p class="SimplePara">0.4760</p> </td><td> <p class="SimplePara">0.5692</p> </td><td> <p class="SimplePara">0.6126</p> </td><td> <p class="SimplePara">0.5459</p> </td></tr><tr><td> <p class="SimplePara">50</p> </td><td> <p class="SimplePara">0.5077</p> </td><td> <p class="SimplePara">0.5052</p> </td><td> <p class="SimplePara">0.7414</p> </td><td> <p class="SimplePara">0.6009</p> </td><td> <p class="SimplePara">0.5077</p> </td></tr></tbody></table></div></div></div><p id="Par41" class="Para">In Fig.&nbsp;<span class="InternalRef"><a href="#Fig2">2</a></span>
 we decrease the number of features by applying selection methods 
containing Chi-square, ANOVA, and information gain and compare the 
accuracy of logistic regression. As our results demonstrate, feature 
selection methods cannot considerably improve the accuracy of logistic 
regression. Data mining algorithms cannot extract the complex and 
nonlinear patterns that exist in Big Data. Extracting these features, 
Deep Learning can use simpler linear models for Big Data analysis tasks 
including classification and prediction which is important when we deal 
with the scale of Big Data.</p><div id="Par42" class="Para">With the 
result of logistic regression based on the bag-of-words model used as a 
baseline, we investigate whether Deep Learning methods can improve the 
accuracy of this logistic regression in Big Data. The bag-of-words model
 does not consider word order and other words in a sentence, and it has a
 limited sense of word sentiment. We believe that using Deep Learning 
methods instead of the bag-of-words may help us to improve the accuracy 
of our model. In consecutive layers of deep architectures in Deep 
Learning, each layer applies a nonlinear transformation on its input and
 provides a representation of its output. On the other word, Deep 
Learning can learn representations of the Big Data in a Deep 
Architecture with multiple levels of representations. It is important to
 consider that transformations in the layers of Deep Learning are 
nonlinear and try to extract underlying factors in the Big Data. The 
output of final layer (the final representation of data which 
constructed by Deep Learning algorithm) can be used as features for 
classifiers or other applications. In our paper, we mainly focus to see 
how Deep Learning can assist with sentiment analysis in StockTwits data 
and which Deep Learning algorithm can be adapted to improve the accuracy
 of sentiment analysis in StockTwits in compare to data mining models. 
With respect to the first topic, we explore three Deep Learning 
algorithms including doc2vec&nbsp;[<span class="CitationRef"><a href="#CR73" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">73</a></span>, <span class="CitationRef"><a href="#CR74" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">74</a></span>, <span class="CitationRef"><a href="#CR75" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">75</a></span>], LSTM&nbsp;[<span class="CitationRef"><a href="#CR76" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">76</a></span>] and CNN&nbsp;[<span class="CitationRef"><a href="#CR77" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">77</a></span>] to see if they can more accurately predict StockTwits users sentiment.<figure class="Figure" id="Fig2"><div class="MediaObject" id="MO7"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig2_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig2_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 2</span> <p class="SimplePara">Accuracy of logistic regression by using feature selection methods</p> </div></figcaption></figure></div></section></section><section id="Sec12" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Deep Learning in Big Data analytics</h3><p id="Par43" class="Para">In
 this section, we explore advantages of using Deep Learning algorithms 
in Big Data analysis. Also, we take a look at some Big Data 
characteristics that challenges Deep Learning in Big Data analysis.</p><p id="Par44" class="Para">Big
 Data analytics, provide the opportunity to develop novel algorithms to 
address some issues related to Big Data. Deep Learning algorithms are 
one of these solutions. For instance, the representations extracted by 
Deep Learning can be used in Big Data analytics approach. In addition, 
when Big Data is represented in a higher form of abstraction, linear 
modeling can be considered for Big Data analytics. There are various 
works that have been performed by using Deep Learning algorithms.</p><p class="Para">Deep
 Learning dates back to the 1940s. Its only appears to be new, because 
Deep Learning was relatively unpopular for several years preceding its 
current popularity, and because Deep Learning has gone through many 
different names, only recently being called deep learning. Deep 
Learning has been rebranded many times, reflecting the influence of 
different researchers and different perspectives. Some basic context of 
the history of Deep Learning is useful for understanding Deep Learning. 
Deep Learning is known as cybernetics in the 1940s1960s, Deep Learning 
known as connectionism in the 1980s1990s, and the current resurgence 
under the name Deep Learning beginning in 2006 [<span class="CitationRef"><a href="#CR78" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">78</a></span>].</p><p id="Par45" class="Para">As
 we mentioned before, Deep Learning algorithms extract an abstract 
representation of Big Data through multi-level hierarchical learning. 
Deep Learning is attractive for extracting information from Big Data 
because it can be used to learn from a massive amount of unlabeled data.
 Once Deep Learning learned unsupervised data (Big Data) more 
traditional models can be trained with less amount of labeled 
data&nbsp;[<span class="CitationRef"><a href="#CR79" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">79</a></span>, <span class="CitationRef"><a href="#CR80" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">80</a></span>, <span class="CitationRef"><a href="#CR81" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">81</a></span>]. Global relationships in the Big Data can perform better by using Deep Learning.</p><p id="Par46" class="Para">Some
 of the advantages of learned abstract representations by Deep Learning 
include, a simple model can work effectively with the knowledge of more 
abstract data representation, automation of data representation 
extraction can lead to a broad application to different data types. 
These specific characteristics of Deep Learning make it desirable for 
Big Data analytics.</p><p id="Par47" class="Para">Deep Learning 
algorithms can be used to address the problem of volume and variety of 
Big Data analytics. Effectively using a massive amount of data (volume 
in Big Data) is one of the advantages of Deep Learning. Since Deep 
Learning deals with data abstraction it is desirable to work with raw 
data in different formats and resources (variety in Big Data) and 
minimize a need for feature selection from new data type observed in Big
 Data.</p><p id="Par48" class="Para">However Big Data has some 
characteristics including streaming and fast moving which can lead to 
some challenges for adopting Deep Learning for Big Data. Deep Learning 
needs to be adapted to lead with a lot of continuous Big Data. There are
 some works associated with Deep Learning and streaming Big Data. For 
instance, adoptive deep belief networks introduced in&nbsp;[<span class="CitationRef"><a href="#CR82" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">82</a></span>] illustrate how Deep Learning can be used to learn from streaming data. Zhou et al.&nbsp;[<span class="CitationRef"><a href="#CR83" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">83</a></span>]
 describe how Deep Learning algorithms can be used for feature learning 
on Big Data. One of the other problem that associate of using Deep 
Learning in Big Data is using Deep Learning for large-scale models and 
massive datasets. In&nbsp;[<span class="CitationRef"><a href="#CR84" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">84</a></span>] Dean uses thousands of CPU cores to train a Deep Learning neural network with billions of parameters. Coates et al.&nbsp;[<span class="CitationRef"><a href="#CR85" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">85</a></span>] suggest using the power of a cluster of GPU servers to overcome the problem of Deep Learning in large-scale datasets.</p><p id="Par49" class="Para">Big
 Data encompasses a lot of things from medicine, genomic and biological 
data to call center. To handle huge volumes of input associated with Big
 Data, large-scale Deep Learning models are desirable. They can 
illustrate the optimal number of model parameters and overcome the 
challenges of Deep Learning for Big Data analysis. There are other Big 
Data problems like domain adaption and streaming data that large-scale 
Deep Learning models for Big Data need to handle.</p><p id="Par50" class="Para">Variety
 is one of the other characteristics of Big Data, which focuses on the 
variation of the input domains and data types in Big Data so the problem
 of domain adoption is another issue that Deep Learning in Big Data 
analysis need to overcome. There are some studies including&nbsp;[<span class="CitationRef"><a href="#CR86" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">86</a></span>, <span class="CitationRef"><a href="#CR87" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">87</a></span>] that mainly focus on domain adoption during the learning process. Glorot et al.&nbsp;[<span class="CitationRef"><a href="#CR86" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">86</a></span>]
 illustrate that Deep Learning can find intermediate data 
representations in a hierarchical learning manner and this 
representation can be used for other domains. Chopra et al. [<span class="CitationRef"><a href="#CR87" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">87</a></span>]
 propose a new Deep Learning model for domain adoption. Their new 
proposed Deep Learning model considers information available from the 
distribution shift between the train and test data. Our paper mainly 
focuses on information retrieval so in the following section, we 
summarize Deep Learning in sentiment analysis.</p></section><section id="Sec13" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Sentiment analysis with Deep Learning approaches</h3><p id="Par51" class="Para">In
 the prior section, we discussed some advantages of using Deep Learning 
in Big Data analysis including the application of Deep Learning 
algorithms for Big Data analysis and how specific characteristics of Big
 Data can lead to some challenges in adopting Deep Learning algorithms 
for Big Data analytics tasks. In this section, we explore sentiment 
analysis using Deep Learning algorithms. In data mining prediction tasks
 feature engineering is the most important and most difficult skill. The
 effort involved in feature engineering is the main reason to seek 
algorithms that can learn features by themselves. Hierarchical feature 
learning in Deep Learning extracts multiple layers of non-linear 
features and then a classifier combines all the features to make 
predictions&nbsp;[<span class="CitationRef"><a href="#CR88" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">88</a></span>].
 Data mining models based on shallow learning like Support Vector 
Machines and Decision Trees are not able to extract complex features. On
 the other hand, Deep Learning algorithms have the capability to 
generalize in global ways, generating learning patterns, and 
relationships beyond immediate neighbors in the Big Data&nbsp;[<span class="CitationRef"><a href="#CR79" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">79</a></span>].
 In order to gain more complex features, Deep Learning algorithms 
transform first features like edge and blobs in image again to extract 
more informative features to distinguish between classes. This process 
is very close to brain activity. The first hierarchy of neurons which 
are sensitive to specific edges and blobs receive information in the 
visual cortex&nbsp;[<span class="CitationRef"><a href="#CR89" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">89</a></span>]
 while brain regions further down the visual pipeline are sensitive to 
more complex structures such as faces. So in other words, Deep Learning 
learns the representation of Big Data in a deep architecture and more 
layers the data goes through, the more complicated the nonlinear 
transformations which are constructed. But hierarchical feature learning
 suffered from major problems such as the vanishing gradient for very 
deep layers, this problem makes these architectures perform poorly in 
comparison to shallow learning algorithms. Deep Learning methods can 
overcome vanishing gradient problem so they can train with dozens of 
layers of non-linear hierarchical features. Not only Deep Learning 
methods are related to learning deep non-linear hierarchical features 
they can also be used to detect very long non-linear time dependencies 
in sequential data. Long short-term memory (LSTM) and Recurrent Neural 
Networks are two examples of neural networks that can increase the 
accuracy of prediction by picking up on activity hundreds of time steps 
in the past. One of the main problems in Big Data is storing data 
effectively and retrieve information from this Big Data. Deep Learning 
algorithms can be used to generate high-level abstract data 
representation which will be used for sentiment analysis (especially for
 raw Big Data input). While a vector representation of Big Data provides
 faster information retrieval, Deep Learning can be used for relational 
understanding of the Big Data. Using Deep Learning algorithms can help 
us to extract semantic features from a massive amount of text data in 
addition to reduce dimensions of the data representations. Hinton et 
al.&nbsp;[<span class="CitationRef"><a href="#CR90" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">90</a></span>, <span class="CitationRef"><a href="#CR91" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">91</a></span>]
 propose a Deep Learning model to learn the binary codes for documents. 
The word count vector of a document is the lowest layer and the learned 
binary code of the documents is the highest layer. The binary code can 
be used for information retrieval in Big Data. we can use some 
unsupervised data in training a Deep Learning model&nbsp;[<span class="CitationRef"><a href="#CR92" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">92</a></span>,&nbsp;<span class="CitationRef"><a href="#CR93" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">93</a></span>]. Ranzato et al.&nbsp;[<span class="CitationRef"><a href="#CR94" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">94</a></span>]
 propose a study in which Deep Learning model learn with supervised and 
unsupervised Big Data. Deep Learning algorithms provide this opportunity
 to extract semantic aspect of a document by capture complex nonlinear 
representations between word occurrences. Using Deep Learning can help 
us leverage unlabeled document (unsupervised Big Data) to have access to
 huge amount of data (Big Data). Unlabeled data are often ambled and 
cheap to collect in Big Data. Since Deep Learning relatively recently 
becomes popular, additional work needs to be done to use hierarchical 
learning strategy as a method for sentiment analysis of Big Data.</p><section id="Sec14" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">word2vec</h4><p id="Par52" class="Para">Mikolov in&nbsp;[<span class="CitationRef"><a href="#CR95" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">95</a></span>],
 proposed word2vec model. In this model, instead of relying on the 
number of occurrences of the words, neural network methods (Deep 
Learning) are used to produce a high-dimensional vector representation 
of each word or document. Word2vec uses the location of words relevant 
to each other in a sentence to find the semantic relationship between 
them. In contrast to the bag-of-words model, word2vec can capture 
sentimental similarity among words.</p><div id="Par53" class="Para">Word2vec is implemented in two different model architectures, <em class="EmphasisTypeItalic ">continuous bag-of-words</em> and <em class="EmphasisTypeItalic ">skip</em>-<em class="EmphasisTypeItalic ">gram</em>.
 In the continuous bag-of-words architecture, we have a sequence of 
words and we need to predict which word is more likely to be the next 
word in this sequence. In the skip-gram architecture, with each word, we
 try to find a more probabilistic surrounding window of words. The 
outcome is in a vector space, words with semantic similarity are nearby.
 When using the word2vec model, the order of the words in a sentence is 
ignored, and only words and their distance from each other are 
considered. Le and Mikolov&nbsp;[<span class="CitationRef"><a href="#CR73" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">73</a></span>],
 describe the doc2vec method. doc2vec generalizes word2vec by adding a 
paragraph vector. This inclusion means that each paragraph, like each 
word, is mapped to a vector. The advantage of considering a paragraph as
 a vector is that it can work as a kind of memory to keep the order of 
the words in a sentence.<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO8"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig3_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig3_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 3</span> <p class="SimplePara">Distributed memory architecture</p> </div></figcaption></figure></div><div id="Par54" class="Para">Doc2vec, like word2vec, is implemented in two different methods <em class="EmphasisTypeItalic ">distributed memory</em> and <em class="EmphasisTypeItalic ">distributed bag-of-words</em>.
 In distributed memory, a paragraph is treated the same as a word. This 
is word2vec beneficial because after paragraph vectors have been learned
 from labeled Big Data they can be used effectively for a task 
especially when labeled data is limited. The distributed bag-of-words 
model ignores the word context as input, but rather predicts words by 
randomly selecting samples from a paragraph. The architectures of 
distributed memory and distributed bag-of-words are provided in 
Figs.&nbsp;<span class="InternalRef"><a href="#Fig3">3</a></span> and <span class="InternalRef"><a href="#Fig4">4</a></span>.<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO9"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig4_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig4_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 4</span> <p class="SimplePara">Distributed bag of words</p> </div></figcaption></figure></div><p id="Par55" class="Para">To
 achieve the goal of higher accuracy, in each iteration of stochastic 
gradient descent, we sample a text window and select some random words 
from this window. At the end of this process, based on the given 
paragraph vector, we will form a classification. The distributed 
bag-of-words model is conceptually simple and does not need to store 
word vectors, so it needs less memory. Deep Learning algorithms are 
powerful to extract useful representation from various kinds of Big Data
 and discriminative results provided by Deep Learning can be used for 
information retrieval&nbsp;[<span class="CitationRef"><a href="#CR96" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">96</a></span>].</p></section><section id="Sec15" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Recurrent Neural Network</h4><p id="Par56" class="Para">The idea behind <em class="EmphasisTypeItalic ">Recurrent Neural Network (RNN)</em>
 is that input data are not independent of each other. Knowing the 
previous iterations data will improve our prediction accuracy. For 
example, consider that we want to predict the next word in a sequence of
 words. Having knowledge of the previous words helps us to improve the 
accuracy of our prediction. Recurrent Neural Networks, by considering 
the previous computation, perform the same task for every element of a 
sequence. In other words, it has memory to capture information about 
what has been calculated so far. But in practice, vanishing gradient is a
 common problem in Deep Learning. Because of the vanishing gradient 
problem, RNNs look back just a few steps. Although vanishing gradients 
are not exclusive to RNNs, they limit our network depth to less than the
 length of the sentence. Thankfully, there are a variety of methods that
 can help us address the vanishing gradient problem. For example, 
instead of using <em class="EmphasisTypeItalic ">tanh</em> or sigmoid as activation functions, we can use ReLU. However, we chose a more popular solution for our work<em class="EmphasisTypeItalic ">Long short-term memory (LSTM)</em>.</p><p id="Par57" class="Para">LSTM was proposed [<span class="CitationRef"><a href="#CR76" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">76</a></span>]
 by Hochreiter and Schmidhuber. The main difference between RNNs and 
LSTMs is the gated cell. Gated cells in LSTMs help the system store more
 information in comparison to RNNs. Information can be stored in, 
written to, or read from a cell. Cells decide whether to remove or store
 information by opening and closing gates. A cell is composed of four 
main elements: an input gate, a neuron with a self-recurrent connection,
 a forget gate, and an output gate. The forget gate is an element which 
allows the cell to remember or forget its previous state. For example, 
assume that we want to capture the gender of the subject. In this case, 
when seeing a new subject, the previous one should be forgotten so that a
 relevant information can be determined and stored.</p></section><section id="Sec16" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Convolutional neural network</h4><p id="Par58" class="Para">One
 of the most commonly used Deep Learning models is the fully-connected 
neural network. Although fully-connected neural networks are considered 
as a good solution in classification tasks, the huge number of 
connections in these networks may lead to problems. These problems can 
be further amplified in text processing because of the high number of 
neurons required. In addition, we believe that words which are close 
together in a sentence are more to each other when compared to words 
which never appear close together in any sentence. But fully-connected 
neural networks treat input words which are far apart the same as words 
which are close together in a sentence. The hierarchical learning 
process of Deep Learning makes it expensive for high-dimensional data 
like image or text. On the other words, these kinds of Deep Learning 
algorithm can be stalled when dealing with Big Data that shows large 
Volume (one of the features of Big Data).</p><p id="Par59" class="Para">Convolutional
 neural networks offer certain advantages that make them desirable to 
address these problems. First, each neuron in the first hidden layer, 
instead of connecting to all input neurons, is only connected to a small
 region of them. This reduction in connection complexity works to also 
reduce potential computational problems. Second, using the same weights 
for each of the hidden neurons provides the opportunity to detect the 
same feature in different locations in the input text. At the end of the
 network, a pooling layer simplifies the information from the 
convolutional layers to the output&nbsp;[<span class="CitationRef"><a href="#CR97" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">97</a></span>].
 The convolutional neural network is one of the methods that can be used
 effectively for Big Data analysis. The convolutional neural network 
which is one of the powerful models in Deep Learning, use convolutional 
layers to filter inputs for useful information.</p><p id="Par60" class="Para">Hinton et al.&nbsp;[<span class="CitationRef"><a href="#CR29" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">29</a></span>]
 use a Deep Learning and convolutional neural network for image object 
recognition. Their Deep Learning model outperforms other existing 
approaches. Hintons team work is valuable because they show the 
importance of Deep Learning in image searching. Dean et al. in&nbsp;[<span class="CitationRef"><a href="#CR84" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">84</a></span>] use similar Deep Learning modeling approach but with a large-scale software infrastructure as a training and in&nbsp;[<span class="CitationRef"><a href="#CR98" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">98</a></span>] video data is used. They use Deep Learning method like stacking and convolution to learn hierarchical representation.</p></section></section><section id="Sec17" tabindex="-1" class="Section2 RenderAsSection2"><h3 class="Heading">Results and discussion</h3><p id="Par61" class="Para">In
 this section, we will explain our experiments in applying Deep Learning
 methods on the StockTwits dataset. We tried to see if Deep Learning 
models could improve the accuracy of sentiment analysis of StockTwits 
messages. Deep Learning attempt to mimic the hierarchical learning 
approach of the human brain. Using Deep Learning in extract features 
bring non-linearity to the Big Data analysis. The results of applying 
three commonly used Deep Learning methods in natural language processing
 are provided in the following section.</p><section id="Sec18" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Doc2vec</h4><div id="Par62" class="Para"> <div id="Tab5" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 5</span> <p class="SimplePara">Performance of doc2vec on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Window</p> </th><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">5</p> </td><td> <p class="SimplePara">0.6202</p> </td><td> <p class="SimplePara">0.6097</p> </td><td> <p class="SimplePara">0.6682</p> </td><td> <p class="SimplePara">0.6376</p> </td><td> <p class="SimplePara">0.6202</p> </td></tr><tr><td> <p class="SimplePara">10</p> </td><td> <p class="SimplePara">0.6723</p> </td><td> <p class="SimplePara">0.6687</p> </td><td> <p class="SimplePara">0.6830</p> </td><td> <p class="SimplePara">0.6757</p> </td><td> <p class="SimplePara">0.6723</p> </td></tr></tbody></table></div></div> </div><p id="Par63" class="Para">As
 our first step, we apply the doc2vec model to the StockTwits dataset to
 see if it can increase the accuracy of sentiment prediction for stock 
market writers. This was chosen as the first model because it uses the 
paragraph as a memory to keep the order of the words in a sentence, and 
maps paragraphs, as well as words, to a vector.</p><p id="Par64" class="Para">Le in&nbsp;[<span class="CitationRef"><a href="#CR73" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">73</a></span>]
 recommends using both doc2vec architectures simultaneously to create a 
paragraph vector. Following his method in our experiment, each paragraph
 vector is a combination of two vectorsone learned by distributed 
memory architecture (DM) and the other learned with distributed 
bag-of-words (DBOW) architecture. The accuracy of the doc2vec model is 
also likely to be affected by window size; with larger windows having 
higher accuracy. In order to evaluate this, we consider windows of the 
most commonly-used sizes5 and 10. The Gensim library in Python was used
 to implement doc2vec and all words with a total frequency of less than 
two were ignored. The results are shown in Table <span class="InternalRef"><a href="#Tab5">5</a></span>.</p><p id="Par65" class="Para">As
 we expected, the accuracy of applying doc2vec for a window size of 10 
is higher than with a window size of 5, but their difference is 
negligible.</p><div id="Par66" class="Para">By comparing the results of applying logistic regression as a baseline on the StockTwits dataset in Table <span class="InternalRef"><a href="#Tab1">1</a></span> with the results of doc2vec in Table <span class="InternalRef"><a href="#Tab5">5</a></span>, we find that doc2vec cannot be an effective model to predict sentiment in the StockTwits dataset. In Fig.&nbsp;<span class="InternalRef"><a href="#Fig5">5</a></span>
 we provide the receiver operating characteristic curve for the window 
sizes of five and ten and compare their results with the ROC of the 
logistic regression.<figure class="Figure" id="Fig5"><div class="MediaObject" id="MO10"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig5_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig5_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 5</span> <p class="SimplePara">Area under the ROC curve for doc2vec with window size of 5 and 10</p> </div></figcaption></figure></div><div id="Par67" class="Para"> <div id="Tab6" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 6</span> <p class="SimplePara">Performance of the LSTM on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">0.6923</p> </td><td> <p class="SimplePara">0.8518</p> </td><td> <p class="SimplePara">0.6571</p> </td><td> <p class="SimplePara">0.7419</p> </td><td> <p class="SimplePara">0.7109</p> </td></tr></tbody></table></div></div> </div></section><section id="Sec19" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Long short-term memory</h4><p id="Par68" class="Para">Based
 on the findings in the previous section, doc2vec is not a good model 
for predicting sentiment of authors regarding the stock market, and so 
we move on to RNNs. These are some of the other most popular models for 
use in Natural Language processing have shown very good results. RNNs 
were adopted to see if they can help improve the accuracy of StockTwits 
sentiment analysis. Although an actual RNN was not used for our 
experiment, LSTM&nbsp;[<span class="CitationRef"><a href="#CR99" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">99</a></span>, <span class="CitationRef"><a href="#CR100" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">100</a></span>, <span class="CitationRef"><a href="#CR101" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">101</a></span>, <span class="CitationRef"><a href="#CR102" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">102</a></span>] could be a viable replacement because it has a deeper memory structure.</p><p id="Par69" class="Para">In our implementation, we used the Theano&nbsp;[<span class="CitationRef"><a href="#CR103" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">103</a></span>]
 library in Python. We use average pooling as our pooling method. For 
the last step, we fed the result of the pooling to a logistic regression
 layer to find the target class label associated with the current input 
sequence. We present the result of our experiments in Table <span class="InternalRef"><a href="#Tab6">6</a></span>. Although using LSTM compared to doc2vec did increase our accuracy, it is still lower than our requirements.</p><div id="Par70" class="Para">Using logistic regression as the baseline and comparing results in Tables <span class="InternalRef"><a href="#Tab1">1</a></span> and <span class="InternalRef"><a href="#Tab6">6</a></span> reveals that LSTM is not an effective model for predicting sentiment in the StockTwits dataset. In Fig.&nbsp;<span class="InternalRef"><a href="#Fig6">6</a></span>, we compare the area under the ROC curve for the results of applying LSTM and logistic regression.<figure class="Figure" id="Fig6"><div class="MediaObject" id="MO11"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig6_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig6_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 6</span> <p class="SimplePara">Area under the ROC curve for long short-term memory</p> </div></figcaption></figure></div><div id="Par71" class="Para"> <div id="Tab7" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 7</span> <p class="SimplePara">Performance of the convolutional neural network on the StockTwits dataset</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Steps</p> </th><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">100</p> </td><td> <p class="SimplePara">0.5700</p> </td><td> <p class="SimplePara">0.6348</p> </td><td> <p class="SimplePara">0.3294</p> </td><td> <p class="SimplePara">0.4338</p> </td><td> <p class="SimplePara">0.5700</p> </td></tr><tr><td> <p class="SimplePara">2000</p> </td><td> <p class="SimplePara">0.7943</p> </td><td> <p class="SimplePara">0.7787</p> </td><td> <p class="SimplePara">0.8221</p> </td><td> <p class="SimplePara">0.7999</p> </td><td> <p class="SimplePara">0.7943</p> </td></tr><tr><td> <p class="SimplePara">4000</p> </td><td> <p class="SimplePara">0.8210</p> </td><td> <p class="SimplePara">0.7828</p> </td><td> <p class="SimplePara">0.8885</p> </td><td> <p class="SimplePara">0.8323</p> </td><td> <p class="SimplePara">0.8210</p> </td></tr><tr><td> <p class="SimplePara">6000</p> </td><td> <p class="SimplePara">0.8651</p> </td><td> <p class="SimplePara">0.8778</p> </td><td> <p class="SimplePara">0.8484</p> </td><td> <p class="SimplePara">0.8629</p> </td><td> <p class="SimplePara">0.8651</p> </td></tr><tr><td> <p class="SimplePara">8000</p> </td><td> <p class="SimplePara">0.8891</p> </td><td> <p class="SimplePara">0.8774</p> </td><td> <p class="SimplePara">0.9046</p> </td><td> <p class="SimplePara">0.8908</p> </td><td> <p class="SimplePara">0.8891</p> </td></tr><tr><td> <p class="SimplePara">10,000</p> </td><td> <p class="SimplePara">0.9093</p> </td><td> <p class="SimplePara">0.9168</p> </td><td> <p class="SimplePara">0.9004</p> </td><td> <p class="SimplePara">0.9086</p> </td><td> <p class="SimplePara">0.9093</p> </td></tr><tr><td> <p class="SimplePara">70,000</p> </td><td> <p class="SimplePara">0.9897</p> </td><td> <p class="SimplePara">0.9909</p> </td><td> <p class="SimplePara">0.9885</p> </td><td> <p class="SimplePara">0.9897</p> </td><td> <p class="SimplePara">0.9897</p> </td></tr></tbody></table></div></div> </div><div id="Par72" class="Para"> <figure class="Figure" id="Fig7"><div class="MediaObject" id="MO12"> <a href="https://media.springernature.com/original/springer-static/image/art%3A10.1186%2Fs40537-017-0111-6/MediaObjects/40537_2017_111_Fig7_HTML.gif" target="_blank" rel="noopener"><span class="u-screenreader-only">Open image in new window</span><img src="40537_2017_111_Fig7_HTML.gif" alt=""></a> </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 7</span> <p class="SimplePara">Compare area under the ROC curve for convolutional neural network in various steps</p> </div></figcaption></figure> </div></section><section id="Sec20" tabindex="-1" class="Section3 RenderAsSection3"><h4 class="Heading">Convolutional neural network</h4><p id="Par73" class="Para">With
 LSTM being found ineffective, we turn to the CNN. Although CNN is very 
popular in image processing, the ability to find the internal structures
 of a Big Data makes it a desirable model for our purposes. We employ 
CNN to see if it can be used to improve our sentiment analysis task by 
using the Tensorflow&nbsp;[<span class="CitationRef"><a href="#CR104" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">104</a></span>] package in Python. The first step of our process is embedding words into low dimensional vectors.</p><p id="Par74" class="Para">After
 that, we perform convolutions with different filter sizes over the 
embedded word vectors. In our experiment, we used filter sizes of 3, 4 
and 5. Then we apply max pooling on the result of the convolution and 
add dropout regularization. The process concludes by using a softmax 
layer to classify our results.</p><div id="Par75" class="Para">Table <span class="InternalRef"><a href="#Tab7">7</a></span> shows the results of these operations. By comparing the accuracy of logistic regression as a baseline in Table <span class="InternalRef"><a href="#Tab1">1</a></span> with the results of applying convolutional neural network provided in Table <span class="InternalRef"><a href="#Tab7">7</a></span>,
 we conclude that CNN outperforms logistic regression after less than 
2000 steps. After 6000 steps the accuracy of CNN is around 86% which is 
considerably higher than the other models. Additionally in Fig.&nbsp;<span class="InternalRef"><a href="#Fig7">7</a></span>,
 we provide the receiver operating characteristic curve for CNN, which 
compares the area under the roc curve after applying CNN in multiple 
steps. As evident in Table <span class="InternalRef"><a href="#Fig7">7</a></span>,
 with proceeding steps in CNN, the ROC curve gets closer to the top left
 corner of the diagram. This proves that by proceeding stepwise in CNN 
on the StockTwits dataset, the accuracy of prediction increases 
gradually.&nbsp;We compare the result of logistic regression, doc2vec, 
LSTM, and CNN (after 10,000 steps) in Table <span class="InternalRef"><a href="#Tab8">8</a></span>.
 Based on the results, we find that CNN is an effective model for 
predicting the sentiment of authors in the StockTwits dataset as it 
outperformed all other models in all five performance measurement. 
&nbsp;<div id="Tab8" class="Table"><div class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 8</span> <p class="SimplePara">Compare Deep Learning models in financial sentiment analysis</p> </div></div><div class="u-scroll-horizontal"><table><colgroup><col class="tcol1 align-left"><col class="tcol2 align-left"><col class="tcol3 align-left"><col class="tcol4 align-left"><col class="tcol5 align-left"><col class="tcol6 align-left"></colgroup><thead><tr><th> <p class="SimplePara">Model</p> </th><th> <p class="SimplePara">Accuracy</p> </th><th> <p class="SimplePara">Precision</p> </th><th> <p class="SimplePara">Recall</p> </th><th> <p class="SimplePara">F-measure</p> </th><th> <p class="SimplePara">AUC</p> </th></tr></thead><tbody><tr><td> <p class="SimplePara">Logistic regression</p> </td><td> <p class="SimplePara">0.7088</p> </td><td> <p class="SimplePara">0.7134</p> </td><td> <p class="SimplePara">0.6980</p> </td><td> <p class="SimplePara">0.7056</p> </td><td> <p class="SimplePara">0.7088</p> </td></tr><tr><td> <p class="SimplePara">Doc2vec</p> </td><td> <p class="SimplePara">0.6723</p> </td><td> <p class="SimplePara">0.6687</p> </td><td> <p class="SimplePara">0.6830</p> </td><td> <p class="SimplePara">0.6757</p> </td><td> <p class="SimplePara">0.6723</p> </td></tr><tr><td> <p class="SimplePara">LSTM</p> </td><td> <p class="SimplePara">0.6923</p> </td><td> <p class="SimplePara">0.8515</p> </td><td> <p class="SimplePara">0.6571</p> </td><td> <p class="SimplePara">0.7419</p> </td><td> <p class="SimplePara">0.7109</p> </td></tr><tr><td> <p class="SimplePara">CNN (10,000 steps)</p> </td><td> <p class="SimplePara">0.9093</p> </td><td> <p class="SimplePara">0.9168</p> </td><td> <p class="SimplePara">0.9004</p> </td><td> <p class="SimplePara">0.9086</p> </td><td> <p class="SimplePara">0.9093</p> </td></tr></tbody></table></div></div></div></section></section></div></section><section id="Sec21" tabindex="-1" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="0">Conclusions<span class="section-icon"></span></h2><div class="content"><p id="Par76" class="Para">Deep
 Learning has good performance and promise in many areas, such as 
natural language processing. Deep Learning has this opportunity to 
address the data analysis and learning problems in Big Data. In contrast
 to data mining approaches with its shallow learning process, Deep 
Learning algorithms transform inputs through more layers. Hidden layers 
in Deep Learning are generally used to extract features or data 
representations. This hierarchical learning process in Deep Learning 
provides the opportunity to find word semantics and relations. These 
attributes make Deep Learning one of the most desirable models for 
sentiment analysis.</p><p id="Par77" class="Para">In this paper, based 
on our results we show that convolutional neural networks can overcome 
data mining approach in stock sentiment analysis. In standard data 
mining approach to text categorization, documents represent as 
bag-of-word vectors. These vectors represent which words appear in a 
document but do not consider the order of the words in a sentence. It is
 clear that in some cases, the word order can change the sentiment of a 
sentence. One remedy to this problem is using bi-grams or n-gram in 
addition to uni-gram&nbsp;[<span class="CitationRef"><a href="#CR86" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">86</a></span>, <span class="CitationRef"><a href="#CR105" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">105</a></span>, <span class="CitationRef"><a href="#CR106" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">106</a></span>]. Unfortunately, using n-grams with <span class="InlineEquation" id="IEq9">\(n &gt; 1\)</span> is not effective&nbsp;[<span class="CitationRef"><a href="#CR107" title="View reference" role="button" aria-pressed="false" aria-haspopup="true" aria-controls="popup-references">107</a></span>].
 Using CNN provides this opportunity to use n-grams to extract the 
sentiment of a document effectively. It benefits from the internal 
structure of data that exists in a document through convolution layers, 
where each computation unit responds to a small region of input data. We
 used logistic regression, which works based on a bag-of-words, as a 
baseline and compared the result of applying Deep Learning to logistic 
regression. Based on our results, among different common Deep Learning 
methods in sentiment analysis, only convolutional neural network 
outperforms logistic regression. The accuracy of convolutional neural 
networks, in comparison to the other models, is considerably better. 
Based on our results we can use CNN to extract the sentiment of authors 
regarding stocks from their words. There are some people in the 
financial social network who can correctly predict the stock market. By 
using CNN to predict their sentiment we can predict future market 
movement.</p></div></section></div><section id="Notes" class="Section1 RenderAsSection1"><h2 class="Heading" data-role="collapsible-handle" tabindex="0">Notes<span class="section-icon"></span></h2><div class="content"><section><h3 class="Heading">Authors contributions</h3><p class="SimplePara">SS
 is the main author, she did all the research and explored different 
methods. The idea of doing sentiment analysis and classifying users to 
bullish and bearish is DW idea. We consult with AP and TMK. AP helps us 
in financial concepts and we use TMK experience to improve our work. All
 authors read and approved the final manuscript.&nbsp;All authors read 
and approved the final manuscript.</p><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Acknowledgements</span></h3><p class="Para">Not applicable.</p></div><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Competing interests</span></h3><p class="Para">The authors declare that they have no competing interests.</p></div><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Availability of data and materials</span></h3><p class="Para">Not applicable.</p></div><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Consent for publication</span></h3><p class="Para">Not applicable.</p></div><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Ethics approval and consent to participate</span></h3><p class="Para">Not applicable.</p></div><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Funding</span></h3><p class="Para">Not applicable.</p></div><div class="FormalPara FormalParaRenderingStyle1"><h3 class="u-regular"><span class="Heading">Publisher's Note</span></h3><p class="Para">Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></section></div></section><section class="Section1 RenderAsSection1" id="Bib1" tabindex="-1"><h2 class="Heading" data-role="collapsible-handle" tabindex="0">References<span class="section-icon"></span></h2><div class="content"><ol class="BibliographyWrapper"><li class="Citation"><div class="CitationNumber">1.</div><div class="CitationContent" id="CR1">Ellison NB, et al. Social network sites: definition, history, and scholarship. J Comput Mediat Commun. 2007;13(1):21030.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2290297"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1111/j.1083-6101.2007.00393.x"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Social%20network%20sites%3A%20definition%2C%20history%2C%20and%20scholarship&amp;author=NB.%20Ellison&amp;journal=J%20Comput%20Mediat%20Commun&amp;volume=13&amp;issue=1&amp;pages=210-230&amp;publication_year=2007"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">2.</div><div class="CitationContent" id="CR2">Wang
 G, Wang T, Wang B, Sambasivan D, Zhang Z, Zheng H, Zhao BY. Crowds on 
wall street: extracting value from social investing platforms, 
foundations and trends in information retrieval. New York: ACM; 2014.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Crowds%20on%20wall%20street%3A%20extracting%20value%20from%20social%20investing%20platforms%2C%20foundations%20and%20trends%20in%20information%20retrieval&amp;author=G.%20Wang&amp;author=T.%20Wang&amp;author=B.%20Wang&amp;author=D.%20Sambasivan&amp;author=Z.%20Zhang&amp;author=H.%20Zheng&amp;author=BY.%20Zhao&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">3.</div><div class="CitationContent" id="CR3">Freedman DA. Statistical models: theory and practice. Cambridge: Cambridge University Press; 2009.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1017/CBO9780511815867"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1167.62001"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Statistical%20models%3A%20theory%20and%20practice&amp;author=DA.%20Freedman&amp;publication_year=2009"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">4.</div><div class="CitationContent" id="CR4">Krizhevsky
 A, Sutskever I, Hinton GE. Imagenet classification with deep 
convolutional neural networks. In: Advances in neural information 
processing systems; 2012. p. 1097105.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Krizhevsky%20A%2C%20Sutskever%20I%2C%20Hinton%20GE.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks.%20In%3A%20Advances%20in%20neural%20information%20processing%20systems%3B%202012.%20p.%201097%E2%80%93105."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">5.</div><div class="CitationContent" id="CR5">Socher
 R, Huang EH, Pennin J, Manning CD, Ng AY. Dynamic pooling and unfolding
 recursive autoencoders for paraphrase detection. Adv Neural Inf Process
 Syst. 2011;24:8019.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Socher%20R%2C%20Huang%20EH%2C%20Pennin%20J%2C%20Manning%20CD%2C%20Ng%20AY.%20Dynamic%20pooling%20and%20unfolding%20recursive%20autoencoders%20for%20paraphrase%20detection.%20Adv%20Neural%20Inf%20Process%20Syst.%202011%3B24%3A801%E2%80%939."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">6.</div><div class="CitationContent" id="CR6">Pearson K. Notes on regression and inheritance in the case of two parents. Proc R Soc Lond. 1895;58:2402.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1098/rspl.1895.0041"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Notes%20on%20regression%20and%20inheritance%20in%20the%20case%20of%20two%20parents&amp;author=K.%20Pearson&amp;journal=Proc%20R%20Soc%20Lond&amp;volume=58&amp;pages=240-242&amp;publication_year=1895"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">7.</div><div class="CitationContent" id="CR7">Graves
 A, Mohamed AR, Hinton G. Speech recognition with deep recurrent neural 
networks. In: 2013 IEEE international conference on acoustics, speech 
and signal processing (ICASSP); 2013.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Graves%20A%2C%20Mohamed%20AR%2C%20Hinton%20G.%20Speech%20recognition%20with%20deep%20recurrent%20neural%20networks.%20In%3A%202013%20IEEE%20international%20conference%20on%20acoustics%2C%20speech%20and%20signal%20processing%20%28ICASSP%29%3B%202013."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">8.</div><div class="CitationContent" id="CR8">Dahl
 G, Mohamed AR, Hinton GE. Phone recognition with the meancovariance 
restricted Boltzmann machine. Adv Neural Inf Process Sytst. 
2010;23:46977.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Phone%20recognition%20with%20the%20mean%E2%80%93covariance%20restricted%20Boltzmann%20machine&amp;author=G.%20Dahl&amp;author=AR.%20Mohamed&amp;author=GE.%20Hinton&amp;journal=Adv%20Neural%20Inf%20Process%20Sytst&amp;volume=23&amp;pages=469-477&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">9.</div><div class="CitationContent" id="CR9">George
 E, Yu D, Deng L, Acero A. Context-dependent pre-trained deep neural 
networks for large-vocabulary speech recognition. IEEE Trans Audio 
Speech Lang Process. 2012;20(1):3042.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/TASL.2011.2134090"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Context-dependent%20pre-trained%20deep%20neural%20networks%20for%20large-vocabulary%20speech%20recognition&amp;author=E.%20George&amp;author=D.%20Yu&amp;author=L.%20Deng&amp;author=A.%20Acero&amp;journal=IEEE%20Trans%20Audio%20Speech%20Lang%20Process&amp;volume=20&amp;issue=1&amp;pages=30-42&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">10.</div><div class="CitationContent" id="CR10">Seide
 F, Li G, Yu D. Conversational speech transcription using 
context-dependent deep neural networks. In: Twelfth annual conference of
 the international speech communication association; 2011.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Seide%20F%2C%20Li%20G%2C%20Yu%20D.%20Conversational%20speech%20transcription%20using%20context-dependent%20deep%20neural%20networks.%20In%3A%20Twelfth%20annual%20conference%20of%20the%20international%20speech%20communication%20association%3B%202011."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">11.</div><div class="CitationContent" id="CR11">Mohamed
 A, Dahl GE, Hinton G. Acoustic modeling using deep belief networks. 
IEEE Trans Audio Speech Lang Process. 2012;20(1):1422.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/TASL.2011.2109382"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Acoustic%20modeling%20using%20deep%20belief%20networks&amp;author=A.%20Mohamed&amp;author=GE.%20Dahl&amp;author=G.%20Hinton&amp;journal=IEEE%20Trans%20Audio%20Speech%20Lang%20Process&amp;volume=20&amp;issue=1&amp;pages=14-22&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">12.</div><div class="CitationContent" id="CR12">Itamar
 A, Rose DC, Karnowski TP. Deep machine learninga new frontier in 
artificial intelligence research [research frontier]. IEEE Comput Intell
 Mag. 2010;5(4):138.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/MCI.2010.938364"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Deep%20machine%20learning%E2%80%94a%20new%20frontier%20in%20artificial%20intelligence%20research%20%5Bresearch%20frontier%5D&amp;author=A.%20Itamar&amp;author=DC.%20Rose&amp;author=TP.%20Karnowski&amp;journal=IEEE%20Comput%20Intell%20Mag&amp;volume=5&amp;issue=4&amp;pages=13-18&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">13.</div><div class="CitationContent" id="CR13">Najafabadi
 NM, Villanustre F, Khoshgoftaar TM, Seliya N, Wald R, Muharemagic E. 
Deep learning applications and challenges in big data analytics. J Big 
Data. 2015;2:1.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1186/s40537-014-0007-7"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Deep%20learning%20applications%20and%20challenges%20in%20big%20data%20analytics&amp;author=NM.%20Najafabadi&amp;author=F.%20Villanustre&amp;author=TM.%20Khoshgoftaar&amp;author=N.%20Seliya&amp;author=R.%20Wald&amp;author=E.%20Muharemagic&amp;journal=J%20Big%20Data&amp;volume=2&amp;pages=1&amp;publication_year=2015"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">14.</div><div class="CitationContent" id="CR14">LeCun
 Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied to 
document recognition. Proc IEEE. 1998;86(11):2278324.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/5.726791"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Gradient-based%20learning%20applied%20to%20document%20recognition&amp;author=Y.%20LeCun&amp;author=L.%20Bottou&amp;author=Y.%20Bengio&amp;author=P.%20Haffner&amp;journal=Proc%20IEEE&amp;volume=86&amp;issue=11&amp;pages=2278-2324&amp;publication_year=1998"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">15.</div><div class="CitationContent" id="CR15">Collobert
 R, Weston J, Bottou L, Karlen M, Kavukcuoglu K, Kuksa P. Natural 
language processing (almost) from scratch. J Mach Learn Res. 
2011;12:2493537.<span class="Occurrences"><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1280.68161"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Natural%20language%20processing%20%28almost%29%20from%20scratch&amp;author=R.%20Collobert&amp;author=J.%20Weston&amp;author=L.%20Bottou&amp;author=M.%20Karlen&amp;author=K.%20Kavukcuoglu&amp;author=P.%20Kuksa&amp;journal=J%20Mach%20Learn%20Res&amp;volume=12&amp;pages=2493-2537&amp;publication_year=2011"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">16.</div><div class="CitationContent" id="CR16">Collobert
 R, Weston J. A unified architecture for natural language processing: 
deep neural networks with multitask learning. In: Proceedings of the 
25th international conference on machine learning. London: ACM; 2008. p.
 1607.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Collobert%20R%2C%20Weston%20J.%20A%20unified%20architecture%20for%20natural%20language%20processing%3A%20deep%20neural%20networks%20with%20multitask%20learning.%20In%3A%20Proceedings%20of%20the%2025th%20international%20conference%20on%20machine%20learning.%20London%3A%20ACM%3B%202008.%20p.%20160%E2%80%937."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">17.</div><div class="CitationContent" id="CR17">Gao J, Deng L, Gamon M, He X, Pantel P. Modeling interestingness with deep neural networks. 2014. US Patent App. 14/304,863.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Gao%20J%2C%20Deng%20L%2C%20Gamon%20M%2C%20He%20X%2C%20Pantel%20P.%20Modeling%20interestingness%20with%20deep%20neural%20networks.%202014.%20US%20Patent%20App.%2014%2F304%2C863."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">18.</div><div class="CitationContent" id="CR18">Kalchbrenner N, Grefenstette E, Blunsom P. A convolutional neural network for modelling sentences. arXiv preprint <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1404.2188"><span class="RefSource">arXiv:1404.2188</span></a></span>. 2014.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">19.</div><div class="CitationContent" id="CR19">Kim Y. Convolutional neural networks for sentence classification. arXiv preprint <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1408.5882"><span class="RefSource">arXiv:1408.5882</span></a></span>. 2014.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">20.</div><div class="CitationContent" id="CR20">Shen
 Y, He X, Gao J, Deng L, Mesnil G. A latent semantic model with 
convolutional-pooling structure for information retrieval. In: 
Proceedings of the 23rd ACM international conference on information and 
knowledge management. New York: ACM; 2014. p. 10110.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Shen%20Y%2C%20He%20X%2C%20Gao%20J%2C%20Deng%20L%2C%20Mesnil%20G.%20A%20latent%20semantic%20model%20with%20convolutional-pooling%20structure%20for%20information%20retrieval.%20In%3A%20Proceedings%20of%20the%2023rd%20ACM%20international%20conference%20on%20information%20and%20knowledge%20management.%20New%20York%3A%20ACM%3B%202014.%20p.%20101%E2%80%9310."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">21.</div><div class="CitationContent" id="CR21">Liheng X, Liu K, Lai S, Zhao J, et al. Product feature mining: semantic clues versus syntactic constituents. ACL. 2014;1:33646.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Product%20feature%20mining%3A%20semantic%20clues%20versus%20syntactic%20constituents&amp;author=X.%20Liheng&amp;author=K.%20Liu&amp;author=S.%20Lai&amp;author=J.%20Zhao&amp;journal=ACL&amp;volume=1&amp;pages=336-346&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">22.</div><div class="CitationContent" id="CR22">Tang
 Duyu, Wei Furu, Yang Nan, Zhou Ming, Liu Ting, Qin Bing. Learning 
sentiment-specific word embedding for twitter sentiment classification. 
ACL. 2014;1:155565.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Learning%20sentiment-specific%20word%20embedding%20for%20twitter%20sentiment%20classification&amp;author=Duyu.%20Tang&amp;author=Furu.%20Wei&amp;author=Nan.%20Yang&amp;author=Ming.%20Zhou&amp;author=Ting.%20Liu&amp;author=Bing.%20Qin&amp;journal=ACL&amp;volume=1&amp;pages=1555-1565&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">23.</div><div class="CitationContent" id="CR23">Weston J, Chopra S, Adams K. # tagspace: semantic embeddings from hashtags. 2014.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Weston%20J%2C%20Chopra%20S%2C%20Adams%20K.%20%23%20tagspace%3A%20semantic%20embeddings%20from%20hashtags.%202014."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">24.</div><div class="CitationContent" id="CR24">Geoffrey E, Osindero S, Teh YW. A fast learning algorithm for deep belief nets. Neural Comput. 2006;18(7):152754.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2224485"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1162/neco.2006.18.7.1527"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1106.68094"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets&amp;author=E.%20Geoffrey&amp;author=S.%20Osindero&amp;author=YW.%20Teh&amp;journal=Neural%20Comput&amp;volume=18&amp;issue=7&amp;pages=1527-1554&amp;publication_year=2006"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">25.</div><div class="CitationContent" id="CR25">Bengio
 Y, Lamblin P, Popovici D, Larochelle H. Greedy layer-wise training of 
deep networks. Adv Neural Inf Process Syst. 2007;19:15360.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Greedy%20layer-wise%20training%20of%20deep%20networks&amp;author=Y.%20Bengio&amp;author=P.%20Lamblin&amp;author=D.%20Popovici&amp;author=H.%20Larochelle&amp;journal=Adv%20Neural%20Inf%20Process%20Syst&amp;volume=19&amp;pages=153-160&amp;publication_year=2007"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">26.</div><div class="CitationContent" id="CR26">Li
 G, Zhu H, Cheng G, Thambiratnam K, Chitsaz B, Yu D, Seide F. 
Context-dependent deep neural networks for audio indexing of real-life 
data. In: IEEE spoken language technology workshop (SLT). 2012. p. 
1438.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Li%20G%2C%20Zhu%20H%2C%20Cheng%20G%2C%20Thambiratnam%20K%2C%20Chitsaz%20B%2C%20Yu%20D%2C%20Seide%20F.%20Context-dependent%20deep%20neural%20networks%20for%20audio%20indexing%20of%20real-life%20data.%20In%3A%20IEEE%20spoken%20language%20technology%20workshop%20%28SLT%29.%202012.%20p.%20143%E2%80%938."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">27.</div><div class="CitationContent" id="CR27">Brin S, Page L. Reprint of: the anatomy of a large-scale hypertextual web search engine. Comput Netw. 2012;56(18):382533.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/j.comnet.2012.10.007"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Reprint%20of%3A%20the%20anatomy%20of%20a%20large-scale%20hypertextual%20web%20search%20engine&amp;author=S.%20Brin&amp;author=L.%20Page&amp;journal=Comput%20Netw&amp;volume=56&amp;issue=18&amp;pages=3825-3833&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">28.</div><div class="CitationContent" id="CR28">Mortensen EN, Barrett WA. Interactive segmentation with intelligent scissors. Graph Models Image Process. 1998;60(5):34984.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1006/gmip.1998.0480"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?0914.68210"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Interactive%20segmentation%20with%20intelligent%20scissors&amp;author=EN.%20Mortensen&amp;author=WA.%20Barrett&amp;journal=Graph%20Models%20Image%20Process&amp;volume=60&amp;issue=5&amp;pages=349-384&amp;publication_year=1998"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">29.</div><div class="CitationContent" id="CR29">Krizhevsky
 A, Sutskever I, Hinton GE. Imagenet classification with deep 
convolutional neural networks. Adv Neural Inf Process Syst. 
2012:1097105.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Krizhevsky%20A%2C%20Sutskever%20I%2C%20Hinton%20GE.%20Imagenet%20classification%20with%20deep%20convolutional%20neural%20networks.%20Adv%20Neural%20Inf%20Process%20Syst.%202012%3A1097%E2%80%93105."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">30.</div><div class="CitationContent" id="CR30">Hinton
 G, Deng L, Dong Y, Dahl GE, Mohamed Abdel-rahman, Jaitly Navdeep, 
Senior Andrew, Vanhoucke Vincent, Nguyen Patrick, Sainath Tara N, et al.
 Deep neural networks for acoustic modeling in speech recognition: the 
shared views of four research groups. IEEE Signal Process Mag. 
2012;29(6):8297.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/MSP.2012.2205597"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Deep%20neural%20networks%20for%20acoustic%20modeling%20in%20speech%20recognition%3A%20the%20shared%20views%20of%20four%20research%20groups&amp;author=G.%20Hinton&amp;author=L.%20Deng&amp;author=Y.%20Dong&amp;author=GE.%20Dahl&amp;author=Abdel-rahman.%20Mohamed&amp;author=Navdeep.%20Jaitly&amp;author=Andrew.%20Senior&amp;author=Vincent.%20Vanhoucke&amp;author=Patrick.%20Nguyen&amp;author=Tara%20N.%20Sainath&amp;journal=IEEE%20Signal%20Process%20Mag&amp;volume=29&amp;issue=6&amp;pages=82-97&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">31.</div><div class="CitationContent" id="CR31">Alexandrescu
 A, Kirchhoff K. Factored neural language models. In: Proceedings of the
 human language technology conference of the NAACL, companion, volume: 
short papers. Association for computational linguistics; 2006. p. 14.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Alexandrescu%20A%2C%20Kirchhoff%20K.%20Factored%20neural%20language%20models.%20In%3A%20Proceedings%20of%20the%20human%20language%20technology%20conference%20of%20the%20NAACL%2C%20companion%2C%20volume%3A%20short%20papers.%20Association%20for%20computational%20linguistics%3B%202006.%20p.%201%E2%80%934."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">32.</div><div class="CitationContent" id="CR32">Luong
 T, Socher R, Manning CD. Better word representations with recursive 
neural networks for morphology. Vancouver: CoNLL; 2013. p. 10413.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Better%20word%20representations%20with%20recursive%20neural%20networks%20for%20morphology&amp;author=T.%20Luong&amp;author=R.%20Socher&amp;author=CD.%20Manning&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">33.</div><div class="CitationContent" id="CR33">Lazaridou
 A, Marelli M, Zamparelli R, Baroni M. Compositionally derived 
representations of morphologically complex words in distributional 
semantics. ACL. 2013;1:151726.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Compositionally%20derived%20representations%20of%20morphologically%20complex%20words%20in%20distributional%20semantics&amp;author=A.%20Lazaridou&amp;author=M.%20Marelli&amp;author=R.%20Zamparelli&amp;author=M.%20Baroni&amp;journal=ACL&amp;volume=1&amp;pages=1517-1526&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">34.</div><div class="CitationContent" id="CR34">Kilgarriff A, Grefenstette G. Introduction to the special issue on the web as corpus. Comput Linguis. 2003;29(3):33347.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2113093"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1162/089120103322711569"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Introduction%20to%20the%20special%20issue%20on%20the%20web%20as%20corpus&amp;author=A.%20Kilgarriff&amp;author=G.%20Grefenstette&amp;journal=Comput%20Linguis&amp;volume=29&amp;issue=3&amp;pages=333-347&amp;publication_year=2003"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">35.</div><div class="CitationContent" id="CR35">Socher
 R, Pennington J, Huang EH, Ng AY, Manning CD. Semi-supervised recursive
 autoencoders for predicting sentiment distributions. In: Proceedings of
 the conference on empirical methods in natural language processing. 
Association for computational linguistics; 2011. p. 15161.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Socher%20R%2C%20Pennington%20J%2C%20Huang%20EH%2C%20Ng%20AY%2C%20Manning%20CD.%20Semi-supervised%20recursive%20autoencoders%20for%20predicting%20sentiment%20distributions.%20In%3A%20Proceedings%20of%20the%20conference%20on%20empirical%20methods%20in%20natural%20language%20processing.%20Association%20for%20computational%20linguistics%3B%202011.%20p.%20151%E2%80%9361."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">36.</div><div class="CitationContent" id="CR36">Hinton GE, Salakhutdinov RR. Reducing the dimensionality of data with neural networks. Science. 2006;313(5786):5047.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2242509"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1126/science.1127647"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1226.68083"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Reducing%20the%20dimensionality%20of%20data%20with%20neural%20networks&amp;author=GE.%20Hinton&amp;author=RR.%20Salakhutdinov&amp;journal=Science&amp;volume=313&amp;issue=5786&amp;pages=504-507&amp;publication_year=2006"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">37.</div><div class="CitationContent" id="CR37">Hinton
 GE, Zemel RS. Autoencoders, minimum description length and helmholtz 
free energy. Adv Neural Inform Process Syst. 1994:310.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Hinton%20GE%2C%20Zemel%20RS.%20Autoencoders%2C%20minimum%20description%20length%20and%20helmholtz%20free%20energy.%20Adv%20Neural%20Inform%20Process%20Syst.%201994%3A3%E2%80%9310."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">38.</div><div class="CitationContent" id="CR38">Smolensky
 P. Information processing in dynamical systems: foundations of harmony 
theory. Technical report, Colorado Univ at Boulder Dept of Computer 
Science; 1986.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Smolensky%20P.%20Information%20processing%20in%20dynamical%20systems%3A%20foundations%20of%20harmony%20theory.%20Technical%20report%2C%20Colorado%20Univ%20at%20Boulder%20Dept%20of%20Computer%20Science%3B%201986."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">39.</div><div class="CitationContent" id="CR39">Hinton GE. Training products of experts by minimizing contrastive divergence. Neural Comput. 2006;14(8):1771800.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1162/089976602760128018"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1010.68111"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Training%20products%20of%20experts%20by%20minimizing%20contrastive%20divergence&amp;author=GE.%20Hinton&amp;journal=Neural%20Comput&amp;volume=14&amp;issue=8&amp;pages=1771-800&amp;publication_year=2006"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">40.</div><div class="CitationContent" id="CR40">Socher
 R, Huval B, Manning CD, Ng AY. Semantic compositionality through 
recursive matrix-vector spaces. In: Proceedings of the 2012 joint 
conference on empirical methods in natural language processing and 
computational natural language learning. Association for computational 
linguistics; 2012. p. 120111.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Socher%20R%2C%20Huval%20B%2C%20Manning%20CD%2C%20Ng%20AY.%20Semantic%20compositionality%20through%20recursive%20matrix-vector%20spaces.%20In%3A%20Proceedings%20of%20the%202012%20joint%20conference%20on%20empirical%20methods%20in%20natural%20language%20processing%20and%20computational%20natural%20language%20learning.%20Association%20for%20computational%20linguistics%3B%202012.%20p.%201201%E2%80%9311."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">41.</div><div class="CitationContent" id="CR41">Socher R, Bauer J, Manning CD, Ng AY. Parsing with compositional vector grammars. ACL. 2013;1:45565.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Parsing%20with%20compositional%20vector%20grammars&amp;author=R.%20Socher&amp;author=J.%20Bauer&amp;author=CD.%20Manning&amp;author=AY.%20Ng&amp;journal=ACL&amp;volume=1&amp;pages=455-465&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">42.</div><div class="CitationContent" id="CR42">Socher
 R, Lin CC, Manning C, Ng AY. Parsing natural scenes and natural 
language with recursive neural networks. In: Proceedings of the 28th 
international conference on machine learning (ICML-11). 2011. p. 12936.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Socher%20R%2C%20Lin%20CC%2C%20Manning%20C%2C%20Ng%20AY.%20Parsing%20natural%20scenes%20and%20natural%20language%20with%20recursive%20neural%20networks.%20In%3A%20Proceedings%20of%20the%2028th%20international%20conference%20on%20machine%20learning%20%28ICML-11%29.%202011.%20p.%20129%E2%80%9336."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">43.</div><div class="CitationContent" id="CR43">Collobert
 R. Deep learning for efficient discriminative parsing. In: Proceedings 
of the fourteenth international conference on artificial intelligence 
and statistics. 2011. p. 22432.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Collobert%20R.%20Deep%20learning%20for%20efficient%20discriminative%20parsing.%20In%3A%20Proceedings%20of%20the%20fourteenth%20international%20conference%20on%20artificial%20intelligence%20and%20statistics.%202011.%20p.%20224%E2%80%9332."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">44.</div><div class="CitationContent" id="CR44">Market Sentiment. <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://www.investopedia.com/"><span class="RefSource">http://www.investopedia.com/</span></a></span>.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">45.</div><div class="CitationContent" id="CR45">Pang B, Lee L. Opinion mining and sentiment analysis. Found Trends Inf Retrieval. 2008;2:135.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1561/1500000011"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Opinion%20mining%20and%20sentiment%20analysis&amp;author=B.%20Pang&amp;author=L.%20Lee&amp;journal=Found%20Trends%20Inf%20Retrieval&amp;volume=2&amp;pages=1-35&amp;publication_year=2008"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">46.</div><div class="CitationContent" id="CR46">Loughran T, McDonald B. When is a liability not a liability? Textual analysis, dictionaries. J Finance. 2011;66:3565.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1111/j.1540-6261.2010.01625.x"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=When%20is%20a%20liability%20not%20a%20liability%3F%20Textual%20analysis%2C%20dictionaries&amp;author=T.%20Loughran&amp;author=B.%20McDonald&amp;journal=J%20Finance&amp;volume=66&amp;pages=35-65&amp;publication_year=2011"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">47.</div><div class="CitationContent" id="CR47">Mao
 H, Gao P, Wang Y, Bollen J. Automatic construction of financial 
semantic orientation lexicon from large scale Chinese news corpus. In: 
7th Financial risks international forum; 2014.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Mao%20H%2C%20Gao%20P%2C%20Wang%20Y%2C%20Bollen%20J.%20Automatic%20construction%20of%20financial%20semantic%20orientation%20lexicon%20from%20large%20scale%20Chinese%20news%20corpus.%20In%3A%207th%20Financial%20risks%20international%20forum%3B%202014."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">48.</div><div class="CitationContent" id="CR48">Steinwart I, Christmann A. Support vector machine. Berlin: Springer; 2008.<span class="Occurrences"><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1203.68171"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Support%20vector%20machine&amp;author=I.%20Steinwart&amp;author=A.%20Christmann&amp;publication_year=2008"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">49.</div><div class="CitationContent" id="CR49">Saif H, He Y, Alani H. Semantic sentiment analysis of Twitter. The semantic Web-ISWC 2012. Berlin: Springer; 2012. p. 50824.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1007/978-3-642-35176-1_32"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Semantic%20sentiment%20analysis%20of%20Twitter.%20The%20semantic%20Web-ISWC%202012&amp;author=H.%20Saif&amp;author=Y.%20He&amp;author=H.%20Alani&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">50.</div><div class="CitationContent" id="CR50">Silva N, Hruschka E, Hruschka E. Tweet sentiment analysis with classifier ensembles. Decis Support Syst. 2014;66:1709.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/j.dss.2014.07.003"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Tweet%20sentiment%20analysis%20with%20classifier%20ensembles&amp;author=N.%20Silva&amp;author=E.%20Hruschka&amp;author=E.%20Hruschka&amp;journal=Decis%20Support%20Syst&amp;volume=66&amp;pages=170-179&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">51.</div><div class="CitationContent" id="CR51">Fersini
 E, Messina E, Pozzi FA. Automatic construction of financial semantic 
orientation lexicon from large scale Chinese news corpus. Decis Support 
Syst. 2014;68:2638.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/j.dss.2014.10.004"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Automatic%20construction%20of%20financial%20semantic%20orientation%20lexicon%20from%20large%20scale%20Chinese%20news%20corpus&amp;author=E.%20Fersini&amp;author=E.%20Messina&amp;author=FA.%20Pozzi&amp;journal=Decis%20Support%20Syst&amp;volume=68&amp;pages=26-38&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">52.</div><div class="CitationContent" id="CR52">Potts C, Pearson K. From frequency to meaning: vector space models of semantics. J Artif Intell Res. 2010;37:14188.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2602620"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=From%20frequency%20to%20meaning%3A%20vector%20space%20models%20of%20semantics&amp;author=C.%20Potts&amp;author=K.%20Pearson&amp;journal=J%20Artif%20Intell%20Res&amp;volume=37&amp;pages=141-188&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">53.</div><div class="CitationContent" id="CR53">Salton G, Buckley C. Term-weighting approaches in automatic text retrieval. Inf Process Manag. 1988;24(5):51323.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/0306-4573%2888%2990021-0"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Term-weighting%20approaches%20in%20automatic%20text%20retrieval&amp;author=G.%20Salton&amp;author=C.%20Buckley&amp;journal=Inf%20Process%20Manag&amp;volume=24&amp;issue=5&amp;pages=513-523&amp;publication_year=1988"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">54.</div><div class="CitationContent" id="CR54">Robertson
 SE, Walker S. Some simple effective approximations to the 2-Poisson 
model for probabilistic weighted retrieval. In: Proceedings of the 17th 
annual international ACM SIGIR conference on research and development in
 information retrieval. New York: Springer Inc.; 1994. p. 23241.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Robertson%20SE%2C%20Walker%20S.%20Some%20simple%20effective%20approximations%20to%20the%202-Poisson%20model%20for%20probabilistic%20weighted%20retrieval.%20In%3A%20Proceedings%20of%20the%2017th%20annual%20international%20ACM%20SIGIR%20conference%20on%20research%20and%20development%20in%20information%20retrieval.%20New%20York%3A%20Springer%20Inc.%3B%201994.%20p.%20232%E2%80%9341."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">55.</div><div class="CitationContent" id="CR55">Bengio Y, et al. Learning deep architectures for AI. Found Trends Mach Learn. 2009;2(1):1127.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=2480723"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1561/2200000006"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1192.68503"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Learning%20deep%20architectures%20for%20AI&amp;author=Y.%20Bengio&amp;journal=Found%20Trends%20Mach%20Learn&amp;volume=2&amp;issue=1&amp;pages=1-127&amp;publication_year=2009"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">56.</div><div class="CitationContent" id="CR56">Chen H, Chiang RHL, Storey VC. Business intelligence and analytics: from big data to big impact. MIS Quart. 2012;36:4.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Business%20intelligence%20and%20analytics%3A%20from%20big%20data%20to%20big%20impact&amp;author=H.%20Chen&amp;author=RHL.%20Chiang&amp;author=VC.%20Storey&amp;journal=MIS%20Quart&amp;volume=36&amp;pages=4&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">57.</div><div class="CitationContent" id="CR57">Dalal
 N, Triggs B. Histograms of oriented gradients for human detection. In: 
IEEE computer society conference on computer vision and pattern 
recognition, CVPR 2005, vol. 1. 2005. p. 88693.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Dalal%20N%2C%20Triggs%20B.%20Histograms%20of%20oriented%20gradients%20for%20human%20detection.%20In%3A%20IEEE%20computer%20society%20conference%20on%20computer%20vision%20and%20pattern%20recognition%2C%20CVPR%202005%2C%20vol.%201.%202005.%20p.%20886%E2%80%9393."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">58.</div><div class="CitationContent" id="CR58">Lowe
 DG. Object recognition from local scale-invariant features. In: The 
proceedings of the seventh IEEE international conference on computer 
vision, vol. 2. 1999. p. 11507.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Lowe%20DG.%20Object%20recognition%20from%20local%20scale-invariant%20features.%20In%3A%20The%20proceedings%20of%20the%20seventh%20IEEE%20international%20conference%20on%20computer%20vision%2C%20vol.%202.%201999.%20p.%201150%E2%80%937."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">59.</div><div class="CitationContent" id="CR59">Bahdanau D, Cho K, Bengio Y. Neural machine translation by jointly learning to align and translate. <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1409.0473"><span class="RefSource">arXiv:1409.0473</span></a></span>. 2014.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">60.</div><div class="CitationContent" id="CR60">Coates
 A, Ng AY. The importance of encoding versus training with sparse coding
 and vector quantization. In: Proceedings of the 28th international 
conference on machine learning (ICML-11). 2011. p. 9218.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Coates%20A%2C%20Ng%20AY.%20The%20importance%20of%20encoding%20versus%20training%20with%20sparse%20coding%20and%20vector%20quantization.%20In%3A%20Proceedings%20of%20the%2028th%20international%20conference%20on%20machine%20learning%20%28ICML-11%29.%202011.%20p.%20921%E2%80%938."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">61.</div><div class="CitationContent" id="CR61">Hinton
 GE, Srivastava N, Krizhevsky A, Sutskever I, Salakhutdinov RR. 
Improving neural networks by preventing co-adaptation of feature 
detectors. <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1207.0580"><span class="RefSource">arXiv:1207.0580</span></a></span>. 2012.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">62.</div><div class="CitationContent" id="CR62">Fan J, Han F, Liu H. Challenges of big data analysis. Natl Sci Rev. 2014;1(2):293314.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1093/nsr/nwt032"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Challenges%20of%20big%20data%20analysis&amp;author=J.%20Fan&amp;author=F.%20Han&amp;author=H.%20Liu&amp;journal=Natl%20Sci%20Rev&amp;volume=1&amp;issue=2&amp;pages=293-314&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">63.</div><div class="CitationContent" id="CR63">Abadi
 M, Agarwal A, Barham P, Brevdo E. Thumbs up or thumbs down? Semantic 
orientation applied to unsupervised classification of reviews. Proc 
Assoc Comput Linguis. 2002;66:41724.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Thumbs%20up%20or%20thumbs%20down%3F%20Semantic%20orientation%20applied%20to%20unsupervised%20classification%20of%20reviews&amp;author=M.%20Abadi&amp;author=A.%20Agarwal&amp;author=P.%20Barham&amp;author=E.%20Brevdo&amp;journal=Proc%20Assoc%20Comput%20Linguis&amp;volume=66&amp;pages=417-424&amp;publication_year=2002"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">64.</div><div class="CitationContent" id="CR64">Pang
 B, Lee L, Vaithyanathan S. Thumbs up? Sentiment classification using 
machine learning techniques. In: Proceedings of the conference on 
empirical methods in natural language processing, vol. 66; 2002. p. 
7986.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Pang%20B%2C%20Lee%20L%2C%20Vaithyanathan%20S.%20Thumbs%20up%3F%20Sentiment%20classification%20using%20machine%20learning%20techniques.%20In%3A%20Proceedings%20of%20the%20conference%20on%20empirical%20methods%20in%20natural%20language%20processing%2C%20vol.%2066%3B%202002.%20p.%2079%E2%80%9386."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">65.</div><div class="CitationContent" id="CR65">Kiritchenko S, Zhu X, Mohammad S. Sentiment analysis of short informal texts. J Artif Intell Res. 2014;50:72362.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Sentiment%20analysis%20of%20short%20informal%20texts&amp;author=S.%20Kiritchenko&amp;author=X.%20Zhu&amp;author=S.%20Mohammad&amp;journal=J%20Artif%20Intell%20Res&amp;volume=50&amp;pages=723-762&amp;publication_year=2014"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">66.</div><div class="CitationContent" id="CR66">Hanley
 JA, McNeil BJ. The meaning and use of the area under a receiver 
operating characteristic (ROC) curve. Radiology. 1982;143:2936.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1148/radiology.143.1.7063747"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=The%20meaning%20and%20use%20of%20the%20area%20under%20a%20receiver%20operating%20characteristic%20%28ROC%29%20curve&amp;author=JA.%20Hanley&amp;author=BJ.%20McNeil&amp;journal=Radiology&amp;volume=143&amp;pages=29-36&amp;publication_year=1982"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">67.</div><div class="CitationContent" id="CR67">Bermingham
 ML, Pong-Wong R, Spiliopoulou A, Hayward C, Rudan I, Campbell H, Wright
 AF, Wilson JF, Agakov F, Navarro P, Haley CS. Application of 
high-dimensional feature selection: evaluation for genomic prediction in
 man. Sci Rep. 2015;5:10312.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1038/srep10312"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Application%20of%20high-dimensional%20feature%20selection%3A%20evaluation%20for%20genomic%20prediction%20in%20man&amp;author=ML.%20Bermingham&amp;author=R.%20Pong-Wong&amp;author=A.%20Spiliopoulou&amp;author=C.%20Hayward&amp;author=I.%20Rudan&amp;author=H.%20Campbell&amp;author=AF.%20Wright&amp;author=JF.%20Wilson&amp;author=F.%20Agakov&amp;author=P.%20Navarro&amp;author=CS.%20Haley&amp;journal=Sci%20Rep&amp;volume=5&amp;pages=10312&amp;publication_year=2015"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">68.</div><div class="CitationContent" id="CR68">Torgo L. Data mining with R. Boca Raton: CRC Press; 2010.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1201/b10328"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Data%20mining%20with%20R&amp;author=L.%20Torgo&amp;publication_year=2010"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">69.</div><div class="CitationContent" id="CR69">Saeys Y, Inza I, Larraaga P. A review of feature selection techniques in bioinformatics. Bioinformatics. 2007;23(19):250717.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1093/bioinformatics/btm344"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=A%20review%20of%20feature%20selection%20techniques%20in%20bioinformatics&amp;author=Y.%20Saeys&amp;author=I.%20Inza&amp;author=P.%20Larra%C3%B1aga&amp;journal=Bioinformatics&amp;volume=23&amp;issue=19&amp;pages=2507-2517&amp;publication_year=2007"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">70.</div><div class="CitationContent" id="CR70">Pearson
 K. X. On the criterion that a given system of deviations from the 
probable in the case of a corsystem of variables is such that it can be 
reasonably supposed to have arisen from random sampling. Lond Edinburgh 
Dublin Philos Mag J Sci. 1900;50:15775.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1080/14786440009463897"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?31.0238.04"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=X.%20On%20the%20criterion%20that%20a%20given%20system%20of%20deviations%20from%20the%20probable%20in%20the%20case%20of%20a%20corsystem%20of%20variables%20is%20such%20that%20it%20can%20be%20reasonably%20supposed%20to%20have%20arisen%20from%20random%20sampling&amp;author=K.%20Pearson&amp;journal=Lond%20Edinburgh%20Dublin%20Philos%20Mag%20J%20Sci&amp;volume=50&amp;pages=157-175&amp;publication_year=1900"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">71.</div><div class="CitationContent" id="CR71">Fisher R. Dispersion on a sphere. Proc R Soc Lond. 1953;217:295305.<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a class="gtm-reference" data-reference-type="MathSciNet" target="_blank" rel="noopener" href="http://www.ams.org/mathscinet-getitem?mr=56866"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1098/rspa.1953.0064"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?0051.37105"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Dispersion%20on%20a%20sphere&amp;author=R.%20Fisher&amp;journal=Proc%20R%20Soc%20Lond&amp;volume=217&amp;pages=295-305&amp;publication_year=1953"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">72.</div><div class="CitationContent" id="CR72">Grnauer A, Vincze M. Using dimension reduction to improve the classification of high-dimensional data. arXiv preprint <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1505.06907"><span class="RefSource">arXiv:1505.06907</span></a></span>. 2015.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">73.</div><div class="CitationContent" id="CR73">Le
 Q, Mikolov T. Distributed representations of sentences and documents. 
In: International conference on machine learning, vol. 31. 2014.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Le%20Q%2C%20Mikolov%20T.%20Distributed%20representations%20of%20sentences%20and%20documents.%20In%3A%20International%20conference%20on%20machine%20learning%2C%20vol.%2031.%202014."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">74.</div><div class="CitationContent" id="CR74">Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. In: Workshop at ICLR. 2013.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Mikolov%20T%2C%20Chen%20K%2C%20Corrado%20G%2C%20Dean%20J.%20Efficient%20estimation%20of%20word%20representations%20in%20vector%20space.%20In%3A%20Workshop%20at%20ICLR.%202013."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">75.</div><div class="CitationContent" id="CR75">Mikolov
 T, Sutskever I, Chen K, Corrado GS, Dean J. Distributed representations
 of words and phrases and their compositionality. In: Workshop at ICLR. 
2013.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Mikolov%20T%2C%20Sutskever%20I%2C%20Chen%20K%2C%20Corrado%20GS%2C%20Dean%20J.%20Distributed%20representations%20of%20words%20and%20phrases%20and%20their%20compositionality.%20In%3A%20Workshop%20at%20ICLR.%202013."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">76.</div><div class="CitationContent" id="CR76">Hochreiter S, Schmidhuber J. Long short-term memory. Neural Comput. 1997;9:173580.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1162/neco.1997.9.8.1735"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Long%20short-term%20memory&amp;author=S.%20Hochreiter&amp;author=J.%20Schmidhuber&amp;journal=Neural%20Comput&amp;volume=9&amp;pages=1735-1780&amp;publication_year=1997"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">77.</div><div class="CitationContent" id="CR77">Chellapilla
 K, Puri S, Simard P. High performance convolutional neural networks for
 document processing. In: Tenth international workshop on frontiers in 
handwriting recognition. Seattle: Suvisoft; 2006.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Chellapilla%20K%2C%20Puri%20S%2C%20Simard%20P.%20High%20performance%20convolutional%20neural%20networks%20for%20document%20processing.%20In%3A%20Tenth%20international%20workshop%20on%20frontiers%20in%20handwriting%20recognition.%20Seattle%3A%20Suvisoft%3B%202006."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">78.</div><div class="CitationContent" id="CR78">Goodfellow I, Bengio Y, Courville A. Deep learning. 
MIT Press; 2016. <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://www.deeplearningbook.org/"><span class="RefSource">http://www.deeplearningbook.org</span></a></span>.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">79.</div><div class="CitationContent" id="CR79">Bengio Y, LeCun Y, et al. Scaling learning algorithms towards AI. Large Scale Kernel Mach. 2007;34(5):141.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Scaling%20learning%20algorithms%20towards%20AI&amp;author=Y.%20Bengio&amp;author=Y.%20LeCun&amp;journal=Large%20Scale%20Kernel%20Mach&amp;volume=34&amp;issue=5&amp;pages=1-41&amp;publication_year=2007"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">80.</div><div class="CitationContent" id="CR80">Bengio
 Y, Courville A, Vincent P. Representation learning: a review and new 
perspectives. IEEE Trans Pattern Anal Mach Intell. 2013;35(8):1798828.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1109/TPAMI.2013.50"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Representation%20learning%3A%20a%20review%20and%20new%20perspectives&amp;author=Y.%20Bengio&amp;author=A.%20Courville&amp;author=P.%20Vincent&amp;journal=IEEE%20Trans%20Pattern%20Anal%20Mach%20Intell&amp;volume=35&amp;issue=8&amp;pages=1798-1828&amp;publication_year=2013"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">81.</div><div class="CitationContent" id="CR81">Bengio
 Y. Deep learning of representations: looking forward. In: International
 conference on statistical language and speech processing. Berlin: 
Springer; 2013. p. 137.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Bengio%20Y.%20Deep%20learning%20of%20representations%3A%20looking%20forward.%20In%3A%20International%20conference%20on%20statistical%20language%20and%20speech%20processing.%20Berlin%3A%20Springer%3B%202013.%20p.%201%E2%80%9337."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">82.</div><div class="CitationContent" id="CR82">Calandra
 R, Raiko T, Deisenroth MP, Pouzols FM. Learning deep belief networks 
from non-stationary streams. In: International conference on artificial 
neural networks. Berlin: Springer; 2012. p. 37986.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Calandra%20R%2C%20Raiko%20T%2C%20Deisenroth%20MP%2C%20Pouzols%20FM.%20Learning%20deep%20belief%20networks%20from%20non-stationary%20streams.%20In%3A%20International%20conference%20on%20artificial%20neural%20networks.%20Berlin%3A%20Springer%3B%202012.%20p.%20379%E2%80%9386."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">83.</div><div class="CitationContent" id="CR83">Zhou
 G, Sohn K, Lee H. Online incremental feature learning with denoising 
autoencoders. In: Artificial intelligence and statistics. 2012. p. 
145361.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Zhou%20G%2C%20Sohn%20K%2C%20Lee%20H.%20Online%20incremental%20feature%20learning%20with%20denoising%20autoencoders.%20In%3A%20Artificial%20intelligence%20and%20statistics.%202012.%20p.%201453%E2%80%9361."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">84.</div><div class="CitationContent" id="CR84">Dean
 J, Corrado G, Monga R, Chen K, Devin M, Mao M, Senior A, Tucker P, Yang
 K, Le QV, et al. Large scale distributed deep networks. In: Advances in
 neural information processing systems. 2012. p. 122331.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Dean%20J%2C%20Corrado%20G%2C%20Monga%20R%2C%20Chen%20K%2C%20Devin%20M%2C%20Mao%20M%2C%20Senior%20A%2C%20Tucker%20P%2C%20Yang%20K%2C%20Le%20QV%2C%20et%20al.%20Large%20scale%20distributed%20deep%20networks.%20In%3A%20Advances%20in%20neural%20information%20processing%20systems.%202012.%20p.%201223%E2%80%9331."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">85.</div><div class="CitationContent" id="CR85">Coates
 A, Huval B, Wang T, Wu D, Catanzaro B, Ng A. Deep learning with cots 
hpc systems. In: International conference on machine learning. 2013. p. 
133745.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Coates%20A%2C%20Huval%20B%2C%20Wang%20T%2C%20Wu%20D%2C%20Catanzaro%20B%2C%20Ng%20A.%20Deep%20learning%20with%20cots%20hpc%20systems.%20In%3A%20International%20conference%20on%20machine%20learning.%202013.%20p.%201337%E2%80%9345."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">86.</div><div class="CitationContent" id="CR86">Glorot
 X, Bordes A, Bengio Y. Domain adaptation for large-scale sentiment 
classification: a deep learning approach. In: Proceedings of the 28th 
international conference on machine learning (ICML-11); 2011. p. 51320.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Glorot%20X%2C%20Bordes%20A%2C%20Bengio%20Y.%20Domain%20adaptation%20for%20large-scale%20sentiment%20classification%3A%20a%20deep%20learning%20approach.%20In%3A%20Proceedings%20of%20the%2028th%20international%20conference%20on%20machine%20learning%20%28ICML-11%29%3B%202011.%20p.%20513%E2%80%9320."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">87.</div><div class="CitationContent" id="CR87">Chopra
 S, Balakrishnan S, Gopalan R. Dlid: deep learning for domain adaptation
 by interpolating between domains. In: ICML workshop on challenges in 
representation learning, vol. 2; 2013.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Chopra%20S%2C%20Balakrishnan%20S%2C%20Gopalan%20R.%20Dlid%3A%20deep%20learning%20for%20domain%20adaptation%20by%20interpolating%20between%20domains.%20In%3A%20ICML%20workshop%20on%20challenges%20in%20representation%20learning%2C%20vol.%202%3B%202013."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">88.</div><div class="CitationContent" id="CR88">Larochelle
 H, Bengio Y, Louradour J, Lamblin P. Exploring strategies for training 
deep neural networks. J Mach Learn Res. 2009;10:140.<span class="Occurrences"><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1235.68168"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Exploring%20strategies%20for%20training%20deep%20neural%20networks&amp;author=H.%20Larochelle&amp;author=Y.%20Bengio&amp;author=J.%20Louradour&amp;author=P.%20Lamblin&amp;journal=J%20Mach%20Learn%20Res&amp;volume=10&amp;pages=1-40&amp;publication_year=2009"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">89.</div><div class="CitationContent" id="CR89">Olshausen
 AB, Field DJ. Sparse coding with an overcomplete basis set: a strategy 
employed by v1? Vision Res. 1997;37(23):331125.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/S0042-6989%2897%2900169-7"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Sparse%20coding%20with%20an%20overcomplete%20basis%20set%3A%20a%20strategy%20employed%20by%20v1%3F&amp;author=AB.%20Olshausen&amp;author=DJ.%20Field&amp;journal=Vision%20Res&amp;volume=37&amp;issue=23&amp;pages=3311-3325&amp;publication_year=1997"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">90.</div><div class="CitationContent" id="CR90">Hinton
 G, Salakhutdinov R. Discovering binary codes for documents by learning 
deep generative models. Topics Cogn Sci. 2011;3(1):7491.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1111/j.1756-8765.2010.01109.x"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Discovering%20binary%20codes%20for%20documents%20by%20learning%20deep%20generative%20models&amp;author=G.%20Hinton&amp;author=R.%20Salakhutdinov&amp;journal=Topics%20Cogn%20Sci&amp;volume=3&amp;issue=1&amp;pages=74-91&amp;publication_year=2011"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">91.</div><div class="CitationContent" id="CR91">Salakhutdinov R, Hinton G. Semantic hashing. Int J Approx Reas. 2009;50(7):96978.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/j.ijar.2008.11.006"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Semantic%20hashing&amp;author=R.%20Salakhutdinov&amp;author=G.%20Hinton&amp;journal=Int%20J%20Approx%20Reas&amp;volume=50&amp;issue=7&amp;pages=969-978&amp;publication_year=2009"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">92.</div><div class="CitationContent" id="CR92">Le
 QV. Building high-level features using large scale unsupervised 
learning. In: 2013 IEEE international conference on acoustics, speech 
and signal processing (ICASSP). 2013. p. 85958.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Le%20QV.%20Building%20high-level%20features%20using%20large%20scale%20unsupervised%20learning.%20In%3A%202013%20IEEE%20international%20conference%20on%20acoustics%2C%20speech%20and%20signal%20processing%20%28ICASSP%29.%202013.%20p.%208595%E2%80%938."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">93.</div><div class="CitationContent" id="CR93">Vincent
 P, Larochelle H, Bengio Y, Manzagol PA. Extracting and composing robust
 features with denoising autoencoders. In: Proceedings of the 25th 
international conference on Machine learning. New York: ACM; 2008. p. 
1096103.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Vincent%20P%2C%20Larochelle%20H%2C%20Bengio%20Y%2C%20Manzagol%20PA.%20Extracting%20and%20composing%20robust%20features%20with%20denoising%20autoencoders.%20In%3A%20Proceedings%20of%20the%2025th%20international%20conference%20on%20Machine%20learning.%20New%20York%3A%20ACM%3B%202008.%20p.%201096%E2%80%93103."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">94.</div><div class="CitationContent" id="CR94">Ranzato
 M, Szummer M. Semi-supervised learning of compact document 
representations with deep networks. In: Proceedings of the 25th 
international conference on machine learning. New York: ACM; 2008. p. 
7929.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Ranzato%20M%2C%20Szummer%20M.%20Semi-supervised%20learning%20of%20compact%20document%20representations%20with%20deep%20networks.%20In%3A%20Proceedings%20of%20the%2025th%20international%20conference%20on%20machine%20learning.%20New%20York%3A%20ACM%3B%202008.%20p.%20792%E2%80%939."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">95.</div><div class="CitationContent" id="CR95">Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. arXiv preprint <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1301.3781"><span class="RefSource">arXiv:1301.3781</span></a></span>. 2013.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">96.</div><div class="CitationContent" id="CR96">Mikolov T, Chen K, Corrado G, Dean J. Efficient estimation of word representations in vector space. arXiv preprint <span class="ExternalRef"><a target="_blank" rel="noopener" href="http://arxiv.org/abs/1301.3781"><span class="RefSource">arXiv:1301.3781</span></a></span>. 2013.<span class="Occurrences"></span></div></li><li class="Citation"><div class="CitationNumber">97.</div><div class="CitationContent" id="CR97">Kim Y. Convolutional neural networks for sentence classification. In: Proceedings of EMNLP. 2014.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Kim%20Y.%20Convolutional%20neural%20networks%20for%20sentence%20classification.%20In%3A%20Proceedings%20of%20EMNLP.%202014."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">98.</div><div class="CitationContent" id="CR98">Le
 QV, Zou WY, Yeung Sy, Ng AY. Learning hierarchical invariant 
spatio-temporal features for action recognition with independent 
subspace analysis. In: 2011 IEEE conference on computer vision and 
pattern recognition (CVPR). 2011. p. 33618.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Le%20QV%2C%20Zou%20WY%2C%20Yeung%20Sy%2C%20Ng%20AY.%20Learning%20hierarchical%20invariant%20spatio-temporal%20features%20for%20action%20recognition%20with%20independent%20subspace%20analysis.%20In%3A%202011%20IEEE%20conference%20on%20computer%20vision%20and%20pattern%20recognition%20%28CVPR%29.%202011.%20p.%203361%E2%80%938."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">99.</div><div class="CitationContent" id="CR99">Gers F, Schmidhuber J, Cummins F. Learning to forget: continual prediction with LSTM. Neural Comput. 2000;12:245171.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1162/089976600300015015"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Learning%20to%20forget%3A%20continual%20prediction%20with%20LSTM&amp;author=F.%20Gers&amp;author=J.%20Schmidhuber&amp;author=F.%20Cummins&amp;journal=Neural%20Comput&amp;volume=12&amp;pages=2451-2471&amp;publication_year=2000"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">100.</div><div class="CitationContent" id="CR100">Graves A. Supervised sequence labelling with recurrent neural networks. Heidelberg: Springer; 2012.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1007/978-3-642-24797-2"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1235.68014"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Supervised%20sequence%20labelling%20with%20recurrent%20neural%20networks&amp;author=A.%20Graves&amp;publication_year=2012"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">101.</div><div class="CitationContent" id="CR101">Bastien
 F, Lamblin P, Pascanu R, Bengio Y. Theano: new features and speed 
improvements. In: NIPS workshop on deep learning and unsupervised 
feature learning. 2012.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Bastien%20F%2C%20Lamblin%20P%2C%20Pascanu%20R%2C%20Bengio%20Y.%20Theano%3A%20new%20features%20and%20speed%20improvements.%20In%3A%20NIPS%20workshop%20on%20deep%20learning%20and%20unsupervised%20feature%20learning.%202012."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">102.</div><div class="CitationContent" id="CR102">Bergstra
 J, Breuleux O, Bastien F, Bengio Y. Theano: a CPU and GPU math 
expression compiler. In: Python for scientific computing conference. 
2012.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Bergstra%20J%2C%20Breuleux%20O%2C%20Bastien%20F%2C%20Bengio%20Y.%20Theano%3A%20a%20CPU%20and%20GPU%20math%20expression%20compiler.%20In%3A%20Python%20for%20scientific%20computing%20conference.%202012."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">103.</div><div class="CitationContent" id="CR103">Bergstra
 J, Breuleux O, Bastien F, Lamblin P. Thumbs up? Sentiment 
classification using machine learning techniques, Python in science, 
vol. 9. 2015.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Bergstra%20J%2C%20Breuleux%20O%2C%20Bastien%20F%2C%20Lamblin%20P.%20Thumbs%20up%3F%20Sentiment%20classification%20using%20machine%20learning%20techniques%2C%20Python%20in%20science%2C%20vol.%209.%202015."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">104.</div><div class="CitationContent" id="CR104">Pang
 B, Lee L, Vaithyanathan S. TensorFlow: large-scale machine learning on 
heterogeneous distributed systems. In: Preliminary white paper, vol. 9. 
2015.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Pang%20B%2C%20Lee%20L%2C%20Vaithyanathan%20S.%20TensorFlow%3A%20large-scale%20machine%20learning%20on%20heterogeneous%20distributed%20systems.%20In%3A%20Preliminary%20white%20paper%2C%20vol.%209.%202015."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">105.</div><div class="CitationContent" id="CR105">Blitzer
 J, Dredze M, Pereira F, et al. Biographies, bollywood, boom-boxes and 
blenders: domain adaptation for sentiment classification. ACL. 
2007;7:4407.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=Biographies%2C%20bollywood%2C%20boom-boxes%20and%20blenders%3A%20domain%20adaptation%20for%20sentiment%20classification&amp;author=J.%20Blitzer&amp;author=M.%20Dredze&amp;author=F.%20Pereira&amp;journal=ACL&amp;volume=7&amp;pages=440-447&amp;publication_year=2007"><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">106.</div><div class="CitationContent" id="CR106">Wang
 S, Manning CD. Baselines and bigrams: simple, good sentiment and topic 
classification. In: Proceedings of the 50th annual meeting of the 
association for computational linguistics: short papers, vol. 2. 
Association for computational linguistics; 2012. p. 904.<span class="Occurrences"><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="https://scholar.google.com/scholar?q=Wang%20S%2C%20Manning%20CD.%20Baselines%20and%20bigrams%3A%20simple%2C%20good%20sentiment%20and%20topic%20classification.%20In%3A%20Proceedings%20of%20the%2050th%20annual%20meeting%20of%20the%20association%20for%20computational%20linguistics%3A%20short%20papers%2C%20vol.%202.%20Association%20for%20computational%20linguistics%3B%202012.%20p.%2090%E2%80%934."><span><span>Google Scholar</span></span></a></span></span></div></li><li class="Citation"><div class="CitationNumber">107.</div><div class="CitationContent" id="CR107">Tan C-M, Wang Y-F, Lee C-D. The use of bigrams to enhance text categorization. Inform Process Manag. 2002;38(4):52946.<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a class="gtm-reference" data-reference-type="CrossRef" target="_blank" rel="noopener" href="https://doi.org/10.1016/S0306-4573%2801%2900045-0"><span><span>CrossRef</span></span></a></span><span class="Occurrence OccurrenceZLBID"><a class="gtm-reference" data-reference-type="MATH" target="_blank" rel="noopener" href="http://www.emis.de/MATH-item?1052.68611"><span><span>MATH</span></span></a></span><span class="Occurrence OccurrenceGS"><a target="_blank" rel="noopener" class="google-scholar-link gtm-reference" data-reference-type="Google Scholar" href="http://scholar.google.com/scholar_lookup?title=The%20use%20of%20bigrams%20to%20enhance%20text%20categorization&amp;author=C-M.%20Tan&amp;author=Y-F.%20Wang&amp;author=C-D.%20Lee&amp;journal=Inform%20Process%20Manag&amp;volume=38&amp;issue=4&amp;pages=529-546&amp;publication_year=2002"><span><span>Google Scholar</span></span></a></span></span></div></li></ol></div></section><section class="Section1 RenderAsSection1"><h2 class="Heading" id="copyrightInformation" data-role="collapsible-handle" tabindex="0">Copyright information<span class="section-icon"></span></h2><div class="ArticleCopyright content"><div class="ArticleCopyright">&nbsp;The Author(s)&nbsp;2018</div><div id="License" class="License"><p class="SimplePara"><strong class="EmphasisTypeBold ">Open Access</strong>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<span class="ExternalRef"><a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by/4.0/"><span class="RefSource">http://creativecommons.org/licenses/by/4.0/</span></a></span>),
 which permits unrestricted use, distribution, and reproduction in any 
medium, provided you give appropriate credit to the original author(s) 
and the source, provide a link to the Creative Commons license, and 
indicate if changes were made.</p></div></div></section></div>
                        </article>
                        <aside class="section section--collapsible" id="AboutThisContent">
    <h2 class="section__heading" id="aboutcontent" data-role="collapsible-handle" tabindex="0">About this article<span class="section-icon"></span></h2>
    <div class="section__content bibliographic-information">
                <div id="crossMark" class="crossmark">
            <a data-crossmark="10.1186%2Fs40537-017-0111-6" class="gtm-crossmark" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1186%2Fs40537-017-0111-6" title="Verify currency and authenticity via CrossMark">
                <span class="u-screenreader-only">CrossMark</span>
                <svg class="CrossMark" id="crossmark-icon" width="57" height="81">
                    <image width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="/springerlink-static/481091012/images/png/crossmark.png" xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/481091012/images/svg/crossmark.svg"></image>
                </svg>
            </a>
        </div>

        <div class="crossmark__adjacent">
            <dl class="citation-info u-highlight-target u-mb-16" id="citeas">
    <dt class="test-cite-heading">
        Cite this article as:
    </dt>
    <dd id="citethis-text">Sohangir, S., Wang, D., Pomeranets, A. et al. J Big Data (2018) 5: 3. https://doi.org/10.1186/s40537-017-0111-6</dd>
</dl>
                <ul class="bibliographic-information__list bibliographic-information__list--inline">
        <li class="bibliographic-information__item">
            <span class="bibliographic-information__title"><abbr title="Digital Object Identifier">DOI</abbr></span>
            <span class="bibliographic-information__value u-overflow-wrap" id="doi-url">https://doi.org/10.1186/s40537-017-0111-6</span>
        </li>
            <li class="bibliographic-information__item">
                <span class="bibliographic-information__title">Publisher Name</span>
                <span class="bibliographic-information__value" id="publisher-name">Springer International Publishing</span>
            </li>
            <li class="bibliographic-information__item ">
                <span class="bibliographic-information__title">Online ISSN</span>
                <span class="bibliographic-information__value" id="electronic-issn">2196-1115</span>
            </li>

        
    </ul>

            <ul class="bibliographic-information__list">
        <li class="bibliographic-information__item">
            <a id="about-journal" class="bibliographic-information__misc-links gtm-about-this" title="Visit Springer.com for information about this article's journal" href="https://www.springer.com/journal/40537/about">About this journal</a>
        </li>
</ul>

        </div>
      
      
          
    </div>
</aside>

                        <div class="section section--collapsible uptodate-recommendations gtm-recommendations">
    <h2 class="uptodate-recommendations__title section__heading gtm-recommendations__title" id="uptodaterecommendations" data-role="collapsible-handle" tabindex="0">Personalised recommendations<span class="section-icon"></span></h2>
    <div class="section__content">
        <div class="uptodate-recommendations__container">
             <link rel="uptodate-inline" href="https://link.springer.com/springerlink-static/481091012/css/recommendations.css">
        </div>
    </div>
</div>
                                    <div class="sticky-banner u-interface u-js-screenreader-only" aria-hidden="true" data-component="SpringerLink.StickyBanner" data-namespace="hasButton">
                <div class="sticky-banner__container"><span class="sticky-banner__title sticky-banner__title--short u-overflow-ellipsis" title="Big Data: Deep Learning for financial sentiment analysis">Big Data: Deep Learning for financial sentiment analysis</span>
                        <div class="citations c-button-dropdown" data-component="SV.Dropdown" data-namespace="citationsSticky" aria-label="button with dropdown options" style="">
        <button type="button" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown.citationsSticky-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</span><span class="c-button-dropdown__icon"></span></button>
<div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown.citationsSticky-dropdown"><ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" class="gtm-cite-dropdown">How to cite?</a>
    </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=refman&amp;flavour=citation" title="Download this article's citation as a .RIS file" class="gtm-export-citation" data-gtmlabel="RIS">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=endnote&amp;flavour=citation" title="Download this article's citation as a .ENW file" class="gtm-export-citation" data-gtmlabel="ENW">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=bibtex&amp;flavour=citation" title="Download this article's citation as a .BIB file" class="gtm-export-citation" data-gtmlabel="BIB">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul></div>
    </div>

                            <a class="c-button share-this gtm-shareby-sharelink-link test-shareby-sharelink-link" data-test="shareable-link" target="_blank" rel="noopener" href="https://link.springer.com/sharelink/10.1186/s40537-017-0111-6"><span>Share</span> <span class="hide-text-small">article</span></a>




                                    <a href="https://link.springer.com/content/pdf/10.1186%2Fs40537-017-0111-6.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right gtm-pdf-link" title="Download this article in PDF format" rel="noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"></path></g></g></g></svg>
            <span class="hide-text-small">Download</span>
            <span>PDF</span>
        </a>

                </div>
            </div>




                    </div>
                    <aside class="main-sidebar-right u-interface">
                        <div data-role="sticky-wrapper">
                            <div class="main-sidebar-right__content u-composite-layer" data-component="SpringerLink.StickySidebar">
                                <div class="article-actions" id="article-actions">
                                    <h2 class="u-screenreader-only">Actions</h2>


                                    <div class="u-js-hide u-js-show-two-col">
                                        

                                                <div class="download-article test-pdf-link">
                                                            <a href="https://link.springer.com/content/pdf/10.1186%2Fs40537-017-0111-6.pdf" target="_blank" class="c-button c-button--blue c-button__icon-right gtm-pdf-link" title="Download this article in PDF format" rel="noopener">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" version="1.1"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill="#fff"><g transform="translate(12.000000, 5.000000)"><path d="M7 7.3L7 1C7 0.4 6.6 0 6 0 5.4 0 5 0.4 5 1L5 7.3 3.5 5.7C3.1 5.3 2.5 5.3 2.1 5.7L2.1 5.7C1.7 6.1 1.7 6.7 2.1 7.1L5.3 10.3C5.7 10.7 6.3 10.7 6.7 10.3L9.9 7.1C10.3 6.7 10.3 6.1 9.9 5.7L9.9 5.7C9.5 5.3 8.9 5.3 8.5 5.7L7 7.3 7 7.3ZM0 13C0 12.4 0.5 12 1 12L11 12C11.6 12 12 12.4 12 13 12 13.6 11.5 14 11 14L1 14C0.4 14 0 13.6 0 13L0 13Z"></path></g></g></g></svg>
            <span class="hide-text-small">Download</span>
            <span>PDF</span>
        </a>

                                                </div>


                                            <div class="citations c-button-dropdown" data-component="SV.Dropdown" data-namespace="citations" aria-label="button with dropdown options">
        <button type="button" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="Dropdown.citations-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">
    <span>Cite</span>
    <span class="hide-text-small">article</span>
</span><span class="c-button-dropdown__icon"></span></button>
<div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="Dropdown.citations-dropdown"><ul class="citations__content" data-role="button-dropdown__content">
    <li>
        <a href="#citeas" class="gtm-cite-dropdown">How to cite?</a>
    </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=refman&amp;flavour=citation" title="Download this article's citation as a .RIS file" class="gtm-export-citation" data-gtmlabel="RIS">
                <span class="citations__extension" data-gtmlabel="RIS">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .RIS
                </span>
                <span class="citations__types">
                        <span>
                            Papers
                        </span>
                        <span>
                            Reference Manager
                        </span>
                        <span>
                            RefWorks
                        </span>
                        <span>
                            Zotero
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=endnote&amp;flavour=citation" title="Download this article's citation as a .ENW file" class="gtm-export-citation" data-gtmlabel="ENW">
                <span class="citations__extension" data-gtmlabel="ENW">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .ENW
                </span>
                <span class="citations__types">
                        <span>
                            EndNote
                        </span>
                </span>
            </a>
        </li>
        <li>
            <a href="https://citation-needed.springer.com/v2/references/10.1186/s40537-017-0111-6?format=bibtex&amp;flavour=citation" title="Download this article's citation as a .BIB file" class="gtm-export-citation" data-gtmlabel="BIB">
                <span class="citations__extension" data-gtmlabel="BIB">
                    <svg class="u-vertical-align-absolute" width="12" height="14" viewBox="0 0 12 14" xmlns="http://www.w3.org/2000/svg"><path d="M7 7.269v-6.271c0-.551-.448-.998-1-.998-.556 0-1 .447-1 .998v6.271l-1.5-1.547c-.375-.387-1.01-.397-1.401-.006l.016-.016c-.397.397-.391 1.025-.001 1.416l3.178 3.178c.392.392 1.024.391 1.415 0l3.178-3.178c.392-.392.391-1.025-.001-1.416l.016.016c-.397-.397-1.018-.388-1.401.006l-1.5 1.547zm-7 5.731c0-.552.456-1 1.002-1h9.995c.554 0 1.002.444 1.002 1 0 .552-.456 1-1.002 1h-9.995c-.554 0-1.002-.444-1.002-1z" fill="#0176C3"></path></svg>
                    .BIB
                </span>
                <span class="citations__types">
                        <span>
                            BibTeX
                        </span>
                        <span>
                            JabRef
                        </span>
                        <span>
                            Mendeley
                        </span>
                </span>
            </a>
        </li>
</ul></div>
    </div>

                                                <a class="c-button share-this gtm-shareby-sharelink-link test-shareby-sharelink-link" data-test="shareable-link" target="_blank" rel="noopener" href="https://link.springer.com/sharelink/10.1186/s40537-017-0111-6"><span>Share</span> <span class="hide-text-small">article</span></a>




                                    </div>
                                </div>
                                <nav class="toc" aria-label="article contents">
    <h2 class="u-h4 u-screenreader-only">Table of contents</h2>
    <ul id="article-contents" class="article-contents" role="menu">
            <li role="menuitem">
                <a title="Article" href="#enumeration"><span class="u-overflow-ellipsis">Article</span></a>
            </li>
            <li role="menuitem">
                <a title="Abstract" href="#Abs1"><span class="u-overflow-ellipsis">Abstract</span></a>
            </li>
            <li role="menuitem">
                <a title="Introduction" href="#Sec1"><span class="u-overflow-ellipsis">Introduction</span></a>
            </li>
            <li role="menuitem">
                <a title="Related work" href="#Sec2"><span class="u-overflow-ellipsis">Related work</span></a>
            </li>
            <li role="menuitem">
                <a title="Methodology" href="#Sec3"><span class="u-overflow-ellipsis">Methodology</span></a>
            </li>
            <li role="menuitem">
                <a title="Conclusions" href="#Sec21"><span class="u-overflow-ellipsis">Conclusions</span></a>
            </li>
            <li role="menuitem">
                <a title="Notes" href="#Notes"><span class="u-overflow-ellipsis">Notes</span></a>
            </li>
            <li role="menuitem">
                <a title="References" href="#Bib1"><span class="u-overflow-ellipsis">References</span></a>
            </li>
            <li role="menuitem">
                <a title="Copyright information" href="#copyrightInformation"><span class="u-overflow-ellipsis">Copyright information</span></a>
            </li>
            
            <li role="menuitem">
                <a title="About this article" href="#aboutcontent"><span class="u-overflow-ellipsis">About this article</span></a>
            </li>
    </ul>
</nav>

                            </div>
                                <div class="skyscraper-ad u-hide" data-component="SpringerLink.GoogleAds" data-namespace="skyscraper"></div>

                        </div>
                    </aside>
                </div>
            </main>
                <footer class="footer u-interface">
        <div class="footer__aside-wrapper">
            <div class="footer__content">
                <div class="footer__aside">
                    <p class="footer__strapline">Over 10 million scientific documents at your fingertips</p>
                                <div class="footer__edition c-button-dropdown c-button-dropdown--ghost" data-component="SpringerLink.EditionSwitcher" aria-label="button with dropdown options">
                                    <button type="button" title="Switch between Academic &amp; Corporate Edition" class="c-button-dropdown__button" data-role="button-dropdown__control" aria-pressed="false" aria-expanded="false" aria-controls="EditionSwitcher.1104119191-dropdown"><span class="u-overflow-ellipsis c-button-dropdown__button-title">Academic Edition</span><span class="c-button-dropdown__icon"></span></button>
                                    <div class="u-composite-layer c-button-dropdown__container" aria-hidden="true" aria-label="dropdown" id="EditionSwitcher.1104119191-dropdown"><ul data-role="button-dropdown__content">
                                        <li class="selected"><a href="https://link.springer.com/siteEdition/link" id="siteedition-academic-link">Academic Edition</a></li>
                                        <li><a href="https://link.springer.com/siteEdition/rd" id="siteedition-corporate-link" tabindex="-1">Corporate Edition</a></li>
                                    </ul></div>
                                </div>
                </div>
            </div>
        </div>
        <div class="footer__content">
            <ul class="footer__nav">
                <li>
                    <a href="https://link.springer.com/">Home</a>
                </li>
                <li>
                    <a href="https://link.springer.com/impressum">Impressum</a>
                </li>
                <li>
                    <a href="https://link.springer.com/termsandconditions">Legal information</a>
                </li>
                <li>
                    <a href="https://link.springer.com/privacystatement">Privacy statement</a>
                </li>
                <li>
                    <a href="https://link.springer.com/cookiepolicy">How we use cookies</a>
                </li>
                <li>
                    <a href="https://link.springer.com/accessibility" class="gtm-footer-accessibility">Accessibility</a>
                </li>
                <li>
                    <a id="contactus-footer-link" href="https://link.springer.com/contactus">Contact us</a>
                </li>
            </ul>
            <a class="parent-logo" target="_blank" rel="noopener" href="https://www.springernature.com/" title="Go to Springer Nature">
                <span class="u-screenreader-only">Springer Nature</span>
                <svg width="125" height="12">
                    <image width="125" height="12" alt="Springer Nature logo" src="/springerlink-static/481091012/images/png/springernature.png" xlink="http://www.w3.org/1999/xlink" xlink:href="/springerlink-static/481091012/images/svg/springernature.svg">
                    </image>
                </svg>
            </a>

            <p class="footer__copyright"> 2017 Springer International Publishing AG. Part of <a target="_blank" rel="noopener" href="https://www.springernature.com/">Springer Nature</a>.</p>

                <p class="footer__user-access-info">
                    <span>Not logged in</span>
                    <span>CAPES MEC (3000197460) - Universidade Tecnologica Federal do Parana (3000201946)</span>
                    <span>168.181.51.234</span>
                </p>
        </div>
    </footer>

        </div>
          <script type="text/javascript">
    (function() {
        document.addEventListener('readystatechange', function () {
            if (document.readyState === 'complete') {
                var linkEl = document.querySelector('.js-ctm');
                if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
                    var scriptMathJax = document.createElement('script');
                    scriptMathJax.async = true;
                    scriptMathJax.src = '/springerlink-static/481091012/js/mathJax.js';
                    var s0 = document.getElementsByTagName('script')[0];
                    s0.parentNode.insertBefore(scriptMathJax, s0);
                }
            }
        });
    })();
</script>

<script type="text/javascript">
    (function() {
        var linkEl = document.querySelector('.js-ctm');
        var scriptsList = [];
        var polyfillFeatures = '';

        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
            (function(h){h.className = h.className.replace('no-js', 'js')})(document.documentElement);
            
            window.SpringerLink = window.SpringerLink || {};
            window.SpringerLink.staticLocation = '/springerlink-static/481091012';
            
            polyfillFeatures = 'default,fetch,Promise,Object.setPrototypeOf,Object.entries,Number.isInteger,MutationObserver,startsWith,Array.prototype.includes,Array.from';
            
            scriptsList = [
                // 'https://cdnjs.cloudflare.com/ajax/libs/airbrake-js/1.0.7/client.min.js',
                window.SpringerLink.staticLocation + '/js/jquery-3.3.1.min.js',
                'https://cdn.polyfill.io/v2/polyfill.js?features=' + polyfillFeatures,
                window.SpringerLink.staticLocation + '/js/main.js',
                        'https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js'
            ];

            scriptsList.forEach(function(script) {
                var tag = document.createElement('script');
                
                tag.async = false;
                tag.src = script;

                document.body.appendChild(tag);
            });
        }
    })();
</script><script src="jquery-3.js"></script><script src="polyfill.js"></script><script src="main.js"></script><script src="6b2ec9cd-5ace-4387-96d2-963e596401c6.js"></script>

<script type="text/javascript">
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>

<script type="text/javascript" class="optanon-category-2">

   function viewport() {
        if (document.documentElement.clientWidth < 620) {
            size = 'small';
        }
        else if(document.documentElement.clientWidth < 1075 ) {
            size = 'medium';
        }
        else {
            size = 'wide';
        }
        return size;
    };

    function reportForMouseEvents(linkCssSelectors, nolardUrl, experiment, abgroup) {
        var counter = 0;
        linkCssSelectors.forEach(function(cssSelector) {
            $('body').delegate(cssSelector, 'click', function() {
                if(counter == 0) {
                    reportConversion(nolardUrl, experiment, abgroup);
                    counter++;
                }
            });
        });
    };

    function reportConversion(nolardUrl, experiment, abgroup) {
        $.ajax({ url: nolardUrl + '/convert/' + experiment + '/' + abgroup });
    };

    function reportForMouseEvent(linkCssSelector, nolardUrl, experiment, abgroup) {
        var counter = 0;
        var elem = document.querySelector(linkCssSelector)

        if (elem.addEventListener) {
            elem.addEventListener("click", function(e) {
                if(counter == 0) {
                    reportConversion(nolardUrl, experiment, abgroup);
                    counter++;
                }
            });
        } else  {
            elem.attachEvent("click", function(e) {
                if(counter == 0) {
                    reportConversion(nolardUrl, experiment, abgroup);
                    counter++;
                }
            });
        }
    };

    function reportParticipation(nolardUrl, experiment, abgroup, participations) {
        if (participations)
            participations.push(experiment + '/' + abgroup)

        var xhr = new XMLHttpRequest()
        xhr.open('GET', nolardUrl + '/participate/' + experiment + '/' + abgroup);
        xhr.send();
    };

        function recordCurrentExperiment() {
            var participations = [];
            if (document.querySelector('#reprintsandpermissions-bottom-link') !== null) {
                reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-article-reprints-permissions-location', 'featureoff', participations);
                reportForMouseEvent('#reprintsandpermissions-bottom-link', 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-article-reprints-permissions-location', 'featureoff');
            } else if(document.querySelector('#reprintsandpermissions-top-link') !== null) {
                reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-article-reprints-permissions-location', 'featureon', participations);
                reportForMouseEvent('#reprintsandpermissions-top-link', 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-article-reprints-permissions-location', 'featureon');
            }
            return participations;
        };

</script>

<script type="text/javascript" class="optanon-category-2">
    window.onload = function() {
    var linkEl = document.querySelector('.js-ctm');


        if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
          var bookProductType = dataLayer[0].content && dataLayer[0].content.book && dataLayer[0].content.book.bookProductType
          var hasBody = dataLayer[0]['Has Body'] == 'Y';
          var userHasAccess = dataLayer[0]['HasAccess'] == 'Y';
          var liveOrStatic = dataLayer[0].content && dataLayer[0].content.version

          // Baseline reference work page
          var isReferenceWork = window.location.pathname.startsWith('/referencework/');
          var isReferenceWorkEntry = window.location.pathname.startsWith('/referenceworkentry/');
          var isEncOrDict = bookProductType == 'Encyclop(a)edia' || bookProductType == 'Dictionary';

          // Baseline static reference work entry page pdf download
          if (isReferenceWorkEntry && isEncOrDict && $('.test-rwepdf-link').length) {
            reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-enc-pdf-download', 'baseline');
            reportForMouseEvents(['.test-rwepdf-link'], 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-enc-pdf-download', 'baseline');
          }
          if (isReferenceWorkEntry && !isEncOrDict && $('.gtm-pdf-link').length) {
            reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-nonenc-pdf-download', 'baseline');
            reportForMouseEvents(['.gtm-pdf-link'], 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-nonenc-pdf-download', 'baseline');

            if (($('.test-bookpdf-link').length || $('.test-bookepub-link').length)) {
                reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-nonenc-book-download', 'baseline');
                reportForMouseEvents(['.test-bookpdf-link', 'test-bookepub-link'], 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-nonenc-book-download', 'baseline');
            }
          }

          // Baseline static reference work page pdf download
          if (isReferenceWork && isEncOrDict && ($('.test-bookpdf-link').length || $('.test-bookepub-link').length)) {
            reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-enc-book-download', 'baseline');
              reportForMouseEvents(['.test-bookpdf-link', 'test-bookepub-link'], 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-enc-book-download', 'baseline');
          }

          if (isReferenceWork && !isEncOrDict) {
            if (($('.test-bookpdf-link').length || $('.test-bookepub-link').length)) {
                reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-nonenc-book-download', 'baseline');
                reportForMouseEvents(['.test-bookpdf-link', 'test-bookepub-link'], 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-nonenc-book-download', 'baseline');
            }

            if ($('.test-book-toc-download-link').length) {
                reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-nonenc-pdf-download', 'baseline');
                reportForMouseEvents(['.test-book-toc-download-link'], 'https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwpage-nonenc-pdf-download', 'baseline');
            }
          }

          // Baseline static rwe page fulltext html view with access
          if (isReferenceWorkEntry && isEncOrDict && hasBody) {
            reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-enc-html-download', 'baseline');
            if (userHasAccess)
                reportConversion('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-enc-html-download', 'baseline');
          }
          if (isReferenceWorkEntry && !isEncOrDict && hasBody) {
            reportParticipation('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-nonenc-html-download', 'baseline');
            if (userHasAccess)
                reportConversion('https://ab-reporting.live.cf.public.springer.com', 'bunsen-'+liveOrStatic+'-rwepage-nonenc-html-download', 'baseline');
          }
      }

            if (window.matchMedia && window.matchMedia(linkEl.media).matches) {
                recordCurrentExperiment()
            }
   };

</script>

    <script type="text/javascript" id="googletag-push">
        
            var adSlot = '270604982/springerlink/40537/article';
        

        var definedSlots = [
                {slot: [728, 90], containerName: 'doubleclick-leaderboard-ad'},
                {slot: [160, 600], containerName: 'doubleclick-ad'},
        ];
    </script>


        
        <span id="chat-widget" class="u-hide"></span>
                    <noscript>
                <img aria-hidden="true" role="presentation" src="https://ssl-springer.met.vgwort.de/na/vgzm.415900-10.1186-s40537-017-0111-6" width='1' height='1' alt='' />
            </noscript>

    

<div style="display: none; visibility: hidden;"><script id="gpt-control-script" src="gpt.js"></script>

<script id="gpt-control-setup">var googletag=googletag||{};googletag.cmd=googletag.cmd||[];</script></div><button href="javascript:;" title="focus catcher" class="js-focus-catcher u-screenreader-only" tabindex="-1"></button><script type="text/javascript" id="">window.Krux||((Krux=function(){Krux.q.push(arguments)}).q=[]);
googletag.cmd.push(function(){googletag.pubads().setTargeting("doi",google_tag_manager["GTM-WCF9Z9"].macro(8));googletag.pubads().setTargeting("kwrd",google_tag_manager["GTM-WCF9Z9"].macro(9));googletag.pubads().setTargeting("pmc",google_tag_manager["GTM-WCF9Z9"].macro(10));googletag.pubads().setTargeting("BPID",google_tag_manager["GTM-WCF9Z9"].macro(11));googletag.pubads().setTargeting("edition",google_tag_manager["GTM-WCF9Z9"].macro(12));googletag.pubads().setTargeting("sucode",google_tag_manager["GTM-WCF9Z9"].macro(13));googletag.pubads().setTargeting("eissn",google_tag_manager["GTM-WCF9Z9"].macro(14));googletag.pubads().setTargeting("pissn",
google_tag_manager["GTM-WCF9Z9"].macro(15));googletag.pubads().setTargeting("eisbn",google_tag_manager["GTM-WCF9Z9"].macro(16));googletag.pubads().setTargeting("pisbn",google_tag_manager["GTM-WCF9Z9"].macro(17));googletag.pubads().setTargeting("logged",google_tag_manager["GTM-WCF9Z9"].macro(18));googletag.pubads().setTargeting("ksg",Krux.segments);googletag.pubads().setTargeting("kuid",Krux.uid);googletag.pubads().setRequestNonPersonalizedAds(google_tag_manager["GTM-WCF9Z9"].macro(22)?0:1);googletag.pubads().enableSingleRequest();googletag.pubads().enableAsyncRendering();googletag.enableServices()});</script><div id="optanon" class="modern"><div id="optanon-popup-bg"></div><div id="optanon-popup-wrapper" role="dialog" aria-modal="true" tabindex="-1" lang="en-GB"><div id="optanon-popup-top"><a href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Close Button');" class="optanon-close-link optanon-close optanon-close-ui" title="Close Preference Centre"><div id="optanon-close" style="background: url(https://optanon.blob.core.windows.net/skins/default_flat_bottom_two_button_white/v2/images/optanon-pop-up-close.png);width:34px;height:34px;"></div></a></div><div id="optanon-popup-body"><div id="optanon-popup-body-left"><div id="optanon-popup-body-left-shading"></div><div id="optanon-branding-top-logo" style="background-image: url(https://optanon.blob.core.windows.net/logos/5138/5138:link.springer.com/springer.png) !important;"></div><ul id="optanon-menu"><li class="menu-item-on menu-item-about" title="Your Privacy"><p><a href="#">Your Privacy</a></p></li><li class="menu-item-necessary menu-item-on" title="Strictly Necessary Cookies"><p><a href="#">Strictly Necessary Cookies</a></p></li><li class="menu-item-on menu-item-performance" title="Performance Cookies"><p><a href="#">Performance Cookies</a></p></li><li class="menu-item-on menu-item-functional" title="Functional Cookies"><p><a href="#">Functional Cookies</a></p></li><li class="menu-item-on menu-item-advertising" title="Targeting Cookies"><p><a href="#">Targeting Cookies</a></p></li><li class="menu-item-moreinfo menu-item-off" title="More Information"><p><a target="_blank" href="https://link.springer.com/cookiepolicy" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Cookie Policy');">More Information</a></p></li></ul></div><div id="optanon-popup-body-right"><h2 aria-label="true">Privacy Preference Centre</h2><h3></h3><div id="optanon-popup-more-info-bar"><div class="optanon-status"><div class="optanon-status-editable"><form><fieldset><p><input value="check" id="chkMain" checked="checked" class="optanon-status-checkbox" type="checkbox"><label for="chkMain">Active</label></p></fieldset></form></div><div class="optanon-status-always-active optanon-status-on"><p>Always Active</p></div></div></div><div id="optanon-main-info-text"></div></div><div class="optanon-bottom-spacer"></div></div><div id="optanon-popup-bottom"> <a href="https://onetrust.com/poweredbyonetrust" target="_blank"><div id="optanon-popup-bottom-logo" style="background: url(https://optanon.blob.core.windows.net/skins/default_flat_bottom_two_button_white/v2/images/cookie-collective-top-bottom.png);width:155px;height:35px;" title="powered by OneTrust"></div></a><div class="optanon-button-wrapper optanon-save-settings-button optanon-close optanon-close-consent"><div class="optanon-white-button-left"></div><div class="optanon-white-button-middle"><a href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Save Settings');">Save Settings</a></div><div class="optanon-white-button-right"></div></div><div class="optanon-button-wrapper optanon-allow-all-button optanon-allow-all" style="display: none;"><div class="optanon-white-button-left"></div><div class="optanon-white-button-middle"><a href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Preferences Allow All');">Allow All</a></div><div class="optanon-white-button-right"></div></div></div></div></div><div class="optanon-alert-box-wrapper  " style="bottom: -116.936px;"><div class="optanon-alert-box-bottom-top"><div class="optanon-alert-box-corner-close"><a class="optanon-alert-box-close" href="#" title="Close Banner" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Banner Close Button');"></a></div></div><div class="optanon-alert-box-bg"><div class="optanon-alert-box-logo"> </div><div class="optanon-alert-box-body"><p>We
 use cookies to personalise content and ads, to provide social media 
features and to analyse our traffic. We also share information about 
your use of our site with our social media, advertising and analytics 
partners in accordance with our <a href="https://link.springer.com/privacystatement">Privacy Statement</a>. You can manage your preferences in Manage Cookies.</p></div><div class="optanon-clearfix"></div><div class="optanon-alert-box-button-container"><div class="optanon-alert-box-button optanon-button-close"><div class="optanon-alert-box-button-middle"><a class="optanon-alert-box-close" href="#">Close</a></div></div><div class="optanon-alert-box-button optanon-button-allow"><div class="optanon-alert-box-button-middle"><a class="optanon-allow-all" href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Banner Accept Cookies');">OK</a></div></div><div class="optanon-alert-box-button optanon-button-more"><div class="optanon-alert-box-button-middle"><a class="optanon-toggle-display" href="#" onclick="Optanon.TriggerGoogleAnalyticsEvent('OneTrust Cookie Consent', 'Banner Open Preferences');">Manage Cookies</a></div></div></div><div class="optanon-clearfix optanon-alert-box-bottom-padding"></div></div></div><script type="text/javascript" id="">(function(d,z){function n(){for(var a in dataLayer)if(dataLayer.hasOwnProperty(a)&&dataLayer[a]["Event Category"])return dataLayer[a]["Event Category"];return"warning: no event category"}function v(a,b,c,h){"undefined"!==typeof dataLayer?dataLayer.push({event:"Scroll To Section",eventCategory:n(),eventAction:a,eventLabel:b,eventValue:1,eventNonInteraction:h}):("undefined"!==typeof ga&&ga("send","event",n(),a,b,1,{nonInteraction:1}),"undefined"!==typeof _gaq&&_gaq.push(["_trackEvent",n(),a,b,1,!0]))}
function k(b,g,c,h){if(-1===a[c].cache.indexOf(c+"-"+h)&&document.querySelectorAll(b).length){var f="viewed"===h?document.querySelectorAll(b)[0].getBoundingClientRect().height:0,x=document.querySelectorAll(b)[0].getBoundingClientRect().top+d.pageYOffset;g>=x+f&&(v(p(c)+" "+p(h),b,c,!1),a[c].cache.push(c+"-"+h),q++)}}function r(a){a=document.querySelectorAll(a);return a.length?a[0].offsetHeight||0:0}function m(b,g,c){var f=d.pageYOffset+d.innerHeight;if(q>=w)"handleClick"===g&&d.removeEventListener(b,
t),"throttle"===g&&d.removeEventListener(b,u);else if(c)setTimeout(function(){0<r(a[c].content)&&(a[c].reached&&k(a[c].content,f,c,"reached"),a[c].viewed&&k(a[c].content,f,c,"viewed"))},10);else for(var e in a)a.hasOwnProperty(e)&&0<r(a[e].content)&&(a[e].reached&&k(a[e].content,f,e,"reached"),a[e].viewed&&k(a[e].content,f,e,"viewed"))}function y(b){b=document.querySelectorAll(a[b].content).length;return 0<b?!0:!1}function p(a){return a.charAt(0).toUpperCase()+a.slice(1)}function u(a,b){var c,f,e,
g=null,d=0,k=function(){d=new Date;g=null;e=a.apply(c,f)};return function(){var h=new Date;d||(d=h);var l=b-(h-d);c=this;f=arguments;0>=l?(clearTimeout(g),g=null,d=h,e=a.apply(c,f)):g||(g=setTimeout(k,l));return e}}function t(a,b){return function(c){a(c,b)}}var w=0,q=0,a={recommendations:{content:".gtm-recommendations iframe",clickable:".gtm-recommendations .gtm-recommendations__title",exists:!1,reached:!1,viewed:!0,size:0,cache:[]},"abstract":{content:"Section.Abstract",clickable:null,exists:!0,
reached:!1,viewed:!0,size:0,cache:[]},references:{content:".Bibliography \x3e .content, [id^\x3dBib1] \x3e .content",clickable:".Bibliography \x3e .Heading, [id^\x3dBib1] \x3e .Heading",exists:!0,reached:!0,viewed:!0,size:0,cache:[]},about:{content:"#AboutThisContent",clickable:"#AboutThisContent \x3e #aboutcontent",exists:!1,reached:!1,viewed:!0,size:0,cache:[]}};d.addEventListener("scroll",u(function(){m("scroll","throttle")},500));d.addEventListener("orientationchange",u(function(){m("orientationchange",
"throttle")},500));for(var b in a)if(a.hasOwnProperty(b)&&(a[b].exists&&a[b].size++,a[b].reached&&a[b].size++,a[b].viewed&&a[b].size++,w+=a[b].size,a[b].exists&&y(b)||!a[b].exists)){a[b].exists&&-1===a[b].cache.indexOf(b+"-exists")&&(v(p(b)+" Exists",a[b].content,b,!0),a[b].cache.push(b+"-exists"),q++);if(0<r(a[b].content)){var l=d.pageYOffset+d.innerHeight;a[b].reached&&k(a[b].content,l,b,"reached");a[b].viewed&&k(a[b].content,l,b,"viewed")}a[b].clickable&&(l=document.querySelectorAll(a[b].clickable)[0])&&
(l.addEventListener("click",t(function(a,b){m("click","handleClick",b)},b)),l.addEventListener("click",t(function(a,b){13==a.keyCode&&m("click","handleClick",b)},b)))}})(window);</script><script type="text/javascript" id="gtm-recommendations-script" src="entry-point"></script><script type="text/javascript" id="">window.Krux||((Krux=function(){Krux.q.push(arguments)}).q=[]);(function(){var a=document.createElement("script");a.type="text/javascript";a.async=!0;a.src=("https:"===location.protocol?"https:":"http:")+"//cdn.krxd.net/controltag/KDqyaFZ_.js";var b=document.getElementsByTagName("script")[0];b.parentNode.insertBefore(a,b)})();</script><script type="text/javascript" id="">window.Krux||((Krux=function(){Krux.q.push(arguments)}).q=[]);(function(){function b(a){a="kx"+a;return window.localStorage?window.localStorage[a]||"":navigator.cookieEnabled?(a=document.cookie.match(a+"\x3d([^;]*)"))&&unescape(a[1])||"":""}Krux.user=b("user");Krux.segments=b("segs")&&b("segs").split(",")||[]})();</script><script type="text/javascript" id="">var allowed=google_tag_manager["GTM-WCF9Z9"].macro(38);Krux("consent:set",{dc:allowed,al:allowed,tg:allowed,cd:!1,sh:!1,re:!1},function(a,b){a?console.error(a):console.log("consent flags set ",b)});</script><script type="text/javascript" id="">window.dataLayer.push({ksg:Krux.segments,kuid:Krux.uid});</script><img class="pub_300x250 pub_300x250m pub_728x90 text-ad textAd text_ad text_ads text-ads text-ad-links" style="width: 1px !important; height: 1px !important; position: absolute !important; left: -10000px !important; top: -1000px !important;"></body><iframe id="kx-proxy-KDqyaFZ_" src="https://cdn.krxd.net/partnerjs/xdi/proxy.3d2100fd7107262ecb55ce6847f01fa5.html#%21kxcid=KDqyaFZ_&amp;kxt=https%3A%2F%2Flink.springer.com&amp;kxcl=cdn&amp;kxp=" style="display: none; visibility: hidden; height: 0; width: 0;"></iframe></html>